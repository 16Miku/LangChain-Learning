{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886ca6c9-ce4a-414a-9b9b-1e9c8176674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# LangGraph官方文档教程\n",
    "# https://langchain-ai.github.io/langgraph/tutorials/get-started/6-time-travel/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f5fb10-0af2-4b3c-8cfc-890c3dec111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time travel¶  时间旅行 ¶\n",
    "# In a typical chatbot workflow, the user interacts with the bot one or more times to accomplish a task. Memory and a human-in-the-loop enable checkpoints in the graph state and control future responses.\n",
    "# 在典型的聊天机器人工作流程中，用户需要与机器人进行一次或多次交互才能完成一项任务。 记忆和人机交互机制会在图形状态中启用检查点，并控制未来的响应。\n",
    "\n",
    "# What if you want a user to be able to start from a previous response and explore a different outcome? Or what if you want users to be able to rewind your chatbot's work to fix mistakes or try a different strategy, something that is common in applications like autonomous software engineers?\n",
    "# 如果您希望用户能够从之前的回复开始，探索不同的结果，该怎么办？或者，如果您希望用户能够回放聊天机器人的工作以修复错误或尝试不同的策略（这在自主软件工程师等应用中很常见），该怎么办？\n",
    "\n",
    "# You can create these types of experiences using LangGraph's built-in time travel functionality.\n",
    "# 您可以使用 LangGraph 的内置时间旅行功能来创建这些类型的体验。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecc82861-2113-44e8-bf69-1f8eac8a6dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note  笔记\n",
    "\n",
    "# This tutorial builds on Customize state.\n",
    "# 本教程以自定义状态为基础。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2bd56ae-43fc-4834-b303-fb95c5391c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Rewind your graph¶\n",
    "# 1. 回放你的图表 ¶\n",
    "# Rewind your graph by fetching a checkpoint using the graph's get_state_history method. You can then resume execution at this previous point in time.\n",
    "# 使用图的 get_state_history 方法获取检查点，即可回溯图。然后，您可以从该时间点恢复执行。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34b31409-d57d-4abd-be8e-f6ce381be9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U \"langchain[google-genai]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f72d58c-3ebb-48f4-866d-d945eeb245d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd846a1-da05-4f4d-84b2-77293b6cb4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e64a4ea8-176f-4d0a-9fb2-1c47b7c9fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Add steps¶\n",
    "# 2. 添加步骤 ¶\n",
    "# Add steps to your graph. Every step will be checkpointed in its state history:\n",
    "# 向图表中添加步骤。每个步骤都会在其状态历史记录中设置检查点：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb99df7-3e32-4f46-afae-0801851c2a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (320b91d6-6d93-4ce5-89cd-a6babb81a1a2)\n",
      " Call ID: 320b91d6-6d93-4ce5-89cd-a6babb81a1a2\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "    search_depth: advanced\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.ibm.com/think/topics/langgraph\", \"title\": \"What is LangGraph? - IBM\", \"content\": \"LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. [...] Agent systems: LangGraph provides a framework for building agent-based systems, which can be used in applications such as robotics, autonomous vehicles or video games.\\n\\nLLM applications: By using LangGraph’s capabilities, developers can build more sophisticated AI models that learn and improve over time. Norwegian Cruise Line uses LangGraph to compile, construct and refine guest-facing AI solutions. This capability allows for improved and personalized guest experiences. [...] By using a graph-based architecture, LangGraph enables users to scale artificial intelligence workflows without slowing down or sacrificing efficiency. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback. In the world of LLMs, this process is referred to as reflection.\", \"score\": 0.9353998, \"raw_content\": null}, {\"url\": \"https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141\", \"title\": \"Introduction to LangGraph: A Beginner's Guide - Medium\", \"content\": \"What is LangGraph?\\n==================\\n\\nLangGraph is a library built on top of LangChain, designed to add cyclic computational capabilities to your LLM applications. While LangChain allows you to define chains of computation (Directed Acyclic Graphs or DAGs), LangGraph introduces the ability to add cycles, enabling more complex, agent-like behaviors where you can call an LLM in a loop, asking it what action to take next.\\n\\nKey Concepts\\n============\", \"score\": 0.91362286, \"raw_content\": null}], \"response_time\": 1.96}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is an open-source AI agent framework created by LangChain. It's designed for building, deploying, and managing complex generative AI agent workflows. It provides tools and libraries to create, run, and optimize large language models (LLMs) in a scalable and efficient manner, using graph-based architectures to model the relationships between components. LangGraph allows you to add cycles, enabling more complex, agent-like behaviors where you can call an LLM in a loop, asking it what action to take next. It enhances decision-making by modeling complex relationships between nodes, using AI agents to analyze their past actions and feedback.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"I'm learning LangGraph. \"\n",
    "                    \"Could you do some research on it for me?\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eb46a39-c97f-455c-bc40-90599046bcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a great project! Let me know if you have any further questions about LangGraph or need help with anything else as you build your autonomous agent.\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Ya that's helpful. Maybe I'll \"\n",
    "                    \"build an autonomous agent with it!\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d55f0f10-e64e-4ae9-b22e-c4bdd522bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Replay the full state history¶\n",
    "# 3. 重放完整的状态历史 ¶\n",
    "# Now that you have added steps to the chatbot, you can replay the full state history to see everything that occurred.\n",
    "# 现在您已经向聊天机器人添加了步骤，您可以 replay 完整的状态历史记录以查看发生的所有事情。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "107b3df8-d4c3-4f6a-9ef1-626954b485b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8477a873-4951-4fe3-8fdc-fc73cf66c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints are saved for every step of the graph. This spans invocations so you can rewind across a full thread's history.\n",
    "# 检查点会保存图表中每一步的执行情况。这涵盖了所有调用 ，因此您可以回溯整个线程的历史记录。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e15e4d-1e62-4ae3-83a6-233938c3efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume from a checkpoint¶\n",
    "# 从检查点恢复 ¶\n",
    "# Resume from the to_replay state, which is after the chatbot node in the second graph invocation. Resuming from this point will call the action node next.\n",
    "# 从 to_replay 状态恢复，该状态位于第二次图表调用中的 chatbot 机器人节点之后。从此处恢复将调用接下来的操作节点。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fa37e90-2e0d-46b7-9c96-e2cc3ed486ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f060eae-d703-6b6f-8006-98c0fe53cc48'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "351bf6b0-00dd-4534-a341-1c93e5b7cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load a state from a moment-in-time¶\n",
    "# 4. 加载某个时刻的状态 ¶\n",
    "# The checkpoint's to_replay.config contains a checkpoint_id timestamp. Providing this checkpoint_id value tells LangGraph's checkpointer to load the state from that moment in time.\n",
    "# 检查点的 to_replay.config 文件包含一个 checkpoint_id 时间戳。提供此 checkpoint_id 值会告知 LangGraph 的检查点程序从该时刻开始加载状态。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97a8933d-a550-4820-8a41-6cc2aa7e201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a great project! Let me know if you have any further questions about LangGraph or need help with anything else as you build your autonomous agent.\n"
     ]
    }
   ],
   "source": [
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c2452-ab7d-434f-944b-11d0bca5513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Congratulations! You've now used time-travel checkpoint traversal in LangGraph. Being able to rewind and explore alternative paths opens up a world of possibilities for debugging, experimentation, and interactive applications.\n",
    "# 恭喜！ 您现在已经在 LangGraph 中使用了时间旅行检查点遍历。能够回溯并探索其他路径，为调试、实验和交互式应用程序开辟了无限可能。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d1be7-ca77-46bd-a889-9e9313dd24bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec0ec6-1da7-4563-96fd-2e08f8691ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f3e01-705f-43ff-a488-3be0f313adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如何自由地选择要回溯的历史记录并展开对话？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59033441-1aea-461d-8240-2f6d1380171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 您好！要在 LangGraph 中自由地选择要回溯的历史记录并展开对话，核心在于利用 LangGraph 的**检查点（Checkpointer）**功能。您的 `ChatbotWithTimeTravel.ipynb` 文件已经包含了实现这一功能的基础。\n",
    "\n",
    "# LangGraph 的 `checkpointer` 会在图的每一步执行后保存当前状态。这些保存的状态被称为“检查点”。通过 `graph.get_state_history()` 方法，您可以获取到一个特定对话线程的所有历史检查点。每个检查点都是一个 `StateSnapshot` 对象，它包含了当时的图状态 (`state.values`) 以及恢复到该状态所需的配置 (`state.config`)。\n",
    "\n",
    "# ### 实现“时间旅行”的步骤和原理\n",
    "\n",
    "# 1.  **保存历史记录：**\n",
    "#     当您使用 `graph.compile(checkpointer=memory)` 编译图时，并为每次 `graph.stream()` 或 `graph.invoke()` 调用提供一个唯一的 `thread_id`（例如 `config = {\"configurable\": {\"thread_id\": \"1\"}}`），LangGraph 就会自动为您保存每次交互的完整图状态历史。\n",
    "\n",
    "# 2.  **获取历史检查点：**\n",
    "#     使用 `graph.get_state_history(config)` 方法可以获取到指定 `thread_id` 的所有 `StateSnapshot` 对象。这些 `StateSnapshot` 是按时间倒序排列的（最新的在前面）。\n",
    "\n",
    "# 3.  **选择回溯点：**\n",
    "#     您可以遍历这些 `StateSnapshot`，向用户展示每个历史点的摘要信息（例如，当时的消息数量、最后一条消息的内容等），然后让用户选择一个想要回溯的特定检查点。每个 `StateSnapshot` 都有一个 `config` 属性，其中包含一个 `checkpoint_id`，这是该特定历史状态的唯一标识符。\n",
    "\n",
    "# 4.  **从检查点恢复对话：**\n",
    "#     一旦用户选择了某个历史检查点，您就可以使用该检查点的 `config` 来调用 `graph.stream()`。当 `graph.stream()` 的第一个参数（即输入消息）为 `None` 时，它会尝试从提供的 `config` 中加载状态并继续执行。如果提供了新的用户输入，它会从该检查点加载状态，然后处理新的输入。\n",
    "\n",
    "# ### 交互式代码示例\n",
    "\n",
    "# 以下代码演示了如何在您的 Jupyter Notebook 中实现一个简单的交互式“时间旅行”功能。它会先进行一段对话，然后列出历史记录，让用户选择一个时间点，最后从该时间点继续对话。\n",
    "\n",
    "# 请确保您已经运行了 `ChatbotWithTimeTravel.ipynb` 中所有之前的代码单元格（特别是设置 API 密钥和构建图的部分），以确保 `graph` 和 `config` 变量可用。\n",
    "\n",
    "# **新的代码单元格：**\n",
    "\n",
    "\n",
    "# ### 代码说明：\n",
    "\n",
    "# 1.  **`run_conversation_and_show_history` 函数：**\n",
    "#     *   这个函数封装了整个交互流程，接受一个初始用户输入和一个 `thread_id`。\n",
    "#     *   它首先进行几次对话，以积累一些历史记录。\n",
    "#     *   然后，它通过 `graph.get_state_history(current_config)` 获取当前线程的所有历史检查点。\n",
    "#     *   为了方便用户选择，它将历史记录反转为正序（从最旧到最新），并打印出每个历史点的序号、消息数量、最后一条消息的摘要以及下一个执行节点。\n",
    "#     *   它进入一个循环，提示用户输入想要回溯到的历史点序号，或者选择继续当前对话，或者退出。\n",
    "#     *   如果用户选择了回溯点，它会使用该历史点的 `StateSnapshot.config` 作为新的配置来调用 `graph.stream(None, selected_snapshot.config, ...)`。这里的 `None` 表示我们不是给图提供新的输入，而是加载并恢复到那个历史状态。\n",
    "#     *   恢复后，它会打印出该历史点的对话内容，并允许用户输入新的问题，从而在那个历史分支上展开新的对话。\n",
    "#     *   如果用户选择不回溯，则继续在当前对话的最新状态上进行交互。\n",
    "\n",
    "# 2.  **`uuid.uuid4()`：**\n",
    "#     为了确保每次运行此示例时都有一个独立的对话历史，我使用了 `uuid.uuid4()` 来生成一个唯一的 `thread_id`。在实际应用中，`thread_id` 通常与用户会话或聊天室相关联。\n",
    "\n",
    "# 3.  **`graph.stream(None, to_replay.config, stream_mode=\"values\")`：**\n",
    "#     这是实现时间旅行的关键。当您将 `stream()` 的第一个参数（输入消息）设置为 `None` 时，LangGraph 会根据传入的 `config`（其中包含了 `checkpoint_id`）从检查点加载完整的历史状态，并从该点开始继续执行。这意味着您可以从历史的任何一个点“复活”对话，并从那里开始新的交互分支。\n",
    "\n",
    "# ### 如何运行：\n",
    "\n",
    "# 1.  确保您的 Jupyter Notebook 环境中已安装所有必要的库 (`langgraph`, `langchain-tavily`, `langchain[google-genai]`)。\n",
    "# 2.  确保您已正确设置 `GOOGLE_API_KEY` 和 `TAVILY_API_KEY` 环境变量（或者通过 `getpass.getpass()` 手动输入）。\n",
    "# 3.  按顺序运行 `ChatbotWithTimeTravel.ipynb` 中所有之前的代码单元格。\n",
    "# 4.  将上述提供的完整代码粘贴到一个新的代码单元格中，然后运行它。\n",
    "\n",
    "# 您将看到一个交互式界面，允许您体验 LangGraph 的“时间旅行”功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65f164a3-b302-41fb-9596-34adc7ccf1da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始新对话线程: 86abd04f-e0c7-40a3-8376-9ae7af827eb1 ---\n",
      "User: Hi, I'm Bob. What is LangGraph?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I'm Bob. What is LangGraph?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (8e60b593-25e6-4b48-90ec-29232bc68a52)\n",
      " Call ID: 8e60b593-25e6-4b48-90ec-29232bc68a52\n",
      "  Args:\n",
      "    topic: general\n",
      "    query: What is LangGraph?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"What is LangGraph?\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"title\": \"LangGraph Tutorial: What Is LangGraph and How to Use It?\", \"content\": \"LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.\", \"score\": 0.9581988, \"raw_content\": null}, {\"url\": \"https://www.ibm.com/think/topics/langgraph\", \"title\": \"What is LangGraph? - IBM\", \"content\": \"LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. LangGraph illuminates the processes within an AI workflow, allowing full transparency of the agent’s state. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including chatbots, state graphs and other agent-based systems. Nodes: In LangGraph, nodes represent individual components or agents within an AI workflow. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback.\", \"score\": 0.9554898, \"raw_content\": null}], \"response_time\": 1.51}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a framework within the LangChain ecosystem designed for building, deploying, and managing complex generative AI agent workflows. It uses graph-based architectures to model the relationships between different components of an AI agent workflow, allowing for transparency and enhanced decision-making. It simplifies the development of complex LLM applications by providing a structured way to manage state and coordinate agent interactions.\n",
      "\n",
      "User: Tell me more about its applications.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me more about its applications.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (dcf4e761-2452-4f86-81af-32033eec5b42)\n",
      " Call ID: dcf4e761-2452-4f86-81af-32033eec5b42\n",
      "  Args:\n",
      "    topic: general\n",
      "    query: LangGraph applications\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph applications\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.langchain.com/langgraph\", \"title\": \"LangGraph - LangChain\", \"content\": \"Design agent-driven user experiences with LangGraph Platform's APIs. Quickly deploy and scale your application with infrastructure built for agents. LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that 'just work'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution to iterate quickly, debug immediately, and scale effortlessly.” LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that 'just work'. LangGraph Platform is a service for deploying and scaling LangGraph applications, with an opinionated API for building agent UXs, plus an integrated developer studio.\", \"score\": 0.8014549, \"raw_content\": null}, {\"url\": \"https://langchain-ai.github.io/langgraph/concepts/application_structure/\", \"title\": \"Application structure - GitHub Pages\", \"content\": \"Published Time: Mon, 07 Jul 2025 00:42:09 GMT Skip to content *   Time travel *   Plans & pricing *   Scalability & resilience Application Structure¶ This guide shows a typical structure of an application and shows how the required information to deploy an application using the LangGraph Platform is specified. Below are examples of directory structures for Python and JavaScript applications: The `langgraph.json` file is a JSON file that specifies the dependencies, graphs, environment variables, and other settings required to deploy a LangGraph application. Each graph is identified by a name (which should be unique) and a path for either: (1) the compiled graph or (2) a function that makes a graph is defined. Back to top Previous Plans & pricingNext Scalability & resilience\", \"score\": 0.7311551, \"raw_content\": null}], \"response_time\": 1.33}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph can be used for:\n",
      "\n",
      "*   **Conversational agents:** Building chatbots that can handle various user requests.\n",
      "*   **Complex task automation:** Automating intricate tasks by coordinating multiple agents.\n",
      "*   **Custom LLM-backed experiences:** Creating tailored experiences powered by large language models.\n",
      "\n",
      "User: Can it be used for emotional support chatbots?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can it be used for emotional support chatbots?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (113569a2-ab20-4721-ae87-9af836b3f82a)\n",
      " Call ID: 113569a2-ab20-4721-ae87-9af836b3f82a\n",
      "  Args:\n",
      "    topic: general\n",
      "    query: LangGraph emotional support chatbot\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph emotional support chatbot\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.youtube.com/watch?v=b3XsvoFWp4c\", \"title\": \"Build a Customer Support Bot | LangGraph - YouTube\", \"content\": \"Build a Customer Support Bot | LangGraph LangChain 1530 likes 71244 views 7 May 2024 Build a Customer Support Chatbot | LangGraph In this tutorial, we create a travel assistant chatbot using LangGraph, demonstrating reusable techniques applicable to building any customer support chatbot or AI system that uses tools, supports many user journeys, or requires a high degree of control. Zero-Shot Tool Executor: In the first part, we develop a simple agent with an LLM and tools, showing the limitations of this flat design for complex experiences. User Confirmation: In the second part, we add user confirmation before the agent takes any sensitive actions, giving the user more control but at the cost of a less autonomous experience. Conditional Interrupts: In the third part, we split tools into \\\"safe\\\" and \\\"sensitive\\\" categories, only requiring user confirmation on sensitive actions. Specialized Workflows: In the fourth part, we separate user journeys into specific \\\"skills\\\" or \\\"workflows\\\". By the end of this tutorial, you'll understand key principles for designing customer support chatbots, balancing expressiveness and control to create delightful user experiences.\", \"score\": 0.66203266, \"raw_content\": null}, {\"url\": \"https://python.langchain.com/docs/tutorials/chatbot/\", \"title\": \"Build a Chatbot | 🦜️   LangChain\", \"content\": \"`from langgraph.checkpoint.memory import MemorySaverfrom langgraph.graph import START, MessagesState, StateGraph# Define a new graphworkflow = StateGraph(state_schema=MessagesState)# Define the function that calls the modeldef call_model(state: MessagesState):    response = model.invoke(state[\\\"messages\\\"])    return {\\\"messages\\\": response}# Define the (single) node in the graphworkflow.add_edge(START, \\\"model\\\")workflow.add_node(\\\"model\\\", call_model)# Add memorymemory = MemorySaver()app = workflow.compile(checkpointer=memory)` `from typing import Sequencefrom langchain_core.messages import BaseMessagefrom langgraph.graph.message import add_messagesfrom typing_extensions import Annotated, TypedDictclass State(TypedDict):    messages: Annotated[Sequence[BaseMessage], add_messages]    language: strworkflow = StateGraph(state_schema=State)def call_model(state: State):    prompt = prompt_template.invoke(state)    response = model.invoke(prompt)    return {\\\"messages\\\": [response]}workflow.add_edge(START, \\\"model\\\")workflow.add_node(\\\"model\\\", call_model)memory = MemorySaver()app = workflow.compile(checkpointer=memory)` `config = {\\\"configurable\\\": {\\\"thread_id\\\": \\\"abc789\\\"}}query = \\\"Hi I'm Todd, please tell me a joke.\\\"language = \\\"English\\\"input_messages = [HumanMessage(query)]for chunk, metadata in app.stream(    {\\\"messages\\\": input_messages, \\\"language\\\": language},    config,    stream_mode=\\\"messages\\\",):    if isinstance(chunk, AIMessage):  # Filter to just model responses        print(chunk.content, end=\\\"|\\\")`\", \"score\": 0.502564, \"raw_content\": null}], \"response_time\": 1.33}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "While the search results don't explicitly confirm LangGraph's use in *emotional* support chatbots, the technology is well-suited for customer support bots. With careful design and the right prompts, it seems feasible to adapt LangGraph for emotional support. Considerations would include:\n",
      "\n",
      "*   **Training Data:** Fine-tuning the LLMs with data that includes empathetic responses and an understanding of emotional cues.\n",
      "*   **Ethical Considerations:** Implementing safeguards to prevent the chatbot from giving harmful advice or posing as a human therapist.\n",
      "*   **Context Management:** Using LangGraph's state management to track the user's emotional state and tailor responses accordingly.\n",
      "*   **Specialized workflows:** Creating workflows that direct users to professional help when necessary.\n",
      "\n",
      "--- 对话历史记录 ---\n",
      "[0] Checkpoint ID: 1f060ed8-9ba1-61af-bfff-a97a2e9a63c3\n",
      "    消息数量: 0\n",
      "    最后一条消息: No messages at this state...\n",
      "    下一个执行节点: ('__start__',)\n",
      "------------------------------\n",
      "[1] Checkpoint ID: 1f060ed8-9ba6-600e-8000-faeea06c7fb8\n",
      "    消息数量: 1\n",
      "    最后一条消息: Hi, I'm Bob. What is LangGraph?...\n",
      "    下一个执行节点: ('chatbot',)\n",
      "------------------------------\n",
      "[2] Checkpoint ID: 1f060ed8-ab2e-6fb3-8001-13d58599cd00\n",
      "    消息数量: 2\n",
      "    最后一条消息: ...\n",
      "    下一个执行节点: ('tools',)\n",
      "------------------------------\n",
      "[3] Checkpoint ID: 1f060ed8-cbce-68c2-8002-c217f8d46509\n",
      "    消息数量: 3\n",
      "    最后一条消息: {\"query\": \"What is LangGraph?\", \"follow_up_questions\": null, \"answer\": null, \"im...\n",
      "    下一个执行节点: ('chatbot',)\n",
      "------------------------------\n",
      "[4] Checkpoint ID: 1f060ed8-d5a9-66f5-8003-80b571c9e522\n",
      "    消息数量: 4\n",
      "    最后一条消息: LangGraph is a framework within the LangChain ecosystem designed for building, d...\n",
      "    下一个执行节点: ()\n",
      "------------------------------\n",
      "[5] Checkpoint ID: 1f060ed8-d5ac-6629-8004-8ea28566ee79\n",
      "    消息数量: 4\n",
      "    最后一条消息: LangGraph is a framework within the LangChain ecosystem designed for building, d...\n",
      "    下一个执行节点: ('__start__',)\n",
      "------------------------------\n",
      "[6] Checkpoint ID: 1f060ed8-d5b0-6241-8005-4a52af41c97c\n",
      "    消息数量: 5\n",
      "    最后一条消息: Tell me more about its applications....\n",
      "    下一个执行节点: ('chatbot',)\n",
      "------------------------------\n",
      "[7] Checkpoint ID: 1f060ed8-dedd-6f2e-8006-4b0d245fc9d0\n",
      "    消息数量: 6\n",
      "    最后一条消息: ...\n",
      "    下一个执行节点: ('tools',)\n",
      "------------------------------\n",
      "[8] Checkpoint ID: 1f060ed8-fa96-6e3d-8007-07dacb2a96fe\n",
      "    消息数量: 7\n",
      "    最后一条消息: {\"query\": \"LangGraph applications\", \"follow_up_questions\": null, \"answer\": null,...\n",
      "    下一个执行节点: ('chatbot',)\n",
      "------------------------------\n",
      "[9] Checkpoint ID: 1f060ed9-05f2-6a7e-8008-ecdc83d2f8b0\n",
      "    消息数量: 8\n",
      "    最后一条消息: LangGraph can be used for:\n",
      "\n",
      "*   **Conversational agents:** Building chatbots tha...\n",
      "    下一个执行节点: ()\n",
      "------------------------------\n",
      "[10] Checkpoint ID: 1f060ed9-05f7-6c2e-8009-9b6a3020cc6a\n",
      "    消息数量: 8\n",
      "    最后一条消息: LangGraph can be used for:\n",
      "\n",
      "*   **Conversational agents:** Building chatbots tha...\n",
      "    下一个执行节点: ('__start__',)\n",
      "------------------------------\n",
      "[11] Checkpoint ID: 1f060ed9-05fa-62f0-800a-e555297246db\n",
      "    消息数量: 9\n",
      "    最后一条消息: Can it be used for emotional support chatbots?...\n",
      "    下一个执行节点: ('chatbot',)\n",
      "------------------------------\n",
      "[12] Checkpoint ID: 1f060ed9-0eb8-61fc-800b-b86b68a008e0\n",
      "    消息数量: 10\n",
      "    最后一条消息: ...\n",
      "    下一个执行节点: ('tools',)\n",
      "------------------------------\n",
      "[13] Checkpoint ID: 1f060ed9-2f5b-6b40-800c-9567a80107a0\n",
      "    消息数量: 11\n",
      "    最后一条消息: {\"query\": \"LangGraph emotional support chatbot\", \"follow_up_questions\": null, \"a...\n",
      "    下一个执行节点: ('chatbot',)\n",
      "------------------------------\n",
      "[14] Checkpoint ID: 1f060ed9-41b3-69b2-800d-7247b892b80f\n",
      "    消息数量: 12\n",
      "    最后一条消息: While the search results don't explicitly confirm LangGraph's use in *emotional*...\n",
      "    下一个执行节点: ()\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "请输入您想回溯到的历史点序号 (例如: 0, 1, 2...)，输入 'n' 继续当前对话，或输入 'q' 退出:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您选择了回溯到历史点 [1]。\n",
      "\n",
      "--- 从检查点 1f060ed8-9ba6-600e-8000-faeea06c7fb8 恢复对话 ---\n",
      "\n",
      "当前对话内容 (恢复后):\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I'm Bob. What is LangGraph?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "从该历史点开始，请输入您的新问题 (输入 'q' 退出):  你记得我的名字吗？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "你记得我的名字吗？\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "是的，你的名字是鲍勃。朗格拉夫是什么？\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "从该历史点开始，请输入您的新问题 (输入 'q' 退出):  我们之前的对话有哪些内容？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "我们之前的对话有哪些内容？\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "我没有记住之前的对话。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "从该历史点开始，请输入您的新问题 (输入 'q' 退出):  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结束当前分支对话。\n"
     ]
    }
   ],
   "source": [
    "import uuid # 用于生成唯一的 thread_id\n",
    "\n",
    "def run_conversation_and_show_history(initial_user_input: str, thread_id: str):\n",
    "    \"\"\"\n",
    "    运行一段对话，然后显示历史记录，并允许用户选择回溯点。\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 开始新对话线程: {thread_id} ---\")\n",
    "    current_config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "    # 第一次交互\n",
    "    print(f\"User: {initial_user_input}\")\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": initial_user_input}]},\n",
    "        current_config,\n",
    "        stream_mode=\"values\",\n",
    "    )\n",
    "    for event in events:\n",
    "        if \"messages\" in event and event[\"messages\"]:\n",
    "            event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    # 第二次交互\n",
    "    second_input = \"Tell me more about its applications.\"\n",
    "    print(f\"\\nUser: {second_input}\")\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": second_input}]},\n",
    "        current_config,\n",
    "        stream_mode=\"values\",\n",
    "    )\n",
    "    for event in events:\n",
    "        if \"messages\" in event and event[\"messages\"]:\n",
    "            event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    # 第三次交互\n",
    "    third_input = \"Can it be used for emotional support chatbots?\"\n",
    "    print(f\"\\nUser: {third_input}\")\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": third_input}]},\n",
    "        current_config,\n",
    "        stream_mode=\"values\",\n",
    "    )\n",
    "    for event in events:\n",
    "        if \"messages\" in event and event[\"messages\"]:\n",
    "            event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    print(\"\\n--- 对话历史记录 ---\")\n",
    "    history_snapshots = []\n",
    "    # get_state_history 返回的是倒序，我们把它正序存储方便用户选择\n",
    "    for i, state in enumerate(reversed(list(graph.get_state_history(current_config)))):\n",
    "        history_snapshots.append(state)\n",
    "        # 获取最后一条消息的内容，如果消息列表为空则显示提示\n",
    "        last_message_content = \"No messages at this state\"\n",
    "        if state.values and \"messages\" in state.values and state.values[\"messages\"]:\n",
    "            last_message_content = state.values[\"messages\"][-1].content\n",
    "        \n",
    "        print(f\"[{i}] Checkpoint ID: {state.config['configurable']['checkpoint_id']}\")\n",
    "        print(f\"    消息数量: {len(state.values.get('messages', []))}\")\n",
    "        print(f\"    最后一条消息: {last_message_content[:80]}...\") # 只显示前80个字符\n",
    "        print(f\"    下一个执行节点: {state.next}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(\"\\n请输入您想回溯到的历史点序号 (例如: 0, 1, 2...)，输入 'n' 继续当前对话，或输入 'q' 退出: \").strip()\n",
    "            if choice.lower() == 'q':\n",
    "                print(\"退出时间旅行模式。\")\n",
    "                return\n",
    "            elif choice.lower() == 'n':\n",
    "                print(\"继续当前对话。\")\n",
    "                selected_snapshot = None # 表示不回溯，继续当前状态\n",
    "                break\n",
    "            \n",
    "            selected_index = int(choice)\n",
    "            if 0 <= selected_index < len(history_snapshots):\n",
    "                selected_snapshot = history_snapshots[selected_index]\n",
    "                print(f\"您选择了回溯到历史点 [{selected_index}]。\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"无效的序号，请重新输入。\")\n",
    "        except ValueError:\n",
    "            print(\"输入无效，请输入数字或 'n'/'q'。\")\n",
    "\n",
    "    if selected_snapshot:\n",
    "        # 使用选定的历史检查点的 config 来恢复对话\n",
    "        print(f\"\\n--- 从检查点 {selected_snapshot.config['configurable']['checkpoint_id']} 恢复对话 ---\")\n",
    "        \n",
    "        # 打印恢复后的当前对话内容\n",
    "        print(\"\\n当前对话内容 (恢复后):\")\n",
    "        if selected_snapshot.values and \"messages\" in selected_snapshot.values:\n",
    "            for msg in selected_snapshot.values[\"messages\"]:\n",
    "                msg.pretty_print()\n",
    "        else:\n",
    "            print(\"无历史消息可显示。\")\n",
    "        \n",
    "        # 准备一个新的输入，从这个历史点开始新的分支\n",
    "        while True:\n",
    "            new_user_input = input(\"\\n从该历史点开始，请输入您的新问题 (输入 'q' 退出): \").strip()\n",
    "            if new_user_input.lower() == 'q':\n",
    "                print(\"结束当前分支对话。\")\n",
    "                break\n",
    "            \n",
    "            # 使用选定的 snapshot 的 config 来 stream 新的输入\n",
    "            new_events = graph.stream(\n",
    "                {\"messages\": [{\"role\": \"user\", \"content\": new_user_input}]},\n",
    "                selected_snapshot.config, # 使用历史检查点的 config\n",
    "                stream_mode=\"values\",\n",
    "            )\n",
    "            for event in new_events:\n",
    "                if \"messages\" in event and event[\"messages\"]:\n",
    "                    event[\"messages\"][-1].pretty_print()\n",
    "    else:\n",
    "        # 如果用户选择不回溯，则继续当前对话\n",
    "        print(\"\\n--- 继续当前对话 ---\")\n",
    "        while True:\n",
    "            new_user_input = input(\"\\n请输入您的新问题 (输入 'q' 退出): \").strip()\n",
    "            if new_user_input.lower() == 'q':\n",
    "                print(\"结束对话。\")\n",
    "                break\n",
    "            \n",
    "            new_events = graph.stream(\n",
    "                {\"messages\": [{\"role\": \"user\", \"content\": new_user_input}]},\n",
    "                current_config, # 使用当前对话的 config\n",
    "                stream_mode=\"values\",\n",
    "            )\n",
    "            for event in new_events:\n",
    "                if \"messages\" in event and event[\"messages\"]:\n",
    "                    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# 运行示例\n",
    "# 使用一个新的线程ID来避免与之前教程的thread_id冲突\n",
    "new_thread_id = str(uuid.uuid4())\n",
    "run_conversation_and_show_history(\"Hi, I'm Bob. What is LangGraph?\", new_thread_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957dafa4-3fc3-4cf9-8f64-f3b73d38b5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9785a06-4eed-4360-b7bd-d6784f8cfbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97295f1-6c7c-496c-b99d-1d128ed887e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44f54c8-04b5-4026-8669-e6cd9ea3cfad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263dc64d-015d-4281-96ed-4418ca3c18ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1bd4b-11fe-41a1-a202-509c5ff82050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c698225-3582-4b95-878c-006959a3deb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3392658-7308-497b-bbab-148ef959695d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb3c501-4e30-4806-9032-d7fd12297ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f9b5e-8266-4f98-803d-3f7a84c2af33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d8469-9dc1-445e-b52e-53646cbdea4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d059d6-a996-49fe-9854-7c6a66764ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67035c7-757b-4945-8226-1b0d81abbf1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c95d9-03b9-441b-b85c-85e786ac8ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adce8e6-1395-4f21-af47-7c67ac2a4d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196de161-bf8c-4651-a4a6-e565fd3be287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf2958-f7a4-41ed-9295-7c3b398bd986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb9aff-81bb-4b70-9476-1ae6ae2106d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc39be-7242-478a-a433-3dde3a53b4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e0fcb-7410-420a-8efe-8d97dab69916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1427e4-3236-4aba-add8-b30241f5eb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba34ae-5d70-4ff2-8e9c-4667d9373066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81013bb-08f1-4172-a12f-3e0fabcf1bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238836ba-c49a-4faf-94b7-097df86e11e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5c044-de15-4aa6-9366-ff79b6da656f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e1a64-56f3-4f43-a1db-2490781a35dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857cc8ea-6c5d-47d0-9b84-4ed1ffedb6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
