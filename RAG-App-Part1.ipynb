{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76083083-2000-40ee-9b76-f077c9a3b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7763de38-daeb-4887-b463-7b32d0a687f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced8d202-d8db-4124-ad72-11b926921403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建RAG应用：第一部分\n",
    "# 本教程旨在指导您构建一个基于文本数据源的简单问答（Q&A）应用程序。我们将深入探讨典型的Q&A架构，并重点介绍RAG技术。\n",
    "\n",
    "# 什么是RAG？\n",
    "# RAG（Retrieval Augmented Generation）是一种结合了信息检索和文本生成的技术，用于增强大型语言模型（LLM）的问答能力。它通过在生成答案之前从外部知识库中检索相关信息，从而使LLM能够提供更准确、更具体、更少幻觉的回答。\n",
    "\n",
    "# 典型的RAG应用程序包含两个主要组件：\n",
    "\n",
    "# 索引（Indexing）: 这是一个用于从数据源摄取数据并对其进行索引的管道。这个过程通常是离线进行的。\n",
    "\n",
    "# 检索和生成（Retrieval and Generation）: 这是实际的RAG链，它在运行时接收用户查询，从索引中检索相关数据，然后将这些数据传递给语言模型以生成答案。\n",
    "\n",
    "# 从原始数据到答案的完整序列通常包括以下步骤：\n",
    "\n",
    "# 索引阶段：\n",
    "\n",
    "# 加载（Load）: 使用Document Loaders加载数据。\n",
    "\n",
    "# 分割（Split）: 使用Text Splitters将大型文档分割成更小的块，以便于搜索和适应模型的上下文窗口。\n",
    "\n",
    "# 存储（Store）: 将分割后的文本块存储并索引起来，通常使用VectorStore和Embeddings模型。\n",
    "\n",
    "# 检索和生成阶段：\n",
    "\n",
    "# 检索（Retrieve）: 根据用户输入，使用Retriever从存储中检索相关的文本块。\n",
    "\n",
    "# 生成（Generate）: ChatModel / LLM结合检索到的数据和原始问题，通过一个提示（Prompt）来生成答案。\n",
    "\n",
    "# 我们将使用LangGraph作为编排框架来实现检索和生成步骤。\n",
    "\n",
    "# 环境设置 (Setup)\n",
    "# 在开始之前，我们需要安装一些必要的库并配置LangSmith（可选，但强烈推荐用于跟踪应用）。\n",
    "\n",
    "# Jupyter Notebook: 建议在Jupyter Notebook环境中运行本教程，以获得更好的交互体验。如果您尚未安装，请参考Jupyter官方文档进行安装。\n",
    "\n",
    "# 安装依赖:\n",
    "# 打开您的PowerShell命令行，然后执行以下pip安装命令。\n",
    "\n",
    "# pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "# pip install -qU \"langchain[google-genai]\"\n",
    "# pip install -qU langchain-google-genai\n",
    "# pip install -qU langchain-chroma\n",
    "# 请注意：\n",
    "\n",
    "# --quiet 或 -q 参数是为了在安装过程中减少输出信息。\n",
    "\n",
    "# -U 参数是为了确保安装的库是最新版本。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b99f28-7f62-444e-ad3a-27931cd8a0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5889ea1a-a30b-4e6e-a58d-1d892c3ced27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 配置 (可选但推荐):\n",
    "# LangSmith 是 LangChain 应用程序的调试、测试、评估和监控平台。它能帮助我们追踪复杂应用中的LLM调用。\n",
    "\n",
    "# 首先，您需要注册 LangSmith 并获取 LANGSMITH_API_KEY。\n",
    "# 然后，在您的PowerShell环境中设置环境变量：\n",
    "# 请将 `YOUR_LANGSMITH_API_KEY` 替换为您自己的LangSmith API Key。\n",
    "\n",
    "# $env:LANGSMITH_TRACING=\"true\"\n",
    "# $env:LANGSMITH_API_KEY=\"YOUR_LANGSMITH_API_KEY\"\n",
    "\n",
    "\n",
    "# 或者，如果您在Jupyter Notebook中运行，可以使用Python代码设置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16960cc8-b9e1-4e8e-beba-77f88ef3d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "# 如果您已经在PowerShell中设置了LANGSMITH_API_KEY，这里可以省略，\n",
    "# 否则，您可以通过getpass输入或直接赋值\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API Key: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4141e35-e292-45f4-bd9f-3a0ee5fe2719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 组件选择:\n",
    "# 我们将从LangChain的集成套件中选择三个核心组件：\n",
    "\n",
    "# 选择聊天模型 (Chat Model):\n",
    "# 我们将使用Google Gemini模型。您需要一个Google Gemini API Key。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "662ce6dd-f7ba-4d73-8c86-393945110903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "聊天模型 (LLM) 已初始化。\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 确保GOOGLE_API_KEY环境变量已设置\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "# 初始化聊天模型\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
    "print(\"聊天模型 (LLM) 已初始化。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c6dd0d-2d9c-4c5d-a2b8-287218d69e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择嵌入模型 (Embeddings Model):\n",
    "# 我们将使用Google Generative AI Embeddings。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6147563-cfd0-488f-87b2-3d516c43bdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入模型 (Embeddings Model) 已初始化。\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# 确保GOOGLE_API_KEY环境变量已设置\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "# 初始化嵌入模型\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "print(\"嵌入模型 (Embeddings Model) 已初始化。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d287860a-c920-4304-8576-1a8e209ad2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择向量存储 (Vector Store):\n",
    "# 我们将使用Chroma作为向量存储，它是一个轻量级的本地向量数据库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18f5dcf3-510f-4f89-ac85-3b82913f7ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量存储 (Vector Store) 已初始化。\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# 初始化向量存储\n",
    "# collection_name 是存储文档的集合名称\n",
    "# embedding_function 指定用于生成嵌入的函数\n",
    "# persist_directory 指定数据本地保存的路径，如果不需要持久化可以移除\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    ")\n",
    "print(\"向量存储 (Vector Store) 已初始化。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac99a3ba-ced4-4566-a68d-e2addccd3b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe8058-64c4-410e-9439-f9c4b597b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在本指南中，我们将构建一个应用程序，该应用程序可以回答关于Lilian Weng的博客文章“LLM Powered Autonomous Agents”的内容的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b124eb51-ea10-4d5b-8d82-a8ac1e873950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 索引 (Indexing)\n",
    "# 这个阶段负责准备我们的数据，使其可以被检索。\n",
    "\n",
    "# 1.1. 加载文档 (Loading documents)\n",
    "\n",
    "# 我们首先需要加载博客文章的内容。DocumentLoaders是用于从各种源加载数据并返回Document对象列表的工具。\n",
    "\n",
    "# 在这个例子中，我们使用WebBaseLoader来加载网页内容。它使用urllib加载HTML，并使用BeautifulSoup解析HTML到文本。通过bs_kwargs参数，我们可以自定义BeautifulSoup的解析行为。这里，我们只关注具有\"post-content\", \"post-title\", 或 \"post-header\" 类的HTML标签，以过滤掉不相关的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "385c6208-3734-4bcf-8020-a68bc72b50b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载的文档数量: 1\n",
      "总字符数: 43047\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 仅保留文章标题、头部和内容的HTML标签\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer}, # 将BeautifulSoup的解析参数传递给bs_kwargs\n",
    ")\n",
    "docs = loader.load() # 加载文档\n",
    "\n",
    "print(f\"加载的文档数量: {len(docs)}\")\n",
    "# 验证加载的文档数量是否为1（因为我们只加载了一个网页）\n",
    "assert len(docs) == 1\n",
    "# 打印文档内容的前500个字符\n",
    "print(f\"总字符数: {len(docs[0].page_content)}\")\n",
    "print(docs[0].page_content[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4e7a399-5312-40c6-86d7-afab94b8f181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DocumentLoader: 从源加载数据并返回Document对象列表的工具。\n",
    "\n",
    "# Document: LangChain中的基本数据结构，包含page_content（文本内容）和metadata（关于文档的附加信息）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e81a529c-627c-4551-8a04-622f421c1b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2. 分割文档 (Splitting documents)\n",
    "\n",
    "# 我们加载的文档（超过42k字符）对于许多模型的上下文窗口来说太长了。即使模型能够处理这么长的文本，在非常长的输入中查找信息也可能很困难。\n",
    "\n",
    "# 为了解决这个问题，我们将把Document分割成更小的文本块（chunks），以便进行嵌入和向量存储。这将有助于我们在运行时只检索博客文章中最相关的部分。\n",
    "\n",
    "# 我们使用RecursiveCharacterTextSplitter，它会递归地使用常见的分隔符（如换行符）分割文档，直到每个文本块达到适当的大小。这是通用文本用例推荐的文本分割器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a1623a-af57-43d5-a860-b05d47fd872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "博客文章被分割成 63 个子文档。\n",
      "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 8}\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,          # 每个文本块的最大字符数\n",
    "    chunk_overlap=200,        # 文本块之间的重叠字符数，有助于保持上下文\n",
    "    add_start_index=True,     # 跟踪原始文档中的起始索引\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs) # 分割文档\n",
    "\n",
    "print(f\"博客文章被分割成 {len(all_splits)} 个子文档。\")\n",
    "# 打印第一个文本块的元数据，查看起始索引信息\n",
    "print(all_splits[0].metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8457e966-7798-4599-9834-49f452de67e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextSplitter: 将Document列表分割成更小文本块的工具。\n",
    "\n",
    "# chunk_size: 限制每个文本块的大小，以适应LLM的上下文窗口。\n",
    "\n",
    "# chunk_overlap: 确保文本块之间有重叠，以避免在分割点丢失重要上下文。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e0a00dd-b76a-48a5-874f-9a257822eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3. 存储文档 (Storing documents)\n",
    "\n",
    "# 现在我们需要索引这66个文本块，以便在运行时可以搜索它们。我们的方法是嵌入每个文档分割的内容，并将这些嵌入插入到向量存储中。给定一个输入查询，我们就可以使用向量搜索来检索相关文档。\n",
    "\n",
    "# 我们可以使用在设置阶段选择的向量存储和嵌入模型，通过一个命令嵌入并存储所有文档分割。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45ebe339-4ec1-4d79-a24c-760ffab022ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在将 63 个文本块添加到向量存储...\n",
      "文档添加完成。前3个文档的ID：\n",
      "['1dce4ef9-8f1e-4710-9d12-024f5d70c9c1', '0f1a44d6-a5d5-4c73-908e-b3c9e24d3d0b', 'dffdd592-3a15-4524-8a4b-517f00cfc9ab']\n"
     ]
    }
   ],
   "source": [
    "# 确保 vector_store 和 all_splits 变量在此处可用\n",
    "# 如果您是独立运行此部分，请确保之前已运行过初始化和加载/分割文档的代码\n",
    "\n",
    "print(f\"正在将 {len(all_splits)} 个文本块添加到向量存储...\")\n",
    "document_ids = vector_store.add_documents(documents=all_splits) # 添加文档到向量存储\n",
    "\n",
    "print(\"文档添加完成。前3个文档的ID：\")\n",
    "print(document_ids[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89e27455-63e9-4b54-aeca-dc924d9a5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings: 用于将文本转换为数值向量（嵌入）的模型包装器。这些向量捕获了文本的语义含义。\n",
    "\n",
    "# VectorStore: 向量数据库的包装器，用于存储和查询嵌入。它允许我们通过计算查询嵌入与存储嵌入之间的相似度来执行语义搜索。\n",
    "\n",
    "# 至此，索引部分完成。我们现在拥有一个可查询的向量存储，其中包含我们博客文章的块状内容。给定用户问题，我们应该能够返回回答该问题所需的博客文章片段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ad0d15a-dd25-4339-93d1-81fedf5350a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 检索和生成 (Retrieval and Generation)\n",
    "# 现在，让我们编写实际的应用程序逻辑。我们希望创建一个简单的应用程序，它接收用户问题，搜索与该问题相关的文档，将检索到的文档和原始问题传递给模型，然后返回一个答案。\n",
    "\n",
    "# 2.1. 提示 (Prompt)\n",
    "\n",
    "# 我们将使用在LangChain提示中心（prompt hub）中预定义的RAG提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de6d37ea-cee4-4e88-aa69-a95ba9894fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG提示模板内容示例:\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 从LangChain Hub拉取RAG提示模板\n",
    "# 注意：对于非美国LangSmith端点，您可能需要在hub.pull中指定api_url=\"https://api.smith.langchain.com\"。\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# 演示提示模板的结构\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(\"RAG提示模板内容示例:\")\n",
    "print(example_messages[0].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f07401e-8af9-4781-8d9c-22f27e214d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个提示模板指导LLM作为一个问答助手，利用提供的上下文来回答问题，并要求回答简洁。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da57a43d-c212-44fb-b0fc-92237817210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2. LangGraph 概览 (LangGraph Overview)\n",
    "\n",
    "# 我们将使用LangGraph将检索和生成步骤连接成一个单一的应用程序。LangGraph是一个用于构建多步LLM应用程序的库，它提供了以下好处：\n",
    "\n",
    "# 可以一次定义应用程序逻辑，并自动支持多种调用模式（流式、异步、批处理）。\n",
    "\n",
    "# 通过LangGraph平台简化部署。\n",
    "\n",
    "# LangSmith将自动追踪应用程序的步骤。\n",
    "\n",
    "# 可以轻松地向应用程序添加关键功能，例如持久化和人工审核。\n",
    "\n",
    "# 要使用LangGraph，我们需要定义三件事：\n",
    "\n",
    "# 应用程序的状态 (State)：应用程序的输入、步骤之间传递的数据和应用程序的输出。\n",
    "\n",
    "# 应用程序的节点 (Nodes)：应用程序的各个步骤（函数）。\n",
    "\n",
    "# 应用程序的“控制流” (Control Flow)：步骤的执行顺序。\n",
    "\n",
    "# 2.3. 状态定义 (State Definition)\n",
    "\n",
    "# 应用程序的状态控制着输入到应用程序、在步骤之间传输以及由应用程序输出的数据。它通常是一个TypedDict，也可以是Pydantic BaseModel。\n",
    "\n",
    "# 对于一个简单的RAG应用程序，我们可以只跟踪输入问题、检索到的上下文和生成的答案："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "589f84d0-83bb-4e87-9b07-d166af4fae7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "应用程序状态 (State) 已定义。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# 定义应用程序的状态\n",
    "# question: 用户提出的问题\n",
    "# context: 检索到的相关文档列表\n",
    "# answer: LLM生成的答案\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "print(\"应用程序状态 (State) 已定义。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "610fb0cc-9330-430c-938d-421dee18b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4. 节点 (应用程序步骤) (Nodes (application steps))\n",
    "\n",
    "# 我们从一个包含两个简单步骤的序列开始：检索和生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f4720d5-9d12-4e11-8f8c-16b33a35a619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索 (retrieve) 和 生成 (generate) 节点函数已定义。\n"
     ]
    }
   ],
   "source": [
    "# 确保 vector_store, prompt, llm 和 State 变量在此处可用\n",
    "\n",
    "def retrieve(state: State):\n",
    "    \"\"\"\n",
    "    检索步骤：根据问题从向量存储中检索相关文档。\n",
    "    输入: state (包含 'question')\n",
    "    输出: 包含 'context' (检索到的文档列表) 的字典\n",
    "    \"\"\"\n",
    "    print(f\"执行检索节点：正在为问题 '{state['question']}' 检索文档...\")\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    print(f\"检索节点完成：检索到 {len(retrieved_docs)} 篇文档。\")\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    \"\"\"\n",
    "    生成步骤：使用检索到的文档和问题生成答案。\n",
    "    输入: state (包含 'question' 和 'context')\n",
    "    输出: 包含 'answer' (LLM生成的答案) 的字典\n",
    "    \"\"\"\n",
    "    print(\"执行生成节点：正在生成答案...\")\n",
    "    # 将检索到的文档内容合并成一个字符串，作为LLM的上下文\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    # 使用提示模板和LLM生成答案\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    print(\"生成节点完成：答案已生成。\")\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "print(\"检索 (retrieve) 和 生成 (generate) 节点函数已定义。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "440fa656-6741-41b8-a901-66dab90f6815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们的检索步骤简单地使用输入问题执行相似性搜索，而生成步骤将检索到的上下文和原始问题格式化为聊天模型的提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7c691c1-e803-4cef-a207-93752a5f003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5. 控制流 (Control flow)\n",
    "\n",
    "# 最后，我们将应用程序编译成一个单一的图对象。在这个例子中，我们只是将检索和生成步骤连接成一个单一的序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3597dbd2-729a-47ff-bae3-16d217241575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph应用程序控制流已定义并编译完成。\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "# 创建一个StateGraph实例，并指定状态类型\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 添加序列：定义了retrieve和generate两个节点的执行顺序\n",
    "graph_builder.add_sequence([retrieve, generate])\n",
    "\n",
    "# 定义图的起始点：从START节点开始，直接进入retrieve节点\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "\n",
    "# 编译图，生成可执行的应用程序\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "print(\"LangGraph应用程序控制流已定义并编译完成。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fccb1b3-429e-4d3b-bfac-de34c9b4e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遇到的 TypeError: Cannot create a consistent method resolution order (MRO) for bases ABC, Generic 错误是一个典型的Python多重继承问题，尤其在处理抽象基类（ABC）和泛型（Generic）时容易出现。\n",
    "\n",
    "# 错误分析\n",
    "# 错误类型: TypeError\n",
    "\n",
    "# 错误信息: Cannot create a consistent method resolution order (MRO) for bases ABC, Generic\n",
    "\n",
    "# 发生位置: 错误发生在您 Jupyter Notebook 的 In[28] 单元格，当执行 from langgraph.graph import START, StateGraph 这一行时。\n",
    "\n",
    "# 深层原因: 堆栈跟踪显示，这个错误源自 langgraph 内部的代码，具体在 langgraph/pregel/protocol.py 文件的 PregelProtocol 类定义中。该类尝试同时继承 Runnable、Generic 和 ABC。\n",
    "\n",
    "# ABC (Abstract Base Class) 是Python中用于定义抽象类的模块。\n",
    "\n",
    "# Generic 是 typing 模块中用于创建泛型类的。\n",
    "\n",
    "# Runnable 是 langchain_core 中的一个基类。\n",
    "\n",
    "# Python在处理多重继承时会使用C3线性化算法来确定方法解析顺序（MRO）。当多个基类（特别是像 ABC 和 Generic 这样有特殊元类的类）以某种方式组合时，有时会创建出无法解析的MRO，导致Python无法确定方法的查找顺序，从而抛出此 TypeError。\n",
    "\n",
    "# 这通常不是您编写的代码逻辑错误，而是 langgraph 库或其依赖项（如 langchain_core、typing 模块）的版本之间存在不兼容性，或者 langgraph 内部在处理多重继承时存在一个边缘情况问题。\n",
    "\n",
    "# 解决方案\n",
    "# 由于错误发生在库的内部，您需要尝试更新或调整库的版本来解决这个问题。以下是您可以尝试的步骤：\n",
    "\n",
    "# 方案一：更新所有相关库到最新版本（推荐）\n",
    "# 最常见的原因是库版本不匹配。请尝试更新所有相关的 LangChain 和 LangGraph 库到最新版本。\n",
    "\n",
    "# 打开 PowerShell 或您的终端。\n",
    "\n",
    "# 执行以下命令来更新所有相关的库：\n",
    "\n",
    "# pip install --upgrade langchain langchain-core langgraph langchain-text-splitters langchain-community langchain-chroma langchain-google-genai bs4 typing-extensions\n",
    "\n",
    "# --upgrade 会确保安装最新版本。\n",
    "\n",
    "# 添加了 bs4 和 typing-extensions，因为它们是您代码中直接使用的或 langgraph 内部可能依赖的。\n",
    "\n",
    "# 更新完成后，重新启动 Jupyter Notebook 内核，并重新运行所有单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ac1ff72-6eb3-4467-bbbe-4187b9c6ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph还内置了用于可视化应用程序控制流的实用程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3457b8e3-0980-4872-b73f-aedf85e7123e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# 绘制Mermaid图并显示\n",
    "# 注意：这需要在您的环境中安装Graphviz或类似的工具来渲染图像。\n",
    "# 如果您在JupyterLab中遇到问题，可能需要安装'python-graphviz'和'graphviz'系统包。\n",
    "# 例如：pip install graphviz 和 sudo apt-get install graphviz (Linux) 或 brew install graphviz (macOS)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd9850f0-f1b9-4097-8ef2-847250985af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 您是否需要使用LangGraph？对于简单的链，您不一定需要LangGraph。然而，当您的应用程序变得更复杂，需要多步骤决策、循环或更复杂的流程时，LangGraph的强大编排能力将变得非常有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb0a28-e76d-47f2-b8b4-100b05a9cdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63fd848e-39da-4eca-a5d3-3bdbee8b7101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6. 使用 (Usage)\n",
    "\n",
    "# 让我们测试一下我们的应用程序！LangGraph支持多种调用模式，包括同步（sync）、异步（async）和流式（streaming）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83a209df-0c2a-46a5-bfee-12c5a553d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同步调用 (Invoke):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab3aa749-ff7a-49c3-adfc-3da5e0ad60ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在同步调用应用程序，问题: 'What is Task Decomposition?'\n",
      "执行检索节点：正在为问题 'What is Task Decomposition?' 检索文档...\n",
      "检索节点完成：检索到 4 篇文档。\n",
      "执行生成节点：正在生成答案...\n",
      "生成节点完成：答案已生成。\n",
      "\n",
      "--- 同步调用结果 ---\n",
      "Context: [Document(id='493c7e21-f9bd-4b09-b583-f731ae043fb2', metadata={'start_index': 2578, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='554a505e-9403-498f-a510-ecd7e05b4c2b', metadata={'start_index': 2578, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='2c32d6a1-1391-4e1b-8c71-8efb95bdf2f7', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='5558df10-4b7a-4b03-8a1a-4062e32344b1', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#')]\n",
      "\n",
      "\n",
      "Answer: Task decomposition is the process of breaking down a complex task into smaller, more manageable steps or subgoals. This can be achieved by an LLM with simple prompting, by using task-specific instructions, or through human input. Another approach, LLM+P, outsources long-horizon planning to an external classical planner using PDDL.\n"
     ]
    }
   ],
   "source": [
    "# 确保 graph 变量在此处可用\n",
    "test_question = \"What is Task Decomposition?\"\n",
    "print(f\"正在同步调用应用程序，问题: '{test_question}'\")\n",
    "result = graph.invoke({\"question\": test_question})\n",
    "\n",
    "print(\"\\n--- 同步调用结果 ---\")\n",
    "print(f\"Context: {result['context']}\\n\\n\")\n",
    "print(f\"Answer: {result['answer']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c38af6f-ecfb-4dd2-8e0d-fce35ae44092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8ba5628-ea58-4a50-a22e-14f2d6c401c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 流式步骤 (Stream steps):流式模式允许您在每个步骤完成时获取更新，这对于长时间运行的应用程序很有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9d52ad8-affa-4ba9-a6cd-bfe2db4d610a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在流式获取应用程序步骤更新，问题: 'What is Task Decomposition?'\n",
      "执行检索节点：正在为问题 'What is Task Decomposition?' 检索文档...\n",
      "检索节点完成：检索到 4 篇文档。\n",
      "{'retrieve': {'context': [Document(id='493c7e21-f9bd-4b09-b583-f731ae043fb2', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='554a505e-9403-498f-a510-ecd7e05b4c2b', metadata={'start_index': 2578, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='2c32d6a1-1391-4e1b-8c71-8efb95bdf2f7', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='5558df10-4b7a-4b03-8a1a-4062e32344b1', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "执行生成节点：正在生成答案...\n",
      "生成节点完成：答案已生成。\n",
      "{'generate': {'answer': 'Task decomposition is a process that breaks down a task into smaller, more manageable parts or subgoals. This can be achieved by an LLM using simple prompts like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\". Alternatively, it can be done through task-specific instructions or human input.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 确保 graph 变量在此处可用\n",
    "test_question = \"What is Task Decomposition?\"\n",
    "print(f\"正在流式获取应用程序步骤更新，问题: '{test_question}'\")\n",
    "for step in graph.stream(\n",
    "    {\"question\": test_question}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58101594-9480-43c3-83ce-95eca4d4d6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a40258b2-1e1a-40a1-ab3d-b4e75d312d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 流式令牌 (Stream tokens):流式令牌模式允许您在LLM生成答案时逐个获取令牌（token），这对于实时用户体验非常有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40883aa7-f4ca-4cfa-ac86-2b0c5f7c2610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在流式获取LLM生成的令牌，问题: 'What is Task Decomposition?'\n",
      "执行检索节点：正在为问题 'What is Task Decomposition?' 检索文档...\n",
      "检索节点完成：检索到 4 篇文档。\n",
      "执行生成节点：正在生成答案...\n",
      "Task decomposition is a process that breaks down a complex task into smaller, manageable parts or subgoals. This can be achieved through various methods, including using a Large Language Model (LLM) with simple prompts, employing task-specific instructions, or incorporating| human inputs. An alternative approach, LLM+P, involves outsourcing long-horizon planning to an external classical planner using PDDL as an interface.|生成节点完成：答案已生成。\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 确保 graph 变量在此处可用\n",
    "test_question = \"What is Task Decomposition?\"\n",
    "print(f\"正在流式获取LLM生成的令牌，问题: '{test_question}'\")\n",
    "for message, metadata in graph.stream(\n",
    "    {\"question\": test_question}, stream_mode=\"messages\"\n",
    "):\n",
    "    # message.content 包含生成的文本，end='|' 只是为了在每个令牌后添加分隔符\n",
    "    print(message.content, end=\"|\")\n",
    "print(\"\\n\") # 打印一个换行符，以便下一个输出不会紧跟在令牌之后\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e0fb448-3008-43b5-9ea1-9af5e7256864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回来源 (Returning sources)通过将检索到的上下文存储在图的状态中，我们可以在状态的\"context\"字段中获取模型生成答案的来源文档。\n",
    "\n",
    "# 深入了解：\n",
    "\n",
    "# Chat models: 接收一系列消息并返回一个消息。\n",
    "\n",
    "# PromptTemplate: 用于构建结构化提示的工具，可以动态插入变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb157106-44e7-4f22-b777-8d3227f300f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0de7c7aa-f221-4378-8887-523f480e8413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.7. 自定义提示 (Customizing the prompt)\n",
    "\n",
    "# 如上所示，我们可以从提示中心加载提示。提示也可以轻松自定义。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a00ae894-0929-4f71-b365-14d0d7676fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自定义RAG提示模板内容示例:\n",
      "使用以下上下文片段来回答最后的问题。\n",
      "如果你不知道答案，就说你不知道，不要试图编造答案。\n",
      "最多使用三句话，并尽可能保持答案简洁。\n",
      "在答案的末尾总是说“感谢您的提问！”。\n",
      "\n",
      "(一些上下文)\n",
      "\n",
      "问题: (一个问题)\n",
      "\n",
      "有用的答案:\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"使用以下上下文片段来回答最后的问题。\n",
    "如果你不知道答案，就说你不知道，不要试图编造答案。\n",
    "最多使用三句话，并尽可能保持答案简洁。\n",
    "在答案的末尾总是说“感谢您的提问！”。\n",
    "\n",
    "{context}\n",
    "\n",
    "问题: {question}\n",
    "\n",
    "有用的答案:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 打印自定义提示的示例\n",
    "print(\"自定义RAG提示模板内容示例:\")\n",
    "print(custom_rag_prompt.invoke({\"context\": \"(一些上下文)\", \"question\": \"(一个问题)\"}).text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6817dcb2-1881-43bc-979b-1f4f4e64f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 您可以根据需要修改template字符串来定制提示的行为和语气。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda2e820-793e-4b3c-8272-8c5246e3868f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0600648-d0b4-48d5-a84b-5cfffd2d0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查询分析 (Query analysis)\n",
    "# 到目前为止，我们是使用原始输入查询执行检索的。然而，让模型生成用于检索的查询有一些优点。例如：\n",
    "\n",
    "# 除了语义搜索之外，我们还可以构建结构化过滤器（例如，“查找自2020年以来的文档”）；\n",
    "\n",
    "# 模型可以将用户查询（可能是多方面的或包含不相关语言）重写为更有效的搜索查询。\n",
    "\n",
    "# 查询分析利用模型从原始用户输入转换或构建优化的搜索查询。我们可以轻松地将查询分析步骤合并到我们的应用程序中。为了说明目的，让我们向向量存储中的文档添加一些元数据。我们将向文档添加一些（人为设计的）部分，以后可以根据这些部分进行过滤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e09d0fb4-3caf-4e0c-b7e7-32809fcd9390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 添加元数据\n",
    "\n",
    "# 首先，我们为每个文档块添加一个\"section\"元数据字段，将其分为“开头”、“中间”和“结尾”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b81ea18b-40d5-4f9a-a5cd-6a8ab2e8b313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在为文档添加 'section' 元数据...\n",
      "元数据添加完成。\n",
      "\n",
      "第一个文档的元数据示例:\n",
      "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 8, 'section': 'beginning'}\n"
     ]
    }
   ],
   "source": [
    "# 确保 all_splits 变量在此处可用\n",
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3 # 将文档大致分为三等份\n",
    "\n",
    "print(\"正在为文档添加 'section' 元数据...\")\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "print(\"元数据添加完成。\")\n",
    "\n",
    "# 打印第一个文档的元数据，查看新增的 'section' 字段\n",
    "print(\"\\n第一个文档的元数据示例:\")\n",
    "print(all_splits[0].metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50c3f816-7c8e-40c6-ab17-53a2f47195ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 更新向量存储\n",
    "\n",
    "# 接下来，我们需要更新向量存储中的文档。我们将为此使用一个简单的InMemoryVectorStore，因为它支持我们稍后将使用的特定功能（即元数据过滤）。请参考您所选向量存储的集成文档，了解其相关功能。\n",
    "\n",
    "# 注意： 如果您之前使用了Chroma并将其持久化到磁盘，为了演示InMemoryVectorStore的过滤功能，我们在这里创建一个新的内存中向量存储。在实际应用中，您可能会选择一个支持元数据过滤的持久化向量存储。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cae77bcb-cdc9-4bb4-85a7-68be050cd422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在创建新的 InMemoryVectorStore 并重新添加文档...\n",
      "InMemoryVectorStore 已创建并文档已添加。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "print(\"正在创建新的 InMemoryVectorStore 并重新添加文档...\")\n",
    "# 创建一个新的InMemoryVectorStore实例\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "# 将带有新元数据的文档重新添加到新的向量存储中\n",
    "_ = vector_store.add_documents(all_splits)\n",
    "print(\"InMemoryVectorStore 已创建并文档已添加。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afbf93f1-f535-4344-8f43-00c99fcadd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 定义搜索查询Schema\n",
    "\n",
    "# 接下来，我们为搜索查询定义一个Schema。我们将为此目的使用结构化输出。这里我们将查询定义为包含一个字符串查询和一个文档部分（“开头”、“中间”或“结尾”），但您可以根据需要进行定义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15a702b2-c496-4a7e-a6b1-3ec221c9ba22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "搜索查询Schema (Search TypedDict) 已定义。\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "# 定义一个结构化的搜索查询Schema\n",
    "class Search(TypedDict):\n",
    "    \"\"\"搜索查询。\"\"\"\n",
    "    query: Annotated[str, ..., \"要运行的搜索查询。\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"], # section字段只能是这三个值之一\n",
    "        ...,\n",
    "        \"要查询的文档部分。\",\n",
    "    ]\n",
    "\n",
    "print(\"搜索查询Schema (Search TypedDict) 已定义。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44473a73-d5d8-44eb-8056-0903f7c960d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 更新LangGraph应用程序\n",
    "\n",
    "# 最后，我们向LangGraph应用程序添加一个步骤，用于从用户的原始输入生成结构化查询。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04145880-9bff-4bd7-ae14-68d26dd01507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在重新编译LangGraph应用程序，包含查询分析步骤...\n",
      "LangGraph应用程序重新编译完成。\n"
     ]
    }
   ],
   "source": [
    "# 确保 llm, prompt, vector_store, Search 和 Document 变量在此处可用\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "# 更新应用程序的状态，包含 'query' 字段\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search # 新增的结构化查询字段\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    \"\"\"\n",
    "    查询分析步骤：使用LLM将用户问题转换为结构化搜索查询。\n",
    "    输入: state (包含 'question')\n",
    "    输出: 包含 'query' (结构化搜索查询) 的字典\n",
    "    \"\"\"\n",
    "    print(f\"执行查询分析节点：正在分析问题 '{state['question']}'...\")\n",
    "    # 使用with_structured_output方法，让LLM按照Search TypedDict的结构生成输出\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    print(f\"查询分析节点完成：生成的结构化查询为 {query}\")\n",
    "    return {\"query\": query}\n",
    "\n",
    "def retrieve(state: State):\n",
    "    \"\"\"\n",
    "    检索步骤：根据结构化查询（包含查询字符串和section过滤器）从向量存储中检索相关文档。\n",
    "    输入: state (包含 'query')\n",
    "    输出: 包含 'context' (检索到的文档列表) 的字典\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "    print(f\"执行检索节点：正在使用查询 '{query['query']}' 和 section '{query['section']}' 检索文档...\")\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        # 使用lambda函数作为过滤器，只检索metadata中section与query['section']匹配的文档\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    print(f\"检索节点完成：检索到 {len(retrieved_docs)} 篇文档。\")\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    \"\"\"\n",
    "    生成步骤：使用检索到的文档和原始问题生成答案。\n",
    "    输入: state (包含 'question' 和 'context')\n",
    "    输出: 包含 'answer' (LLM生成的答案) 的字典\n",
    "    \"\"\"\n",
    "    print(\"执行生成节点：正在生成答案...\")\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    print(\"生成节点完成：答案已生成。\")\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# 重新构建和编译图，包含新的 analyze_query 步骤\n",
    "print(\"正在重新编译LangGraph应用程序，包含查询分析步骤...\")\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\") # 起始点现在连接到 analyze_query\n",
    "graph = graph_builder.compile()\n",
    "print(\"LangGraph应用程序重新编译完成。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59f9c861-b968-4aa3-8dd7-5df8977ea7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新绘制的LangGraph流程图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5abcb472-b4a9-45b6-b76b-12316ad9bc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1036582-52f7-448d-8cff-282aca30003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试查询分析功能：\n",
    "\n",
    "# 我们可以通过专门要求从文章末尾获取上下文来测试我们的实现。请注意，模型在答案中包含了不同的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2bc6432b-609e-4ed0-aa1a-d4cf46d7461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在流式获取应用程序步骤更新，问题: 'What does the end of the post say about Task Decomposition?'\n",
      "执行查询分析节点：正在分析问题 'What does the end of the post say about Task Decomposition?'...\n",
      "查询分析节点完成：生成的结构化查询为 {'section': 'end', 'query': 'Task Decomposition'}\n",
      "{'analyze_query': {'query': {'section': 'end', 'query': 'Task Decomposition'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "执行检索节点：正在使用查询 'Task Decomposition' 和 section 'end' 检索文档...\n",
      "检索节点完成：检索到 4 篇文档。\n",
      "{'retrieve': {'context': [Document(id='25eec2d5-9ea3-49c6-bd77-12cdb04830fa', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 38621, 'section': 'end'}, page_content='are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"'), Document(id='d02777af-8d79-481a-9ad8-21869ef8d7bb', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 34990, 'section': 'end'}, page_content='Conversatin samples:\\n[\\n  {\\n    \"role\": \"system\",'), Document(id='54b4d047-f037-4e0c-a402-ba1c3cc0c759', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 37831, 'section': 'end'}, page_content='\"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully'), Document(id='022c42b0-2b64-4f58-ae5b-7a0aa2b8846f', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39002, 'section': 'end'}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "执行生成节点：正在生成答案...\n",
      "生成节点完成：答案已生成。\n",
      "{'generate': {'answer': 'The provided context does not contain any information about \"Task Decomposition.\" Therefore, it does not say anything about it at the end of the post or anywhere else.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 确保 graph 变量在此处可用\n",
    "test_question_with_filter = \"What does the end of the post say about Task Decomposition?\"\n",
    "print(f\"正在流式获取应用程序步骤更新，问题: '{test_question_with_filter}'\")\n",
    "for step in graph.stream(\n",
    "    {\"question\": test_question_with_filter},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d19e51c7-d60b-45c6-b430-a8432356289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在流式步骤和LangSmith跟踪中，我们现在可以观察到被馈送到检索步骤的结构化查询。\n",
    "\n",
    "# 查询分析是一个丰富的问题，有广泛的方法。请参阅相关的操作指南以获取更多示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b81b71b-a931-4946-a7f5-5d0025b8dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下一步 (Next steps)\n",
    "# 我们已经涵盖了构建一个基于数据的基本Q&A应用程序的步骤：\n",
    "\n",
    "# 使用Document Loader加载数据。\n",
    "\n",
    "# 使用Text Splitter对索引数据进行分块，使其更容易被模型使用。\n",
    "\n",
    "# 嵌入数据并将数据存储在VectorStore中。\n",
    "\n",
    "# 响应传入问题，检索先前存储的文本块。\n",
    "\n",
    "# 使用检索到的文本块作为上下文生成答案。\n",
    "\n",
    "# 增加了查询分析功能，使LLM能够生成结构化查询，从而实现更精确的检索。\n",
    "\n",
    "# 在教程的第二部分，我们将扩展这里的实现，以适应对话式交互和多步检索过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389438ce-dca8-4d14-9ff7-bfbc31d89a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784b9729-4f7d-4011-8a79-522ac24bdd11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39620bbd-b3e1-4df7-9165-d4fc79836094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c6443-3419-4743-bfcc-5b5e7bfc2c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca420d04-4a20-4ecd-afd8-3518c681bab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ce30c8-c9c1-4563-88f4-1e4567579336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51436a98-a93a-4548-82b9-d90fb179cd04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa466c57-b1a7-42cb-8480-1bbbf798785d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3be99-83de-4b9a-9a5a-422a4be36945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
