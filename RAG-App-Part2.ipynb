{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee02ec-2089-49be-ba33-9b4d0bbec070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 官方教程文档\n",
    "# https://python.langchain.com/docs/tutorials/qa_chat_history/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98487262-1e56-4faf-96ac-512dd20eb83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建RAG应用程序：第二部分\n",
    "# 在许多问答应用程序中，我们希望用户能够进行来回的对话，这意味着应用程序需要某种“记忆”来记住过去的问答，并具备将这些信息融入当前思考的逻辑。\n",
    "\n",
    "# 本教程是多部分教程的第二部分：\n",
    "\n",
    "# 第一部分介绍了RAG并展示了一个最小实现。\n",
    "# 第二部分（本指南）将扩展实现，以适应对话式交互和多步检索过程。\n",
    "# 在这里，我们将重点放在添加整合历史消息的逻辑上，这涉及到聊天历史的管理。我们将涵盖两种方法：\n",
    "\n",
    "# 链（Chains）: 最多执行一个检索步骤。\n",
    "# 代理（Agents）: 赋予LLM自由裁量权，以执行多个检索步骤。\n",
    "# 注意: 这里介绍的方法利用了现代聊天模型的工具调用能力。\n",
    "\n",
    "# 对于外部知识源，我们将继续使用第一部分中Lilian Weng的博客文章“LLM Powered Autonomous Agents”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c1266-aa1b-457d-8ef2-e1c7e3898a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境设置 (Setup)\n",
    "# 在开始之前，我们需要安装一些必要的库并配置LangSmith（可选，但强烈推荐用于跟踪应用）。\n",
    "\n",
    "# 1.安装依赖:\n",
    "# 打开您的PowerShell命令行，然后执行以下pip安装命令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36626cf-7030-4441-833c-8d81584619f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph beautifulsoup4 langchain langchain-core\n",
    "# pip install -qU \"langchain[google-genai]\"\n",
    "# pip install -qU langchain-google-genai\n",
    "# pip install -qU langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bfcbe5-e3f1-42b0-a8c4-d37bfb8b7e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --quiet 或 -q 参数是为了在安装过程中减少输出信息。\n",
    "# -U 参数是为了确保安装的库是最新版本。\n",
    "# 我额外添加了 langchain 和 langchain-core，以确保所有LangChain相关的核心组件都更新到最新，避免潜在的MRO（Method Resolution Order）错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1b983-b477-4d0c-b4de-050f2391d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.LangSmith 配置 (可选但推荐):\n",
    "# LangSmith 是 LangChain 应用程序的调试、测试、评估和监控平台。它能帮助我们追踪复杂应用中的LLM调用。\n",
    "\n",
    "# 首先，您需要注册 LangSmith 并获取 LANGSMITH_API_KEY。然后，在您的PowerShell环境中设置环境变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5fe90e-785a-4fe9-9736-d18be2d65f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# $env:LANGSMITH_TRACING=\"true\"\n",
    "# $env:LANGSMITH_API_KEY=\"YOUR_LANGSMITH_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9be46-969c-4db5-92f4-fde597d2a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 请将 YOUR_LANGSMITH_API_KEY 替换为您自己的LangSmith API Key。\n",
    "\n",
    "# 或者，如果您在Jupyter Notebook中运行，可以使用Python代码设置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef03fb8c-d746-4521-a500-223f613fd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "# 如果您已经在PowerShell中设置了LANGSMITH_API_KEY，这里可以省略，\n",
    "# 否则，您可以通过getpass输入或直接赋值\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API Key: \")\n",
    "print(\"LangSmith 跟踪已启用。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c2d0e5-0a15-40e7-886b-dcc3dc872228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.组件选择:\n",
    "# 我们将从LangChain的集成套件中选择三个核心组件：\n",
    "\n",
    "# 选择聊天模型 (Chat Model):\n",
    "# 我们将使用Google Gemini模型。您需要一个Google Gemini API Key。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ed98af-1118-48f9-bbc3-a5901139e437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "聊天模型 (LLM) 已初始化。\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 确保GOOGLE_API_KEY环境变量已设置\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "# 初始化聊天模型。 \"gemini-2.5-flash\"是模型名称，model_provider指定提供者。\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
    "print(\"聊天模型 (LLM) 已初始化。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482e4f0-4e78-4727-8565-b3cebc4ed9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择嵌入模型 (Embeddings Model):\n",
    "# 我们将使用Google Generative AI Embeddings。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98419935-75fe-4bc7-881d-c73b8e0bc492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入模型 (Embeddings Model) 已初始化。\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# 确保GOOGLE_API_KEY环境变量已设置\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "# 初始化嵌入模型。 \"models/gemini-embedding-001\"是嵌入模型的名称。\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "print(\"嵌入模型 (Embeddings Model) 已初始化。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc527565-97f2-4bdc-943a-992218bcceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择向量存储 (Vector Store):\n",
    "# 我们将使用Chroma作为向量存储，它是一个轻量级的本地向量数据库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a5cdb1-7afa-4053-ae4d-98a4e820d264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量存储 (Vector Store) 已初始化。\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# 初始化向量存储\n",
    "# collection_name: 存储文档的集合名称，用于区分不同的数据集。\n",
    "# embedding_function: 指定用于生成文档嵌入的函数，这里使用我们之前初始化的embeddings模型。\n",
    "# persist_directory: 指定数据本地保存的路径。如果不需要持久化（例如每次运行都重新生成），可以移除此参数。\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    ")\n",
    "print(\"向量存储 (Vector Store) 已初始化。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab964766-f1cf-4eeb-85b4-c7a7b1a45c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e33496f-9e2c-40cc-bdd0-2fa856ee3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 链 (Chains)\n",
    "# 首先，让我们重新审视第一部分中构建的向量存储，它索引了Lilian Weng的博客文章“LLM Powered Autonomous Agents”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaba471c-6f6a-4fe9-8a66-669ff0846dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始加载文档...\n",
      "文档加载完成，共 1 篇文档。\n",
      "开始分割文档...\n",
      "文档分割完成，共 63 个文本块。\n",
      "开始索引文本块到向量存储...\n",
      "文本块索引完成。\n"
     ]
    }
   ],
   "source": [
    "import bs4 # 用于HTML解析\n",
    "from langchain import hub # 用于从LangChain Hub拉取提示模板\n",
    "from langchain_community.document_loaders import WebBaseLoader # 用于从网页加载文档\n",
    "from langchain_core.documents import Document # LangChain文档的基本数据结构\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter # 用于递归文本分割\n",
    "from typing_extensions import List, TypedDict # 用于类型提示\n",
    "\n",
    "# --- 1. 索引阶段：加载并分块博客内容 ---\n",
    "print(\"开始加载文档...\")\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",), # 指定要加载的网页URL\n",
    "    bs_kwargs=dict( # 传递给BeautifulSoup解析器的关键字参数\n",
    "        parse_only=bs4.SoupStrainer( # BeautifulSoup的过滤器，只解析指定class的HTML标签\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\") # 仅保留文章内容、标题和头部\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load() # 加载文档，返回Document对象列表\n",
    "print(f\"文档加载完成，共 {len(docs)} 篇文档。\")\n",
    "\n",
    "print(\"开始分割文档...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, # 每个文本块的最大字符数\n",
    "    chunk_overlap=200 # 文本块之间的重叠字符数，有助于保持上下文\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs) # 分割文档，返回更小的Document对象列表\n",
    "print(f\"文档分割完成，共 {len(all_splits)} 个文本块。\")\n",
    "\n",
    "# --- 2. 索引文本块到向量存储 ---\n",
    "print(\"开始索引文本块到向量存储...\")\n",
    "# 将所有分割后的文档添加到向量存储中。`_` 表示我们不关心返回的文档ID。\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "print(\"文本块索引完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8dc98-f24f-4c45-8f44-4c5905c60d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这段代码与第一部分中的索引部分完全相同，它确保我们的向量存储是最新的，包含了博客文章的嵌入式文本块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99afbe77-933d-462e-a279-547b5750b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在RAG教程的第一部分中，我们将用户输入、检索到的上下文和生成的答案表示为状态中的独立键。对话体验可以用一系列消息自然地表示。除了来自用户和助手的消息外，检索到的文档和其他工件可以通过工具消息（Tool Messages）合并到消息序列中。这促使我们使用消息序列来表示RAG应用程序的状态。具体来说，我们将有：\n",
    "\n",
    "# 用户输入作为 HumanMessage；\n",
    "# 向量存储查询作为带有工具调用的 AIMessage；\n",
    "# 检索到的文档作为 ToolMessage；\n",
    "# 最终响应作为 AIMessage。\n",
    "# LangGraph提供了一个内置的 MessagesState，以方便这种状态模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13fb2abf-e364-420d-8e90-4ebc5e8ea63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph 的 MessagesState 已初始化。\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "# StateGraph 是 LangGraph 中用于定义图的基类。\n",
    "# MessagesState 是 LangGraph 提供的一个特殊的状态类型，它将所有消息存储在一个列表中。\n",
    "# 每次更新状态时，新消息都会被追加到 'messages' 列表中，而不是覆盖现有状态。\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "print(\"LangGraph 的 MessagesState 已初始化。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d89ca-ce90-4dda-88e2-4dd8ea7b1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MessagesState 的使用极大地简化了对话历史的管理，因为它自动处理消息的追加，使我们能够轻松地构建具有记忆的对话应用程序。\n",
    "\n",
    "# 利用工具调用与检索步骤进行交互还有另一个好处，即检索的查询是由我们的模型生成的。这在对话设置中尤其重要，因为用户查询可能需要根据聊天历史进行上下文化。例如，考虑以下对话：\n",
    "\n",
    "# Human: “什么是任务分解？”\n",
    "# AI: “任务分解涉及将复杂任务分解为更小、更简单的步骤，使其更易于代理或模型管理。”\n",
    "# Human: “有哪些常见方法？”\n",
    "# 在这种情况下，模型可以生成一个查询，例如“任务分解的常见方法”。工具调用自然地促进了这一点。正如RAG教程的查询分析部分一样，这允许模型将用户查询重写为更有效的搜索查询。它还支持不涉及检索步骤的直接响应（例如，响应用户的通用问候）。\n",
    "\n",
    "# 现在，让我们将检索步骤转换为一个工具："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dcb239c-face-409f-8f56-de1c63d9ac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索工具 'retrieve' 已定义。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool # 导入 tool 装饰器，用于将函数转换为工具\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\") # 使用 @tool 装饰器将 retrieve 函数注册为一个工具\n",
    "def retrieve(query: str):\n",
    "    \"\"\"\n",
    "    检索工具：根据查询从向量存储中检索相关信息。\n",
    "    此工具被设计为由LLM调用，用于执行信息检索。\n",
    "\n",
    "    Args:\n",
    "        query (str): 用于搜索向量存储的查询字符串。\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, List[Document]]:\n",
    "            - str: 序列化后的文档内容，用于LLM生成答案。\n",
    "            - List[Document]: 原始的检索到的文档对象列表，作为工件存储在状态中。\n",
    "    \"\"\"\n",
    "    print(f\"--- 正在执行工具: retrieve, 查询: '{query}' ---\")\n",
    "    # 从向量存储中执行相似性搜索，k=2表示检索最相似的2个文档。\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    # 将检索到的文档内容格式化为字符串，每个文档包含其元数据和内容。\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    print(f\"--- 工具 'retrieve' 执行完成，检索到 {len(retrieved_docs)} 篇文档 ---\")\n",
    "    # 返回序列化内容和原始文档列表。\n",
    "    # response_format=\"content_and_artifact\" 允许工具返回两个值：\n",
    "    # 第一个值 (serialized) 作为 ToolMessage 的内容，\n",
    "    # 第二个值 (retrieved_docs) 作为 ToolMessage 的附加工件 (artifact) 存储。\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "print(\"检索工具 'retrieve' 已定义。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e151fbf8-8ebe-4035-8c3c-12f4e090da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tool(response_format=\"content_and_artifact\") 详解：\n",
    "\n",
    "# @tool 装饰器：这是LangChain提供的一种将普通Python函数转换为可被LLM调用的“工具”的方式。当LLM被赋予使用工具的能力时，它可以通过生成一个特殊的“工具调用”来调用这些函数。\n",
    "# response_format=\"content_and_artifact\"：这个参数告诉LangGraph（或LangChain的工具调用机制）如何处理工具的返回值。\n",
    "# content：工具返回的第一个值（这里是 serialized 字符串）将被用作 ToolMessage 的主要内容。LLM在后续生成答案时会直接看到这个内容。\n",
    "# artifact：工具返回的第二个值（这里是 retrieved_docs 列表）将被存储在 ToolMessage 的 additional_kwargs 字段中。这允许我们保留原始的文档对象，以便在需要时进行进一步处理或调试，而LLM的上下文不会被这些原始对象占用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92e6322-2d73-41dd-9772-ea4d3da88c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169fc96f-b91f-4ab7-a77b-87338714aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们的图将由三个节点组成：\n",
    "\n",
    "# 1.query_or_respond 节点: 处理用户输入，要么生成一个用于检索器的查询，要么直接响应。\n",
    "# 2.tools 节点: 执行检索工具。\n",
    "# 3.generate 节点: 使用检索到的上下文生成最终响应。\n",
    "# 我们将在下面构建它们。请注意，我们利用了另一个预构建的LangGraph组件 ToolNode，它执行工具并将结果作为 ToolMessage 添加到状态中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ad5b5c8-fb72-4ce2-a50f-3c33b7db3cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "工具节点 'tools' (ToolNode) 已初始化。\n",
      "生成节点 'generate' 已定义。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage # 导入不同类型的消息\n",
    "from langgraph.prebuilt import ToolNode # 导入 LangGraph 的预构建 ToolNode\n",
    "\n",
    "# --- 节点 1: query_or_respond ---\n",
    "# 这个节点负责接收用户输入，并决定是调用检索工具还是直接回复。\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"\n",
    "    生成工具调用进行检索或直接响应。\n",
    "    这个节点是图的入口点，LLM会根据对话历史和当前用户输入决定下一步行动。\n",
    "    \"\"\"\n",
    "    print(\"--- 正在执行节点: query_or_respond ---\")\n",
    "    # 将 retrieve 工具绑定到 LLM。这意味着 LLM 现在知道如何使用这个工具。\n",
    "    # llm_with_tools 变成了一个 Runnable，当它认为合适时，可以生成一个 ToolCall。\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    \n",
    "    # 调用 LLM，传入当前的状态消息列表。LLM会根据这些消息决定是生成一个普通回复\n",
    "    # 还是一个工具调用。\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    \n",
    "    # MessagesState 的特点是它将新消息追加到状态的 'messages' 列表中，而不是覆盖。\n",
    "    # 因此，我们返回一个包含新生成响应的字典，LangGraph 会将其追加到 `state[\"messages\"]`。\n",
    "    print(f\"--- 节点 'query_or_respond' 完成，LLM响应类型: {response.type} ---\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# --- 节点 2: tools ---\n",
    "# 这个节点负责执行 LLM 生成的工具调用。\n",
    "# ToolNode 是 LangGraph 的一个预构建节点，它会自动解析并执行 LLM 生成的工具调用。\n",
    "# 它接收一个工具列表作为参数。\n",
    "tools = ToolNode([retrieve])\n",
    "print(\"工具节点 'tools' (ToolNode) 已初始化。\")\n",
    "\n",
    "# --- 节点 3: generate ---\n",
    "# 这个节点负责使用检索到的内容（如果有）和对话历史生成最终答案。\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"\n",
    "    生成答案。\n",
    "    这个节点在工具执行完毕后被调用，用于整合检索到的信息和对话历史来生成用户最终看到的答案。\n",
    "    \"\"\"\n",
    "    print(\"--- 正在执行节点: generate ---\")\n",
    "    # 获取最近的工具消息。这些消息包含了检索工具的执行结果。\n",
    "    recent_tool_messages = []\n",
    "    # 从消息列表的末尾向前遍历，查找类型为 \"tool\" 的消息。\n",
    "    # 这样做是为了确保我们只获取当前回合相关的工具消息。\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            # 如果遇到非工具消息，说明已经超出了当前工具调用的范围，停止遍历。\n",
    "            break\n",
    "    # 将工具消息列表反转，使其按时间顺序排列（从旧到新）。\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # 从工具消息中提取检索到的文档内容。\n",
    "    # 每个 tool_message.content 包含了 retrieve 工具返回的序列化文档内容。\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    \n",
    "    # 构建系统消息的内容，其中包含通用指令和检索到的上下文。\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"Retrieved Context:\\n{docs_content}\" # 明确标记这是检索到的上下文\n",
    "    )\n",
    "    \n",
    "    # 过滤出用于生成最终答案的对话消息。\n",
    "    # 这里我们只保留 HumanMessage、SystemMessage，以及不包含工具调用的 AIMessage。\n",
    "    # 这样可以避免将LLM内部的工具调用思考过程暴露给最终用户。\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    \n",
    "    # 构建最终的提示列表，系统消息在前，对话消息在后。\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # 调用 LLM 生成最终的响应。\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    # 将生成的响应作为新的 AIMessage 追加到状态中。\n",
    "    print(f\"--- 节点 'generate' 完成，生成答案: {response.content[:50]}... ---\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"生成节点 'generate' 已定义。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c403604-0afe-45df-b1f0-8c0bf8b0237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_or_respond 节点详解：\n",
    "\n",
    "# llm.bind_tools([retrieve])：这是LangChain中一个强大的功能。它将一个或多个工具（这里是我们的 retrieve 工具）“绑定”到LLM上。这意味着LLM在生成响应时，除了生成文本，还可以选择生成一个 ToolCall，指示它想要调用哪个工具以及传递什么参数。\n",
    "# llm_with_tools.invoke(state[\"messages\"])：LLM接收当前所有的对话消息。如果它判断需要外部信息来回答问题，它会生成一个 ToolCall；如果它可以直接回答，或者只是一个问候，它会生成一个普通文本回复。\n",
    "# return {\"messages\": [response]}：LangGraph的 MessagesState 会自动将这个 response 追加到 state[\"messages\"] 列表中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c63207b-0d48-44af-909b-45f56c9cb0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 节点详解：\n",
    "\n",
    "# recent_tool_messages 提取：为了确保只使用与当前问题相关的检索结果，我们从 state[\"messages\"] 中反向遍历，收集最近的 ToolMessage。\n",
    "# system_message_content 构建：将检索到的 docs_content 嵌入到系统提示中，明确告诉LLM这是它应该用来回答问题的上下文。\n",
    "# conversation_messages 过滤：这个列表只包含实际的对话消息，排除了LLM内部生成的工具调用消息，确保最终呈现给用户的对话是清晰和自然的。\n",
    "# llm.invoke(prompt)：最后，将包含系统指令、检索上下文和过滤后对话历史的完整提示传递给LLM，生成最终的用户可见答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587b53d-a547-4d9d-b0fa-8add0abd7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后，我们编译我们的应用程序到一个单一的图对象中。在这个例子中，我们只是将这些步骤连接成一个序列。我们还允许第一个 query_or_respond 步骤“短路”（short-circuit），如果它没有生成工具调用，则直接响应用户。这使得我们的应用程序能够支持对话体验——例如，响应不需要检索步骤的通用问候。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258252cd-908f-4746-a3b7-507b535f289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始构建和编译LangGraph应用程序...\n",
      "LangGraph应用程序编译完成。\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import END # 导入 LangGraph 的 END 节点，表示图的终止\n",
    "from langgraph.prebuilt import tools_condition # 导入 LangGraph 的预构建条件函数\n",
    "\n",
    "print(\"开始构建和编译LangGraph应用程序...\")\n",
    "# 添加节点到图构建器\n",
    "graph_builder.add_node(query_or_respond) # 添加处理用户输入/生成查询的节点\n",
    "graph_builder.add_node(tools) # 添加执行工具的节点\n",
    "graph_builder.add_node(generate) # 添加生成最终答案的节点\n",
    "\n",
    "# 设置图的入口点\n",
    "graph_builder.set_entry_point(\"query_or_respond\") # 应用程序从 query_or_respond 节点开始执行\n",
    "\n",
    "# 添加条件边：根据 query_or_respond 的输出决定下一步走向\n",
    "# tools_condition 是 LangGraph 的一个预构建函数，它检查LLM的响应是否包含工具调用。\n",
    "# 如果包含工具调用，则走向 \"tools\" 节点。\n",
    "# 如果不包含工具调用（即LLM直接生成了答案），则走向 END 节点，结束执行。\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\", # 条件判断的来源节点\n",
    "    tools_condition,    # 用于判断的条件函数\n",
    "    {\n",
    "        END: END,       # 如果条件函数返回 END，则图执行结束\n",
    "        \"tools\": \"tools\" # 如果条件函数返回 \"tools\"，则图执行转向 \"tools\" 节点\n",
    "    },\n",
    ")\n",
    "\n",
    "# 添加常规边：定义确定性的流程\n",
    "graph_builder.add_edge(\"tools\", \"generate\") # \"tools\" 节点执行完毕后，总是转向 \"generate\" 节点\n",
    "graph_builder.add_edge(\"generate\", END) # \"generate\" 节点执行完毕后，总是转向 END 节点，结束执行\n",
    "\n",
    "# 编译图，生成可执行的应用程序\n",
    "graph = graph_builder.compile()\n",
    "print(\"LangGraph应用程序编译完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928bce0-2885-4557-a37a-7e4c5d58c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_builder.add_conditional_edges 详解：\n",
    "\n",
    "# 这是LangGraph中实现条件逻辑的关键。它允许图根据某个节点的输出动态地选择下一个执行路径。\n",
    "# \"query_or_respond\"：指定了条件判断发生在哪一个节点之后。\n",
    "# tools_condition：这是一个函数，它会检查 query_or_respond 节点产生的最新消息。如果消息包含 tool_calls（即LLM决定调用工具），它会返回一个特定的键（通常是 tools）；如果消息不包含 tool_calls（即LLM直接给出了文本响应），它会返回 END。\n",
    "# {END: END, \"tools\": \"tools\"}：这是一个映射，将 tools_condition 的返回值映射到下一个节点。\n",
    "# END: END：如果 tools_condition 返回 END，则图的执行终止。这处理了LLM直接回答问题或问候的情况。\n",
    "# \"tools\": \"tools\"：如果 tools_condition 返回 \"tools\"，则图的执行转向名为 \"tools\" 的节点（即我们的 ToolNode）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d54bc-7cff-41fe-82de-bffb79e89dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdf2769-7713-4f88-bbbd-a019781aa9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph流程图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86cec86a-8360-4700-a20c-989d53542e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# 绘制Mermaid图并显示\n",
    "# 注意：这需要在您的环境中安装Graphviz或类似的工具来渲染图像。\n",
    "# 如果您在JupyterLab中遇到问题，可能需要安装'python-graphviz'和'graphviz'系统包。\n",
    "# 例如：pip install graphviz 和 sudo apt-get install graphviz (Linux) 或 brew install graphviz (macOS)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5293c-589b-40d0-9c8e-83251852bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 让我们测试我们的应用程序。\n",
    "\n",
    "# 请注意，它会适当地响应不需要额外检索步骤的消息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "122b1531-d7ec-44dc-b4a9-3567a36782fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 测试简单问候，输入: 'Hello' ---\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello\n",
      "--- 正在执行节点: query_or_respond ---\n",
      "--- 节点 'query_or_respond' 完成，LLM响应类型: ai ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# 确保 graph 变量在此处可用\n",
    "input_message = \"Hello\" # 用户输入一个简单的问候\n",
    "\n",
    "print(f\"--- 测试简单问候，输入: '{input_message}' ---\")\n",
    "# 调用图的 stream 方法，以流式模式获取每个步骤的输出。\n",
    "# stream_mode=\"values\" 表示每个步骤完成后返回整个状态的最新值。\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=input_message)]}, # 初始状态包含一个 HumanMessage\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    # 打印每个步骤中最新的消息。\n",
    "    # pretty_print() 是 LangChain 消息对象的一个方法，用于美观地打印消息内容。\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5726617-b493-41d0-a656-1c8c0099ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里 query_or_respond 节点中的LLM判断“Hello”不需要工具调用，直接生成了问候语，并通过 tools_condition 短路到 END。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef33ca3-f4c7-43ee-825f-7f6a12f31664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当执行搜索时，我们可以流式传输步骤，以观察查询生成、检索和答案生成："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6ae754d-da8a-4edb-9726-7d3ac62572c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 测试RAG问答，输入: 'What is Task Decomposition?' ---\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Task Decomposition?\n",
      "--- 正在执行节点: query_or_respond ---\n",
      "--- 节点 'query_or_respond' 完成，LLM响应类型: ai ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (985d37ab-7c6e-4c0d-8b46-18f194f2a90a)\n",
      " Call ID: 985d37ab-7c6e-4c0d-8b46-18f194f2a90a\n",
      "  Args:\n",
      "    query: Task Decomposition\n",
      "--- 正在执行工具: retrieve, 查询: 'Task Decomposition' ---\n",
      "--- 工具 'retrieve' 执行完成，检索到 2 篇文档 ---\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "--- 正在执行节点: generate ---\n",
      "--- 节点 'generate' 完成，生成答案: Task decomposition involves breaking down a larger... ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition involves breaking down a larger task into smaller, more manageable steps or subgoals. This can be achieved through methods such as using an LLM with simple prompts to identify steps, providing task-specific instructions, or incorporating human inputs.\n"
     ]
    }
   ],
   "source": [
    "# 确保 graph 变量在此处可用\n",
    "input_message = \"What is Task Decomposition?\" # 用户输入一个需要检索的问题\n",
    "\n",
    "print(f\"\\n--- 测试RAG问答，输入: '{input_message}' ---\")\n",
    "# 以流式模式调用图\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=input_message)]}, # 初始状态包含一个 HumanMessage\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    # 打印每个步骤中最新的消息\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e8e634-1afd-4804-b172-b73a5ab857cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在这里，LLM 在 query_or_respond 步骤中识别出需要检索，生成了 retrieve 工具调用，tools 节点执行了检索，然后 generate 节点利用检索到的信息和原始问题生成了最终答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34470ed-6c6c-46a1-890b-3e27ea9b8bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abfac6-4a13-403f-9237-e038b7656c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 聊天历史的状态管理 (Stateful management of chat history)\n",
    "# 在生产环境中，问答应用程序通常会将聊天历史持久化到数据库中，并能够适当地读取和更新它。\n",
    "\n",
    "# LangGraph 实现了一个内置的持久化层，使其成为支持多轮对话的聊天应用程序的理想选择。\n",
    "\n",
    "# 为了管理多轮对话和线程，我们所要做的就是在编译应用程序时指定一个 checkpointer。由于图中的节点将消息追加到状态中，我们将在不同的调用中保留一致的聊天历史。\n",
    "\n",
    "# LangGraph 提供了一个简单的内存检查点器 (MemorySaver)，我们将在下面使用它。有关更多详细信息，包括如何使用不同的持久化后端（例如 SQLite 或 Postgres），请参阅其文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "040c2809-08dc-43f4-921b-3d8595d1dfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存检查点器 (MemorySaver) 已初始化。\n",
      "LangGraph应用程序已使用 MemorySaver 重新编译。\n",
      "已设置对话线程ID: abc123\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver # 导入内存检查点器\n",
    "\n",
    "# 创建一个 MemorySaver 实例。\n",
    "# MemorySaver 会将图的状态保存在内存中，允许在不同调用之间保持对话历史。\n",
    "memory = MemorySaver()\n",
    "print(\"内存检查点器 (MemorySaver) 已初始化。\")\n",
    "\n",
    "# 重新编译图，并指定 checkpointer。\n",
    "# 这样，图在每次运行时都会使用 memory 对象来保存和恢复状态。\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "print(\"LangGraph应用程序已使用 MemorySaver 重新编译。\")\n",
    "\n",
    "# 为对话线程指定一个ID。\n",
    "# 这个ID用于区分不同的对话线程，MemorySaver 会为每个 thread_id 存储独立的对话历史。\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "print(f\"已设置对话线程ID: {config['configurable']['thread_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ff600-e2b1-4fc9-a666-070edb61f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MemorySaver 详解：\n",
    "\n",
    "# MemorySaver 是LangGraph提供的一个简单的持久化实现，它将每个对话线程的状态保存在Python进程的内存中。\n",
    "# checkpointer=memory：在 graph_builder.compile() 中传入 checkpointer 参数，告诉LangGraph使用这个 memory 对象来管理图的状态持久化。\n",
    "# config = {\"configurable\": {\"thread_id\": \"abc123\"}}：这是LangChain/LangGraph中用于配置可配置组件（如checkpointer）的标准方式。thread_id 是一个唯一的标识符，用于识别特定的对话会话。每次调用 graph.stream 或 graph.invoke 时，如果传入相同的 thread_id，LangGraph就会加载并更新该 thread_id 对应的历史状态。\n",
    "# 我们现在可以像以前一样调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10330a9b-433a-4e62-96d9-58220d59a693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 第一次询问，输入: 'What is Task Decomposition?' ---\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Task Decomposition?\n",
      "--- 正在执行节点: query_or_respond ---\n",
      "--- 节点 'query_or_respond' 完成，LLM响应类型: ai ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (fc97bc07-e24a-459d-9963-d529e598caf5)\n",
      " Call ID: fc97bc07-e24a-459d-9963-d529e598caf5\n",
      "  Args:\n",
      "    query: Task Decomposition\n",
      "--- 正在执行工具: retrieve, 查询: 'Task Decomposition' ---\n",
      "--- 工具 'retrieve' 执行完成，检索到 2 篇文档 ---\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "--- 正在执行节点: generate ---\n",
      "--- 节点 'generate' 完成，生成答案: Task decomposition is the process of breaking down... ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition is the process of breaking down a larger task into smaller, more manageable steps or subgoals. This can be achieved by an LLM using simple prompts, through task-specific instructions, or with human input.\n"
     ]
    }
   ],
   "source": [
    "# 确保 graph 和 config 变量在此处可用\n",
    "input_message = \"What is Task Decomposition?\"\n",
    "\n",
    "print(f\"--- 第一次询问，输入: '{input_message}' ---\")\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=input_message)]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config, # 传入配置，启用状态持久化\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083b057-bade-466d-9c6c-9743eaa1e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在，我们进行第二次询问，这次的问题依赖于之前的上下文："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1dc8727c-d42e-496b-9c57-5d7f3411b069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 第二次询问，输入: 'Can you look up some common ways of doing it?' ---\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up some common ways of doing it?\n",
      "--- 正在执行节点: query_or_respond ---\n",
      "--- 节点 'query_or_respond' 完成，LLM响应类型: ai ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Common ways to perform task decomposition include:\n",
      "\n",
      "1.  **Using an LLM with simple prompting:** This involves giving the LLM prompts like \"Steps for XYZ.\\n1.\" or \"What are the subgoals for achieving XYZ?\" to guide it in breaking down the task.\n",
      "2.  **Using task-specific instructions:** Providing the LLM with specific instructions tailored to the task, such as \"Write a story outline.\" for a novel-writing task.\n",
      "3.  **With human inputs:** Directly involving human users to define or refine the sub-tasks.\n"
     ]
    }
   ],
   "source": [
    "# 确保 graph 和 config 变量在此处可用\n",
    "input_message = \"Can you look up some common ways of doing it?\" # 第二次询问，依赖于“Task Decomposition”的上下文\n",
    "\n",
    "print(f\"\\n--- 第二次询问，输入: '{input_message}' ---\")\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=input_message)]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config, # 再次传入相同的配置，以便加载之前的对话历史\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f93a2-ec32-4212-be1a-dcda34987359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 请注意，在第二个问题中，模型生成的查询 (common methods of task decomposition) 包含了对话上下文。这是因为 query_or_respond 节点中的LLM在生成查询时，能够访问并理解 state[\"messages\"] 中完整的对话历史。\n",
    "\n",
    "# LangSmith 跟踪在这里特别有信息量，因为我们可以清楚地看到在每个步骤中，聊天模型看到了哪些消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b213c163-1c2c-48d7-8fcf-3894b996b73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2bda64-7413-435e-a88b-0c540c10bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代理 (Agents)\n",
    "# 代理利用LLM的推理能力在执行过程中做出决策。使用代理可以让你在检索过程中获得额外的自由裁量权。虽然它们的行为不如上述“链”可预测，但它们能够执行多个检索步骤以满足查询，或迭代单个搜索。\n",
    "\n",
    "# 下面我们组装一个最小的RAG代理。使用LangGraph预构建的ReAct代理构造函数，我们可以在一行代码中完成此操作。\n",
    "\n",
    "# 提示: 查看LangGraph的Agentic RAG教程，了解更高级的代理实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04e3009e-6510-4d5f-83df-e144cd16e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReAct 代理 (agent_executor) 已创建并编译。\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent # 导入 LangGraph 预构建的 ReAct 代理构造函数\n",
    "\n",
    "# 使用 create_react_agent 函数创建一个 ReAct 代理。\n",
    "# llm: 指定用于代理的语言模型。\n",
    "# tools: 指定代理可以使用的工具列表（这里是我们的 retrieve 工具）。\n",
    "# checkpointer: 指定用于持久化代理状态的检查点器（这里是之前定义的 memory）。\n",
    "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)\n",
    "print(\"ReAct 代理 (agent_executor) 已创建并编译。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decee497-589d-431b-a521-6b2e3ba52b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_react_agent 详解：\n",
    "\n",
    "# create_react_agent 是LangGraph提供的一个高级抽象，它基于ReAct（Reasoning and Acting）范式构建了一个代理。\n",
    "# ReAct 代理的工作原理是：LLM会观察当前的对话历史和工具输出，然后思考（Reason）下一步应该做什么（是回答问题，还是调用工具），然后行动（Act）（调用工具或给出最终答案）。这个过程可以循环多次，直到LLM认为问题已解决。\n",
    "# 通过 llm 和 [retrieve] 参数，我们告诉代理使用哪个LLM进行推理，以及它可以使用哪些工具。\n",
    "# checkpointer=memory 确保了代理的对话历史和思考过程也能被持久化，从而支持多轮复杂对话。\n",
    "# 让我们检查一下代理的图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f02680b5-ff9a-4aef-af1d-7504efc71598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c978ed-b650-4e74-9fd6-8fd8f300899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代理图与链图的关键区别：\n",
    "\n",
    "# 循环（Looping）: 代理图的关键区别在于，它不是在 generate 步骤之后结束运行，而是工具调用之后会循环回到原始的LLM调用（这里是 agent 节点）。这意味着LLM可以根据检索到的上下文决定是回答问题，还是生成另一个工具调用以获取更多信息。\n",
    "# 决策权: 代理赋予LLM更大的决策权，让它自己判断是否需要多次检索，以及如何组合信息来回答复杂问题。\n",
    "# 让我们测试一下。我们构建一个通常需要迭代检索步骤才能回答的问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d98be70c-423a-437f-a394-e8393c71e92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已设置新的对话线程ID: def222\n",
      "\n",
      "--- 测试代理多步检索，输入: 'What is the standard method for Task Decomposition?\n",
      "\n",
      "Once you get the answer, look up common extensions of that method.' ---\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the standard method for Task Decomposition?\n",
      "\n",
      "Once you get the answer, look up common extensions of that method.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (fff68099-b7a4-4c93-ab9d-168c474672a8)\n",
      " Call ID: fff68099-b7a4-4c93-ab9d-168c474672a8\n",
      "  Args:\n",
      "    query: standard method for Task Decomposition\n",
      "--- 正在执行工具: retrieve, 查询: 'standard method for Task Decomposition' ---\n",
      "--- 工具 'retrieve' 执行完成，检索到 2 篇文档 ---\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'start_index': 2578, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Source: {'start_index': 2578, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition can be performed through three main methods:\n",
      "\n",
      "1.  **LLM with simple prompting**: This involves using a Large Language Model (LLM) with straightforward prompts, such as \"Steps for XYZ.\\n1.\" or \"What are the subgoals for achieving XYZ?\".\n",
      "2.  **Task-specific instructions**: Providing the LLM with specific instructions tailored to the task, for example, \"Write a story outline\" for generating a novel.\n",
      "3.  **Human inputs**: Decomposing tasks with direct human intervention and guidance.\n",
      "\n",
      "A common extension to these methods is **LLM+P (Liu et al. 2023)**. This approach leverages an external classical planner for long-horizon planning. It uses the Planning Domain Definition Language (PDDL) as an intermediate interface. The process involves the LLM translating the problem into \"Problem PDDL,\" then requesting a classical planner to generate a PDDL plan based on an existing \"Domain PDDL,\" and finally translating the PDDL plan back into natural language. This essentially outsources the planning step to an external tool, which is common in certain robotic setups.\n"
     ]
    }
   ],
   "source": [
    "# 确保 agent_executor 和 memory 变量在此处可用\n",
    "# 为新的对话线程指定一个ID，以避免与之前的“abc123”线程混淆。\n",
    "config = {\"configurable\": {\"thread_id\": \"def222\"}}\n",
    "print(f\"已设置新的对话线程ID: {config['configurable']['thread_id']}\")\n",
    "\n",
    "input_message = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "print(f\"\\n--- 测试代理多步检索，输入: '{input_message}' ---\")\n",
    "# 以流式模式调用代理执行器\n",
    "for event in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=input_message)]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config, # 传入配置，启用状态持久化\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af170a7-9523-472a-bd1e-7e045360e295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb75505e-51de-4ad4-baac-ea200d706adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abddc1-c5be-4acd-bc8f-49948d7bb2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下一步 (Next steps)\n",
    "# 我们已经涵盖了构建一个基本的对话式问答应用程序的步骤：\n",
    "\n",
    "# 我们使用链构建了一个可预测的应用程序，该应用程序为每个用户输入最多生成一个查询。\n",
    "# 我们使用代理构建了一个可以迭代查询序列的应用程序。\n",
    "# 要探索不同类型的检索器和检索策略，请访问操作指南的检索器部分。有关LangChain对话记忆抽象的详细演练，请访问如何添加消息历史（记忆）指南。要了解有关代理的更多信息，请查看概念指南和LangGraph代理架构页面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d940c46-ef4b-46fe-b2e7-ece300b5d642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc37d9-4f30-4e63-be76-30c541694e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8eac5-89b1-41b6-8ad8-28a78e9e20f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3462c59-b9bd-4991-bc10-e8c794823efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93398e77-e35c-4d81-8b5d-9f8c19b5793d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c283f563-a029-4679-9a2c-840e2149e561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8907a050-3a29-4541-96af-6bfcea01eafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e5039d-922b-4c0f-b57d-4ba88f2ee062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4968a38-e15c-4cd9-b671-87ebbdef6a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af78a3-b1c3-48bf-9385-b47d75c2a7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26a27b-414f-49cf-a824-82410daafe81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9cd6e-f3f2-43df-b63d-f3577d515b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab719ca-618f-4732-a739-b78de5be2687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
