{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0590bd6-3d21-4cab-b51a-512a0733b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®˜æ–¹æ–‡æ¡£æ•™ç¨‹\n",
    "# https://python.langchain.com/docs/tutorials/chatbot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876db97e-aedb-419c-a4eb-6d8ef2fcfa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºèŠå¤©æœºå™¨äºº\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ead7f4-9651-43df-8e14-7e625b7be2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¦‚è¿°\n",
    "# æˆ‘ä»¬å°†é€šè¿‡ä¸€ä¸ªç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•è®¾è®¡å’Œå®ç°ä¸€ä¸ªåŸºäº LLM çš„èŠå¤©æœºå™¨äººã€‚è¯¥èŠå¤©æœºå™¨äººå°†èƒ½å¤Ÿä¸èŠå¤©æ¨¡å‹è¿›è¡Œå¯¹è¯ï¼Œå¹¶è®°ä½ä¹‹å‰çš„äº¤äº’ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79bcaa-c34f-4865-8e1f-3f562d258196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½®\n",
    "# Jupyter Notebook\n",
    "# æœ¬æŒ‡å—ï¼ˆä»¥åŠæ–‡æ¡£ä¸­çš„å¤§å¤šæ•°å…¶ä»–æŒ‡å—ï¼‰å‡ä½¿ç”¨ Jupyter Notebook ï¼Œå¹¶å‡è®¾è¯»è€…ä¹Ÿä½¿ç”¨ Jupyter Notebookã€‚Jupyter Notebook éå¸¸é€‚åˆå­¦ä¹ å¦‚ä½•ä½¿ç”¨ LLM ç³»ç»Ÿï¼Œå› ä¸ºç»å¸¸ä¼šå‡ºç°é—®é¢˜ï¼ˆä¾‹å¦‚æ„å¤–è¾“å‡ºã€API æ•…éšœç­‰ï¼‰ï¼Œè€Œåœ¨äº¤äº’å¼ç¯å¢ƒä¸­é˜…è¯»æŒ‡å—æ˜¯æ›´å¥½åœ°ç†è§£è¿™äº›ç³»ç»Ÿçš„ç»ä½³æ–¹å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92572ab5-fefa-4491-9437-2fc4ada77cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…\n",
    "# æœ¬æ•™ç¨‹éœ€è¦ langchain-core å’Œ langgraph ã€‚æœ¬æŒ‡å—éœ€è¦ langgraph >= 0.2.28 ã€‚\n",
    "# conda install langchain-core langgraph>0.2.27 -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48944ea5-165d-4460-8e8c-8ae5d1adcf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith\n",
    "# ä½¿ç”¨ LangChain æ„å»ºçš„è®¸å¤šåº”ç”¨ç¨‹åºéƒ½åŒ…å«å¤šä¸ªæ­¥éª¤ï¼Œéœ€è¦å¤šæ¬¡è°ƒç”¨ LLM å‡½æ•°ã€‚éšç€è¿™äº›åº”ç”¨ç¨‹åºå˜å¾—è¶Šæ¥è¶Šå¤æ‚ï¼Œèƒ½å¤Ÿæ£€æŸ¥é“¾æˆ–ä»£ç†å†…éƒ¨ç©¶ç«Ÿå‘ç”Ÿäº†ä»€ä¹ˆå˜å¾—è‡³å…³é‡è¦ã€‚æœ€å¥½çš„æ–¹æ³•æ˜¯ä½¿ç”¨ LangSmith ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a3c25-a5ff-4443-ac9d-2c2a997c26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€šè¿‡ä¸Šé¢çš„é“¾æ¥æ³¨å†Œåï¼Œè¯·ç¡®ä¿è®¾ç½®ç¯å¢ƒå˜é‡ä»¥å¼€å§‹è®°å½•è·Ÿè¸ªï¼š\n",
    "\n",
    "# export LANGSMITH_TRACING=\"true\"\n",
    "# export LANGSMITH_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81854275-3b92-47bc-8a77-fddba8d41b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æˆ–è€…ï¼Œå¦‚æœåœ¨ç¬”è®°æœ¬ä¸­ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼è®¾ç½®å®ƒä»¬ï¼š\n",
    "\n",
    "# import getpass\n",
    "# import os\n",
    "\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d163636-0532-45bd-ba2a-50b39119be65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde0b37a-0653-4b42-927c-803d7ffe7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿«é€Ÿå…¥é—¨\n",
    "# é¦–å…ˆï¼Œè®©æˆ‘ä»¬å­¦ä¹ å¦‚ä½•å•ç‹¬ä½¿ç”¨è¯­è¨€æ¨¡å‹ã€‚LangChain æ”¯æŒå¤šç§ä¸åŒçš„è¯­è¨€æ¨¡å‹ï¼Œæ‚¨å¯ä»¥äº’æ¢ä½¿ç”¨ - è¯·åœ¨ä¸‹æ–¹é€‰æ‹©æ‚¨æƒ³è¦ä½¿ç”¨çš„æ¨¡å‹ï¼\n",
    "# é€‰æ‹©èŠå¤©æ¨¡å‹ ï¼š\n",
    "# Google Gemini â–¾\n",
    "# pip install -qU \"langchain[google-genai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdb72424-084c-40cd-ba7c-b5b64fc49661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80dd3e4d-ff08-4ebb-b1b0-0569ee3fb4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¦–å…ˆè®©æˆ‘ä»¬ç›´æ¥ä½¿ç”¨æ¨¡å‹ã€‚ChatModel æ˜¯ ChatModel â€œRunnablesâ€çš„å®ä¾‹ï¼Œè¿™æ„å‘³ç€å®ƒä»¬æš´éœ²äº†ä¸€ä¸ªç”¨äºäº¤äº’çš„æ ‡å‡†æ¥å£ã€‚ä¸ºäº†ç®€å•åœ°è°ƒç”¨æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ¶ˆæ¯åˆ—è¡¨ä¼ é€’ç»™ .invoke æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f00ed36-14e1-471b-8664-9dbb0f3f7772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Miku! It's nice to meet you. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--04d948fe-7cb2-4500-b794-a409348980b3-0', usage_metadata={'input_tokens': 7, 'output_tokens': 20, 'total_tokens': 27, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi! I'm Miku\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93cdf12b-11e0-4a16-ac36-dc476b55e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯¥æ¨¡å‹æœ¬èº«æ²¡æœ‰ä»»ä½•çŠ¶æ€æ¦‚å¿µã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ é—®ä¸€ä¸ªåç»­é—®é¢˜ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db845ed2-5ef9-494e-878a-63389b6c2596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a large language model, I have no way of knowing your name. You haven't told me!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--d4e62309-c9bb-4c04-aa3f-68fcfa5a4091-0', usage_metadata={'input_tokens': 6, 'output_tokens': 23, 'total_tokens': 29, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"What's my name?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e655bc5a-8134-45df-a3c3-6f2a7e0f368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹ LangSmith è·Ÿè¸ªç¤ºä¾‹\n",
    "# æˆ‘ä»¬å‘ç°å®ƒæ²¡æœ‰å°†ä¹‹å‰çš„å¯¹è¯å†…å®¹çº³å…¥ä¸Šä¸‹æ–‡ï¼Œä¹Ÿæ— æ³•å›ç­”é—®é¢˜ã€‚è¿™ç»™èŠå¤©æœºå™¨äººå¸¦æ¥äº†ç³Ÿç³•çš„ä½“éªŒï¼\n",
    "# ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦å°†æ•´ä¸ªå¯¹è¯å†å²è®°å½•ä¼ å…¥æ¨¡å‹ã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™æ ·åšä¼šå‘ç”Ÿä»€ä¹ˆï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caa3d21a-a747-46fb-89fe-a85918d8cb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Miku. You just told me! ğŸ˜Š', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--a079d517-e392-43a2-9bff-731199c61166-0', usage_metadata={'input_tokens': 24, 'output_tokens': 13, 'total_tokens': 37, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm Miku\"),\n",
    "        AIMessage(content=\"Hello Miku! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bcabe0-2e20-4a9e-b39f-d9d8d8964578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç°åœ¨æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬å¾—åˆ°äº†è‰¯å¥½çš„å“åº”ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2bd9b6-0c98-48d6-9522-66706b3998d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿™æ˜¯èŠå¤©æœºå™¨äººå¯¹è¯äº¤äº’èƒ½åŠ›çš„åŸºæœ¬ç†å¿µã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬å¦‚ä½•æ‰èƒ½æœ€å¥½åœ°å®ç°è¿™ä¸€ç‚¹å‘¢ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1dabad8-6ac1-4888-8166-fe6a32d73a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¶ˆæ¯æŒä¹…åŒ–\n",
    "# LangGraph å®ç°äº†å†…ç½®æŒä¹…å±‚ï¼Œä½¿å…¶æˆä¸ºæ”¯æŒå¤šè½®å¯¹è¯çš„èŠå¤©åº”ç”¨ç¨‹åºçš„ç†æƒ³é€‰æ‹©ã€‚\n",
    "# å°†æˆ‘ä»¬çš„èŠå¤©æ¨¡å‹åŒ…è£…åœ¨ä¸€ä¸ªæœ€å°çš„ LangGraph åº”ç”¨ç¨‹åºä¸­ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿè‡ªåŠ¨ä¿å­˜æ¶ˆæ¯å†å²è®°å½•ï¼Œä»è€Œç®€åŒ–å¤šè½®åº”ç”¨ç¨‹åºçš„å¼€å‘ã€‚\n",
    "# LangGraph è‡ªå¸¦ä¸€ä¸ªç®€å•çš„å†…å­˜æ£€æŸ¥ç‚¹ï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹é¢ä½¿ç”¨å®ƒã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬å¦‚ä½•ä½¿ç”¨ä¸åŒçš„æŒä¹…åŒ–åç«¯ï¼ˆä¾‹å¦‚ SQLite æˆ– Postgresï¼‰ï¼Œè¯·å‚é˜…å…¶æ–‡æ¡£ ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cafa242-856f-4d6b-aa4c-17593672bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1804056d-0bee-47e2-916a-ce5cfd1a175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç°åœ¨æˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ª config ï¼Œæ¯æ¬¡éƒ½ä¼ é€’ç»™å¯è¿è¡Œå¯¹è±¡ã€‚æ­¤é…ç½®åŒ…å«ä¸€äº›ä¸ç›´æ¥åŒ…å«åœ¨è¾“å…¥ä¸­ä½†ä»ç„¶æœ‰ç”¨çš„ä¿¡æ¯ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›åŒ…å«ä¸€ä¸ª thread_id ã€‚å®ƒåº”è¯¥å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c668e75a-0a8d-49a9-9b24-567346a0ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a5277a5-2c95-41bc-9e75-4a340484bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨å•ä¸ªåº”ç”¨ç¨‹åºæ”¯æŒå¤šä¸ªå¯¹è¯çº¿ç¨‹ï¼Œå½“æ‚¨çš„åº”ç”¨ç¨‹åºæœ‰å¤šä¸ªç”¨æˆ·æ—¶ï¼Œè¿™æ˜¯ä¸€ä¸ªå¸¸è§çš„è¦æ±‚ã€‚\n",
    "# ç„¶åæˆ‘ä»¬å¯ä»¥è°ƒç”¨è¯¥åº”ç”¨ç¨‹åºï¼š\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09df3338-b9aa-4e54-b5e0-e51724251fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Miku! It's nice to meet you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "query = \"Hi! I'm Miku.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d966e69c-071e-486a-8b35-1dbf91c4900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Miku. You just told me! ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "query = \"What's my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26244c8b-dbb8-4e75-b87f-8b7221c718e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¤ªæ£’äº†ï¼æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººç°åœ¨è®°ä½äº†æˆ‘ä»¬çš„ä¸€äº›äº‹æƒ…ã€‚å¦‚æœæˆ‘ä»¬ä¿®æ”¹é…ç½®ï¼Œå¼•ç”¨ä¸åŒçš„ thread_id ï¼Œå°±èƒ½çœ‹åˆ°å®ƒé‡æ–°å¼€å§‹å¯¹è¯äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6d24c0b-70f0-4965-89e0-1d8fa7787797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As a large language model, I don't know your name. I have no memory of past conversations and don't have access to personal information. You haven't told me your name.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e2fb0df-42c8-45f4-8c4c-716613a7a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½†æ˜¯ï¼Œæˆ‘ä»¬æ€»æ˜¯å¯ä»¥å›åˆ°åŸå§‹å¯¹è¯ï¼ˆå› ä¸ºæˆ‘ä»¬å°†å…¶ä¿å­˜åœ¨æ•°æ®åº“ä¸­ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "565a18ea-9a94-438b-a61e-28f8b326a216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You told me your name is Miku. Is that still correct?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77160585-45c0-4c71-bae6-a26b22b15bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿™å°±æ˜¯æˆ‘ä»¬å¦‚ä½•æ”¯æŒèŠå¤©æœºå™¨äººä¸è®¸å¤šç”¨æˆ·è¿›è¡Œå¯¹è¯ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de516904-c306-4406-b69d-9ff2d4ca496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tip  æç¤º\n",
    "# å¯¹äºå¼‚æ­¥æ”¯æŒï¼Œå°† call_model èŠ‚ç‚¹æ›´æ–°ä¸ºå¼‚æ­¥å‡½æ•°ï¼Œå¹¶åœ¨è°ƒç”¨åº”ç”¨ç¨‹åºæ—¶ä½¿ç”¨ .ainvoke ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feab2ce6-81c6-423d-b248-0e566e8d1b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As a large language model, I have no memory of past conversations. Therefore, I don't know your name. You haven't told me!\n"
     ]
    }
   ],
   "source": [
    "# Async function for node:\n",
    "async def call_model(state: MessagesState):\n",
    "    response = await model.ainvoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define graph as before:\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "app = workflow.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Async invocation:\n",
    "output = await app.ainvoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d0698-d18d-48e5-9703-c7770e6af583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç›®å‰ï¼Œæˆ‘ä»¬æ‰€åšçš„åªæ˜¯åœ¨æ¨¡å‹å‘¨å›´æ·»åŠ äº†ä¸€ä¸ªç®€å•çš„æŒä¹…å±‚ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æ·»åŠ æç¤ºæ¨¡æ¿æ¥ä½¿èŠå¤©æœºå™¨äººå˜å¾—æ›´åŠ å¤æ‚å’Œä¸ªæ€§åŒ–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91ced6-76d9-4b7b-bd7c-96c5e297460f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a561792c-ca6b-4372-8d43-43eb6716a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt templates(æç¤ºæ¨¡æ¿)\n",
    "# æç¤ºæ¨¡æ¿æœ‰åŠ©äºå°†åŸå§‹ç”¨æˆ·ä¿¡æ¯è½¬æ¢ä¸º LLM å¯ä»¥å¤„ç†çš„æ ¼å¼ã€‚\n",
    "# åœ¨æœ¬ä¾‹ä¸­ï¼ŒåŸå§‹ç”¨æˆ·è¾“å…¥åªæ˜¯ä¸€æ¡æ¶ˆæ¯ï¼Œæˆ‘ä»¬ä¼šå°†å…¶ä¼ é€’ç»™ LLMã€‚\n",
    "# ç°åœ¨è®©æˆ‘ä»¬è®©å®ƒæ›´å¤æ‚ä¸€äº›ã€‚\n",
    "# é¦–å…ˆï¼Œè®©æˆ‘ä»¬æ·»åŠ ä¸€æ¡åŒ…å«ä¸€äº›è‡ªå®šä¹‰æŒ‡ä»¤çš„ç³»ç»Ÿæ¶ˆæ¯ï¼ˆä½†ä»ç„¶æ¥å—æ¶ˆæ¯ä½œä¸ºè¾“å…¥ï¼‰ã€‚\n",
    "# æ¥ä¸‹æ¥ï¼Œé™¤äº†æ¶ˆæ¯ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å°†æ·»åŠ æ›´å¤šè¾“å…¥ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be462e8-39a3-4c8d-a8cd-88e1fb6f185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸ºäº†æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª ChatPromptTemplate ã€‚æˆ‘ä»¬å°†åˆ©ç”¨ MessagesPlaceholder æ¥ä¼ é€’æ‰€æœ‰æ¶ˆæ¯ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc02ea52-a9af-4a2b-a515-42fdc29c8d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You talk like a pirate. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13aae62e-025d-4103-8ff2-9bd1be96650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æˆ‘ä»¬ç°åœ¨å¯ä»¥æ›´æ–°æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºä»¥åŒ…å«æ­¤æ¨¡æ¿ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cdd2a64-134f-4499-a180-64eac032fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d419b78f-e858-4867-b189-1484a4b6b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æˆ‘ä»¬ä»¥åŒæ ·çš„æ–¹å¼è°ƒç”¨åº”ç”¨ç¨‹åºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e961e444-a995-443a-8128-c0b797255599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ahoy there, LuoTianYi! A pleasure to meet ye on the digital seas! What brings ye to these waters? I be ready to lend a hand, or at least spin a yarn or two.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"Hi! I'm LuoTianYi.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd6ad1a8-4abe-4664-93ab-2e52a2736d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Shiver me timbers, ye be testin' me memory, aye? Yer name be LuoTianYi, as ye told me just a moment ago! Don't be makin' this ol' salt doubt his senses!\n"
     ]
    }
   ],
   "source": [
    "query = \"What is my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394fa94-9bd5-44ea-a685-dfc2c6b41281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¤ªæ£’äº†ï¼ç°åœ¨è®©æˆ‘ä»¬æŠŠæç¤ºç¬¦å˜å¾—æ›´å¤æ‚ä¸€äº›ã€‚å‡è®¾æç¤ºç¬¦æ¨¡æ¿ç°åœ¨çœ‹èµ·æ¥åƒè¿™æ ·ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61042180-addc-4380-9261-bc8a8a581bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "544c7e4c-0af8-4e2d-b6a3-dcf5a0bab9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯·æ³¨æ„ï¼Œæˆ‘ä»¬åœ¨æç¤ºæ¡†ä¸­æ·»åŠ äº†æ–°çš„ language è¾“å…¥ã€‚æˆ‘ä»¬çš„åº”ç”¨ç°åœ¨æœ‰ä¸¤ä¸ªå‚æ•°â€”â€”è¾“å…¥ messages å’Œ language ã€‚æˆ‘ä»¬åº”è¯¥æ›´æ–°åº”ç”¨çš„çŠ¶æ€ä»¥åæ˜ è¿™ä¸€ç‚¹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c28589cd-90a7-439d-b4f2-c57a0a7315e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    language: str\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47ada81f-439b-4a1a-b72d-7f714211caf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ä½ å¥½ï¼Œæ´›å¤©ä¾ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n",
    "query = \"Hi! I'm LuoTianYi.\"\n",
    "language = \"Chinese\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc05cb-72a7-4415-866b-1f2c02c3728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯·æ³¨æ„ï¼Œæ•´ä¸ªçŠ¶æ€æ˜¯æŒä¹…çš„ï¼Œå› æ­¤å¦‚æœä¸éœ€è¦æ›´æ”¹ï¼Œæˆ‘ä»¬å¯ä»¥çœç•¥ language ç­‰å‚æ•°ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b9caa71-0d1f-4549-a944-e7bb2fcf518d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ä½ çš„åå­—æ˜¯æ´›å¤©ä¾ã€‚\n"
     ]
    }
   ],
   "source": [
    "query = \"What is my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec11fd5a-0c02-4f82-9207-3fb2b2f9866e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676bfcc-cf93-4b8f-9f3a-7d241b3add51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Managing Conversation Historyï¼ˆç®¡ç†å¯¹è¯å†å²è®°å½•ï¼‰\n",
    "# æ„å»ºèŠå¤©æœºå™¨äººæ—¶ï¼Œéœ€è¦ç†è§£çš„ä¸€ä¸ªé‡è¦æ¦‚å¿µæ˜¯å¦‚ä½•ç®¡ç†å¯¹è¯å†å²è®°å½•ã€‚å¦‚æœä¸åŠ ä»¥ç®¡ç†ï¼Œæ¶ˆæ¯åˆ—è¡¨å°†æ— é™å¢é•¿ï¼Œå¹¶å¯èƒ½æº¢å‡º LLM çš„ä¸Šä¸‹æ–‡çª—å£ã€‚å› æ­¤ï¼Œæ·»åŠ ä¸€ä¸ªé™åˆ¶ä¼ å…¥æ¶ˆæ¯å¤§å°çš„æ­¥éª¤éå¸¸é‡è¦ã€‚\n",
    "# é‡è¦çš„æ˜¯ï¼Œæ‚¨éœ€è¦åœ¨æç¤ºæ¨¡æ¿ä¹‹å‰ä½†åœ¨ä»æ¶ˆæ¯å†å²è®°å½•ä¸­åŠ è½½ä»¥å‰çš„æ¶ˆæ¯ä¹‹åæ‰§è¡Œæ­¤æ“ä½œã€‚\n",
    "# æˆ‘ä»¬å¯ä»¥åœ¨æç¤ºå‰æ·»åŠ ä¸€ä¸ªç®€å•çš„æ­¥éª¤æ¥é€‚å½“ä¿®æ”¹ messages é”®ï¼Œç„¶åå°†è¯¥æ–°é“¾åŒ…è£…åœ¨æ¶ˆæ¯å†å²è®°å½•ç±»ä¸­ã€‚\n",
    "# LangChain è‡ªå¸¦ä¸€äº›å†…ç½®åŠ©æ‰‹ï¼Œç”¨äºç®¡ç†æ¶ˆæ¯åˆ—è¡¨ ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ trim_messages åŠ©æ‰‹æ¥å‡å°‘å‘é€ç»™æ¨¡å‹çš„æ¶ˆæ¯æ•°é‡ã€‚ä¿®å‰ªå™¨å…è®¸æˆ‘ä»¬æŒ‡å®šè¦ä¿ç•™çš„æ ‡è®°æ•°é‡ï¼Œä»¥åŠå…¶ä»–å‚æ•°ï¼Œä¾‹å¦‚æ˜¯å¦è¦å§‹ç»ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ä»¥åŠæ˜¯å¦å…è®¸éƒ¨åˆ†æ¶ˆæ¯ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "824cabfa-ec15-4ce7-8504-a14f4f3de6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e7ed03-1457-4424-86ae-491be3d0f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸ºäº†åœ¨æˆ‘ä»¬çš„é“¾ä¸­ä½¿ç”¨å®ƒï¼Œæˆ‘ä»¬åªéœ€è¦åœ¨å°† messages è¾“å…¥ä¼ é€’ç»™æç¤ºä¹‹å‰è¿è¡Œä¿®å‰ªå™¨ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0a4d7ce-890f-40e1-8405-cca0d11f264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "    prompt = prompt_template.invoke(\n",
    "        {\"messages\": trimmed_messages, \"language\": state[\"language\"]}\n",
    "    )\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a26b47dc-67d9-4d4e-ba6b-660851950434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç°åœ¨ï¼Œå¦‚æœæˆ‘ä»¬å°è¯•è¯¢é—®æ¨¡å‹æˆ‘ä»¬çš„åå­—ï¼Œå®ƒå°†ä¸ä¼šçŸ¥é“ï¼Œå› ä¸ºæˆ‘ä»¬ä¿®å‰ªäº†èŠå¤©è®°å½•çš„é‚£ä¸€éƒ¨åˆ†ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1bb8944-5388-4202-97fc-1ee1923b5e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘æ— æ³•çŸ¥é“ä½ çš„åå­—ã€‚ä½ æ²¡æœ‰å‘Šè¯‰æˆ‘ä½ çš„åå­—ã€‚\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"What is my name?\"\n",
    "language = \"Chinese\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb325c6-619a-42e9-8a8d-c83828522c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½†å¦‚æœæˆ‘ä»¬è¯¢é—®æœ€è¿‘å‡ æ¡æ¶ˆæ¯ä¸­çš„ä¿¡æ¯ï¼Œå®ƒä¼šè®°ä½ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "992940e4-9b74-444e-80e3-cae4162364c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ä½ é—®çš„æ•°å­¦é—®é¢˜æ˜¯ï¼š2 + 2 ç­‰äºå¤šå°‘ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc678\"}}\n",
    "query = \"What math problem did I ask?\"\n",
    "language = \"Chinese\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324d4f6-b0a8-4c46-9a9f-1fc2e43887eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦‚æœæ‚¨çœ‹ä¸€ä¸‹ LangSmithï¼Œæ‚¨å°±å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ° LangSmith è·Ÿè¸ªä¸­å¹•åå‘ç”Ÿçš„äº‹æƒ…ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9b09a3-edd4-4977-91b6-b4d28c8df04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming(æµå¼ä¼ è¾“)\n",
    "# ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»æœ‰äº†ä¸€ä¸ªå¯ä»¥è¿è¡Œçš„èŠå¤©æœºå™¨äººã€‚ç„¶è€Œï¼Œå¯¹äºèŠå¤©æœºå™¨äººåº”ç”¨ç¨‹åºæ¥è¯´ï¼Œä¸€ä¸ªéå¸¸é‡è¦çš„ç”¨æˆ·ä½“éªŒè€ƒè™‘å› ç´ æ˜¯æµå¼ä¼ è¾“ã€‚LLM æœ‰æ—¶å¯èƒ½éœ€è¦ä¸€æ®µæ—¶é—´æ‰èƒ½å“åº”ï¼Œå› æ­¤ä¸ºäº†æå‡ç”¨æˆ·ä½“éªŒï¼Œå¤§å¤šæ•°åº”ç”¨ç¨‹åºéƒ½ä¼šåœ¨æ¯ä¸ªä»¤ç‰Œç”Ÿæˆæ—¶å°†å…¶æµå¼ä¼ è¾“å›æ¥ã€‚è¿™è®©ç”¨æˆ·èƒ½å¤Ÿçœ‹åˆ°è¿›åº¦ã€‚\n",
    "# é»˜è®¤æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„ LangGraph åº”ç”¨ç¨‹åºä¸­çš„ .stream ä¼šæµå¼ä¼ è¾“åº”ç”¨ç¨‹åºæ­¥éª¤â€”â€”åœ¨æœ¬ä¾‹ä¸­ï¼Œæ˜¯æ¨¡å‹å“åº”çš„å•ä¸ªæ­¥éª¤ã€‚è®¾ç½® stream_mode=\"messages\" å…è®¸æˆ‘ä»¬æ”¹ä¸ºæµå¼ä¼ è¾“è¾“å‡ºä»¤ç‰Œï¼š\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bce4d5d8-20ca-4eff-93ab-5865c5f7f012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½|å¥¥|ç‰¹æ›¼ï¼\n",
      "\n",
      "è¿™é‡Œæœ‰ä¸ªç¬‘è¯ç»™ä½ ï¼š\n",
      "\n",
      "ä¸ºä»€ä¹ˆå¥¥ç‰¹æ›¼æ€»æ˜¯|èµ¢ï¼Ÿ\n",
      "\n",
      "å› ä¸ºä»–æ€»æ˜¯â€œå¥¥ç‰¹â€ä¸€æŠŠï¼ (å› ä¸ºä»–æ€»æ˜¯â€œall| outâ€ ä¸€æŠŠï¼Œ â€œå¥¥ç‰¹â€ å’Œ â€œall outâ€ å‘éŸ³ç›¸ä¼¼)\n",
      "\n",
      "å¸Œæœ›ä½ å–œæ¬¢ï¼\n",
      "|"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n",
    "query = \"Hi I'm Ultraman, please tell me a joke.\"\n",
    "language = \"Chinese\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "for chunk, metadata in app.stream(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if isinstance(chunk, AIMessage):  # Filter to just model responses\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80c695-c532-41f3-8dd5-fd208acfb580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74bdef5-6a59-41a4-bf42-76b3f19d6ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac673e1-1211-491d-8822-690d73f1b117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
