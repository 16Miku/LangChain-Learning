{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886ca6c9-ce4a-414a-9b9b-1e9c8176674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# LangGraphå®˜æ–¹æ–‡æ¡£æ•™ç¨‹\n",
    "# https://langchain-ai.github.io/langgraph/tutorials/get-started/6-time-travel/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f5fb10-0af2-4b3c-8cfc-890c3dec111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time travelÂ¶  æ—¶é—´æ—…è¡Œ Â¶\n",
    "# In a typical chatbot workflow, the user interacts with the bot one or more times to accomplish a task. Memory and a human-in-the-loop enable checkpoints in the graph state and control future responses.\n",
    "# åœ¨å…¸å‹çš„èŠå¤©æœºå™¨äººå·¥ä½œæµç¨‹ä¸­ï¼Œç”¨æˆ·éœ€è¦ä¸æœºå™¨äººè¿›è¡Œä¸€æ¬¡æˆ–å¤šæ¬¡äº¤äº’æ‰èƒ½å®Œæˆä¸€é¡¹ä»»åŠ¡ã€‚ è®°å¿†å’Œäººæœºäº¤äº’æœºåˆ¶ä¼šåœ¨å›¾å½¢çŠ¶æ€ä¸­å¯ç”¨æ£€æŸ¥ç‚¹ï¼Œå¹¶æ§åˆ¶æœªæ¥çš„å“åº”ã€‚\n",
    "\n",
    "# What if you want a user to be able to start from a previous response and explore a different outcome? Or what if you want users to be able to rewind your chatbot's work to fix mistakes or try a different strategy, something that is common in applications like autonomous software engineers?\n",
    "# å¦‚æœæ‚¨å¸Œæœ›ç”¨æˆ·èƒ½å¤Ÿä»ä¹‹å‰çš„å›å¤å¼€å§‹ï¼Œæ¢ç´¢ä¸åŒçš„ç»“æœï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿæˆ–è€…ï¼Œå¦‚æœæ‚¨å¸Œæœ›ç”¨æˆ·èƒ½å¤Ÿå›æ”¾èŠå¤©æœºå™¨äººçš„å·¥ä½œä»¥ä¿®å¤é”™è¯¯æˆ–å°è¯•ä¸åŒçš„ç­–ç•¥ï¼ˆè¿™åœ¨è‡ªä¸»è½¯ä»¶å·¥ç¨‹å¸ˆç­‰åº”ç”¨ä¸­å¾ˆå¸¸è§ï¼‰ï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿ\n",
    "\n",
    "# You can create these types of experiences using LangGraph's built-in time travel functionality.\n",
    "# æ‚¨å¯ä»¥ä½¿ç”¨ LangGraph çš„å†…ç½®æ—¶é—´æ—…è¡ŒåŠŸèƒ½æ¥åˆ›å»ºè¿™äº›ç±»å‹çš„ä½“éªŒã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecc82861-2113-44e8-bf69-1f8eac8a6dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note  ç¬”è®°\n",
    "\n",
    "# This tutorial builds on Customize state.\n",
    "# æœ¬æ•™ç¨‹ä»¥è‡ªå®šä¹‰çŠ¶æ€ä¸ºåŸºç¡€ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2bd56ae-43fc-4834-b303-fb95c5391c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Rewind your graphÂ¶\n",
    "# 1. å›æ”¾ä½ çš„å›¾è¡¨ Â¶\n",
    "# Rewind your graph by fetching a checkpoint using the graph's get_state_history method. You can then resume execution at this previous point in time.\n",
    "# ä½¿ç”¨å›¾çš„ get_state_history æ–¹æ³•è·å–æ£€æŸ¥ç‚¹ï¼Œå³å¯å›æº¯å›¾ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥ä»è¯¥æ—¶é—´ç‚¹æ¢å¤æ‰§è¡Œã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34b31409-d57d-4abd-be8e-f6ce381be9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U \"langchain[google-genai]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f72d58c-3ebb-48f4-866d-d945eeb245d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd846a1-da05-4f4d-84b2-77293b6cb4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e64a4ea8-176f-4d0a-9fb2-1c47b7c9fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Add stepsÂ¶\n",
    "# 2. æ·»åŠ æ­¥éª¤ Â¶\n",
    "# Add steps to your graph. Every step will be checkpointed in its state history:\n",
    "# å‘å›¾è¡¨ä¸­æ·»åŠ æ­¥éª¤ã€‚æ¯ä¸ªæ­¥éª¤éƒ½ä¼šåœ¨å…¶çŠ¶æ€å†å²è®°å½•ä¸­è®¾ç½®æ£€æŸ¥ç‚¹ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb99df7-3e32-4f46-afae-0801851c2a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (320b91d6-6d93-4ce5-89cd-a6babb81a1a2)\n",
      " Call ID: 320b91d6-6d93-4ce5-89cd-a6babb81a1a2\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "    search_depth: advanced\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.ibm.com/think/topics/langgraph\", \"title\": \"What is LangGraph? - IBM\", \"content\": \"LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. [...] Agent systems: LangGraph provides a framework for building agent-based systems, which can be used in applications such as robotics, autonomous vehicles or video games.\\n\\nLLM applications: By using LangGraphâ€™s capabilities, developers can build more sophisticated AI models that learn and improve over time. Norwegian Cruise Line uses LangGraph to compile, construct and refine guest-facing AI solutions. This capability allows for improved and personalized guest experiences. [...] By using a graph-based architecture, LangGraph enables users to scale artificial intelligence workflows without slowing down or sacrificing efficiency. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback. In the world of LLMs, this process is referred to as reflection.\", \"score\": 0.9353998, \"raw_content\": null}, {\"url\": \"https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141\", \"title\": \"Introduction to LangGraph: A Beginner's Guide - Medium\", \"content\": \"What is LangGraph?\\n==================\\n\\nLangGraph is a library built on top of LangChain, designed to add cyclic computational capabilities to your LLM applications. While LangChain allows you to define chains of computation (Directed Acyclic Graphs or DAGs), LangGraph introduces the ability to add cycles, enabling more complex, agent-like behaviors where you can call an LLM in a loop, asking it what action to take next.\\n\\nKey Concepts\\n============\", \"score\": 0.91362286, \"raw_content\": null}], \"response_time\": 1.96}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is an open-source AI agent framework created by LangChain. It's designed for building, deploying, and managing complex generative AI agent workflows. It provides tools and libraries to create, run, and optimize large language models (LLMs) in a scalable and efficient manner, using graph-based architectures to model the relationships between components. LangGraph allows you to add cycles, enabling more complex, agent-like behaviors where you can call an LLM in a loop, asking it what action to take next. It enhances decision-making by modeling complex relationships between nodes, using AI agents to analyze their past actions and feedback.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"I'm learning LangGraph. \"\n",
    "                    \"Could you do some research on it for me?\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eb46a39-c97f-455c-bc40-90599046bcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a great project! Let me know if you have any further questions about LangGraph or need help with anything else as you build your autonomous agent.\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Ya that's helpful. Maybe I'll \"\n",
    "                    \"build an autonomous agent with it!\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d55f0f10-e64e-4ae9-b22e-c4bdd522bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Replay the full state historyÂ¶\n",
    "# 3. é‡æ”¾å®Œæ•´çš„çŠ¶æ€å†å² Â¶\n",
    "# Now that you have added steps to the chatbot, you can replay the full state history to see everything that occurred.\n",
    "# ç°åœ¨æ‚¨å·²ç»å‘èŠå¤©æœºå™¨äººæ·»åŠ äº†æ­¥éª¤ï¼Œæ‚¨å¯ä»¥ replay å®Œæ•´çš„çŠ¶æ€å†å²è®°å½•ä»¥æŸ¥çœ‹å‘ç”Ÿçš„æ‰€æœ‰äº‹æƒ…ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "107b3df8-d4c3-4f6a-9ef1-626954b485b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8477a873-4951-4fe3-8fdc-fc73cf66c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints are saved for every step of the graph. This spans invocations so you can rewind across a full thread's history.\n",
    "# æ£€æŸ¥ç‚¹ä¼šä¿å­˜å›¾è¡¨ä¸­æ¯ä¸€æ­¥çš„æ‰§è¡Œæƒ…å†µã€‚è¿™æ¶µç›–äº†æ‰€æœ‰è°ƒç”¨ ï¼Œå› æ­¤æ‚¨å¯ä»¥å›æº¯æ•´ä¸ªçº¿ç¨‹çš„å†å²è®°å½•ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e15e4d-1e62-4ae3-83a6-233938c3efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume from a checkpointÂ¶\n",
    "# ä»æ£€æŸ¥ç‚¹æ¢å¤ Â¶\n",
    "# Resume from the to_replay state, which is after the chatbot node in the second graph invocation. Resuming from this point will call the action node next.\n",
    "# ä» to_replay çŠ¶æ€æ¢å¤ï¼Œè¯¥çŠ¶æ€ä½äºç¬¬äºŒæ¬¡å›¾è¡¨è°ƒç”¨ä¸­çš„ chatbot æœºå™¨äººèŠ‚ç‚¹ä¹‹åã€‚ä»æ­¤å¤„æ¢å¤å°†è°ƒç”¨æ¥ä¸‹æ¥çš„æ“ä½œèŠ‚ç‚¹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fa37e90-2e0d-46b7-9c96-e2cc3ed486ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f060eae-d703-6b6f-8006-98c0fe53cc48'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "351bf6b0-00dd-4534-a341-1c93e5b7cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load a state from a moment-in-timeÂ¶\n",
    "# 4. åŠ è½½æŸä¸ªæ—¶åˆ»çš„çŠ¶æ€ Â¶\n",
    "# The checkpoint's to_replay.config contains a checkpoint_id timestamp. Providing this checkpoint_id value tells LangGraph's checkpointer to load the state from that moment in time.\n",
    "# æ£€æŸ¥ç‚¹çš„ to_replay.config æ–‡ä»¶åŒ…å«ä¸€ä¸ª checkpoint_id æ—¶é—´æˆ³ã€‚æä¾›æ­¤ checkpoint_id å€¼ä¼šå‘ŠçŸ¥ LangGraph çš„æ£€æŸ¥ç‚¹ç¨‹åºä»è¯¥æ—¶åˆ»å¼€å§‹åŠ è½½çŠ¶æ€ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97a8933d-a550-4820-8a41-6cc2aa7e201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a great project! Let me know if you have any further questions about LangGraph or need help with anything else as you build your autonomous agent.\n"
     ]
    }
   ],
   "source": [
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c2452-ab7d-434f-944b-11d0bca5513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Congratulations! You've now used time-travel checkpoint traversal in LangGraph. Being able to rewind and explore alternative paths opens up a world of possibilities for debugging, experimentation, and interactive applications.\n",
    "# æ­å–œï¼ æ‚¨ç°åœ¨å·²ç»åœ¨ LangGraph ä¸­ä½¿ç”¨äº†æ—¶é—´æ—…è¡Œæ£€æŸ¥ç‚¹éå†ã€‚èƒ½å¤Ÿå›æº¯å¹¶æ¢ç´¢å…¶ä»–è·¯å¾„ï¼Œä¸ºè°ƒè¯•ã€å®éªŒå’Œäº¤äº’å¼åº”ç”¨ç¨‹åºå¼€è¾Ÿäº†æ— é™å¯èƒ½ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d1be7-ca77-46bd-a889-9e9313dd24bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec0ec6-1da7-4563-96fd-2e08f8691ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f3e01-705f-43ff-a488-3be0f313adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦‚ä½•è‡ªç”±åœ°é€‰æ‹©è¦å›æº¯çš„å†å²è®°å½•å¹¶å±•å¼€å¯¹è¯ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59033441-1aea-461d-8240-2f6d1380171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‚¨å¥½ï¼è¦åœ¨ LangGraph ä¸­è‡ªç”±åœ°é€‰æ‹©è¦å›æº¯çš„å†å²è®°å½•å¹¶å±•å¼€å¯¹è¯ï¼Œæ ¸å¿ƒåœ¨äºåˆ©ç”¨ LangGraph çš„**æ£€æŸ¥ç‚¹ï¼ˆCheckpointerï¼‰**åŠŸèƒ½ã€‚æ‚¨çš„ `ChatbotWithTimeTravel.ipynb` æ–‡ä»¶å·²ç»åŒ…å«äº†å®ç°è¿™ä¸€åŠŸèƒ½çš„åŸºç¡€ã€‚\n",
    "\n",
    "# LangGraph çš„ `checkpointer` ä¼šåœ¨å›¾çš„æ¯ä¸€æ­¥æ‰§è¡Œåä¿å­˜å½“å‰çŠ¶æ€ã€‚è¿™äº›ä¿å­˜çš„çŠ¶æ€è¢«ç§°ä¸ºâ€œæ£€æŸ¥ç‚¹â€ã€‚é€šè¿‡ `graph.get_state_history()` æ–¹æ³•ï¼Œæ‚¨å¯ä»¥è·å–åˆ°ä¸€ä¸ªç‰¹å®šå¯¹è¯çº¿ç¨‹çš„æ‰€æœ‰å†å²æ£€æŸ¥ç‚¹ã€‚æ¯ä¸ªæ£€æŸ¥ç‚¹éƒ½æ˜¯ä¸€ä¸ª `StateSnapshot` å¯¹è±¡ï¼Œå®ƒåŒ…å«äº†å½“æ—¶çš„å›¾çŠ¶æ€ (`state.values`) ä»¥åŠæ¢å¤åˆ°è¯¥çŠ¶æ€æ‰€éœ€çš„é…ç½® (`state.config`)ã€‚\n",
    "\n",
    "# ### å®ç°â€œæ—¶é—´æ—…è¡Œâ€çš„æ­¥éª¤å’ŒåŸç†\n",
    "\n",
    "# 1.  **ä¿å­˜å†å²è®°å½•ï¼š**\n",
    "#     å½“æ‚¨ä½¿ç”¨ `graph.compile(checkpointer=memory)` ç¼–è¯‘å›¾æ—¶ï¼Œå¹¶ä¸ºæ¯æ¬¡ `graph.stream()` æˆ– `graph.invoke()` è°ƒç”¨æä¾›ä¸€ä¸ªå”¯ä¸€çš„ `thread_id`ï¼ˆä¾‹å¦‚ `config = {\"configurable\": {\"thread_id\": \"1\"}}`ï¼‰ï¼ŒLangGraph å°±ä¼šè‡ªåŠ¨ä¸ºæ‚¨ä¿å­˜æ¯æ¬¡äº¤äº’çš„å®Œæ•´å›¾çŠ¶æ€å†å²ã€‚\n",
    "\n",
    "# 2.  **è·å–å†å²æ£€æŸ¥ç‚¹ï¼š**\n",
    "#     ä½¿ç”¨ `graph.get_state_history(config)` æ–¹æ³•å¯ä»¥è·å–åˆ°æŒ‡å®š `thread_id` çš„æ‰€æœ‰ `StateSnapshot` å¯¹è±¡ã€‚è¿™äº› `StateSnapshot` æ˜¯æŒ‰æ—¶é—´å€’åºæ’åˆ—çš„ï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰ã€‚\n",
    "\n",
    "# 3.  **é€‰æ‹©å›æº¯ç‚¹ï¼š**\n",
    "#     æ‚¨å¯ä»¥éå†è¿™äº› `StateSnapshot`ï¼Œå‘ç”¨æˆ·å±•ç¤ºæ¯ä¸ªå†å²ç‚¹çš„æ‘˜è¦ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œå½“æ—¶çš„æ¶ˆæ¯æ•°é‡ã€æœ€åä¸€æ¡æ¶ˆæ¯çš„å†…å®¹ç­‰ï¼‰ï¼Œç„¶åè®©ç”¨æˆ·é€‰æ‹©ä¸€ä¸ªæƒ³è¦å›æº¯çš„ç‰¹å®šæ£€æŸ¥ç‚¹ã€‚æ¯ä¸ª `StateSnapshot` éƒ½æœ‰ä¸€ä¸ª `config` å±æ€§ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ª `checkpoint_id`ï¼Œè¿™æ˜¯è¯¥ç‰¹å®šå†å²çŠ¶æ€çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚\n",
    "\n",
    "# 4.  **ä»æ£€æŸ¥ç‚¹æ¢å¤å¯¹è¯ï¼š**\n",
    "#     ä¸€æ—¦ç”¨æˆ·é€‰æ‹©äº†æŸä¸ªå†å²æ£€æŸ¥ç‚¹ï¼Œæ‚¨å°±å¯ä»¥ä½¿ç”¨è¯¥æ£€æŸ¥ç‚¹çš„ `config` æ¥è°ƒç”¨ `graph.stream()`ã€‚å½“ `graph.stream()` çš„ç¬¬ä¸€ä¸ªå‚æ•°ï¼ˆå³è¾“å…¥æ¶ˆæ¯ï¼‰ä¸º `None` æ—¶ï¼Œå®ƒä¼šå°è¯•ä»æä¾›çš„ `config` ä¸­åŠ è½½çŠ¶æ€å¹¶ç»§ç»­æ‰§è¡Œã€‚å¦‚æœæä¾›äº†æ–°çš„ç”¨æˆ·è¾“å…¥ï¼Œå®ƒä¼šä»è¯¥æ£€æŸ¥ç‚¹åŠ è½½çŠ¶æ€ï¼Œç„¶åå¤„ç†æ–°çš„è¾“å…¥ã€‚\n",
    "\n",
    "# ### äº¤äº’å¼ä»£ç ç¤ºä¾‹\n",
    "\n",
    "# ä»¥ä¸‹ä»£ç æ¼”ç¤ºäº†å¦‚ä½•åœ¨æ‚¨çš„ Jupyter Notebook ä¸­å®ç°ä¸€ä¸ªç®€å•çš„äº¤äº’å¼â€œæ—¶é—´æ—…è¡Œâ€åŠŸèƒ½ã€‚å®ƒä¼šå…ˆè¿›è¡Œä¸€æ®µå¯¹è¯ï¼Œç„¶ååˆ—å‡ºå†å²è®°å½•ï¼Œè®©ç”¨æˆ·é€‰æ‹©ä¸€ä¸ªæ—¶é—´ç‚¹ï¼Œæœ€åä»è¯¥æ—¶é—´ç‚¹ç»§ç»­å¯¹è¯ã€‚\n",
    "\n",
    "# è¯·ç¡®ä¿æ‚¨å·²ç»è¿è¡Œäº† `ChatbotWithTimeTravel.ipynb` ä¸­æ‰€æœ‰ä¹‹å‰çš„ä»£ç å•å…ƒæ ¼ï¼ˆç‰¹åˆ«æ˜¯è®¾ç½® API å¯†é’¥å’Œæ„å»ºå›¾çš„éƒ¨åˆ†ï¼‰ï¼Œä»¥ç¡®ä¿ `graph` å’Œ `config` å˜é‡å¯ç”¨ã€‚\n",
    "\n",
    "# **æ–°çš„ä»£ç å•å…ƒæ ¼ï¼š**\n",
    "\n",
    "\n",
    "# ### ä»£ç è¯´æ˜ï¼š\n",
    "\n",
    "# 1.  **`run_conversation_and_show_history` å‡½æ•°ï¼š**\n",
    "#     *   è¿™ä¸ªå‡½æ•°å°è£…äº†æ•´ä¸ªäº¤äº’æµç¨‹ï¼Œæ¥å—ä¸€ä¸ªåˆå§‹ç”¨æˆ·è¾“å…¥å’Œä¸€ä¸ª `thread_id`ã€‚\n",
    "#     *   å®ƒé¦–å…ˆè¿›è¡Œå‡ æ¬¡å¯¹è¯ï¼Œä»¥ç§¯ç´¯ä¸€äº›å†å²è®°å½•ã€‚\n",
    "#     *   ç„¶åï¼Œå®ƒé€šè¿‡ `graph.get_state_history(current_config)` è·å–å½“å‰çº¿ç¨‹çš„æ‰€æœ‰å†å²æ£€æŸ¥ç‚¹ã€‚\n",
    "#     *   ä¸ºäº†æ–¹ä¾¿ç”¨æˆ·é€‰æ‹©ï¼Œå®ƒå°†å†å²è®°å½•åè½¬ä¸ºæ­£åºï¼ˆä»æœ€æ—§åˆ°æœ€æ–°ï¼‰ï¼Œå¹¶æ‰“å°å‡ºæ¯ä¸ªå†å²ç‚¹çš„åºå·ã€æ¶ˆæ¯æ•°é‡ã€æœ€åä¸€æ¡æ¶ˆæ¯çš„æ‘˜è¦ä»¥åŠä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹ã€‚\n",
    "#     *   å®ƒè¿›å…¥ä¸€ä¸ªå¾ªç¯ï¼Œæç¤ºç”¨æˆ·è¾“å…¥æƒ³è¦å›æº¯åˆ°çš„å†å²ç‚¹åºå·ï¼Œæˆ–è€…é€‰æ‹©ç»§ç»­å½“å‰å¯¹è¯ï¼Œæˆ–è€…é€€å‡ºã€‚\n",
    "#     *   å¦‚æœç”¨æˆ·é€‰æ‹©äº†å›æº¯ç‚¹ï¼Œå®ƒä¼šä½¿ç”¨è¯¥å†å²ç‚¹çš„ `StateSnapshot.config` ä½œä¸ºæ–°çš„é…ç½®æ¥è°ƒç”¨ `graph.stream(None, selected_snapshot.config, ...)`ã€‚è¿™é‡Œçš„ `None` è¡¨ç¤ºæˆ‘ä»¬ä¸æ˜¯ç»™å›¾æä¾›æ–°çš„è¾“å…¥ï¼Œè€Œæ˜¯åŠ è½½å¹¶æ¢å¤åˆ°é‚£ä¸ªå†å²çŠ¶æ€ã€‚\n",
    "#     *   æ¢å¤åï¼Œå®ƒä¼šæ‰“å°å‡ºè¯¥å†å²ç‚¹çš„å¯¹è¯å†…å®¹ï¼Œå¹¶å…è®¸ç”¨æˆ·è¾“å…¥æ–°çš„é—®é¢˜ï¼Œä»è€Œåœ¨é‚£ä¸ªå†å²åˆ†æ”¯ä¸Šå±•å¼€æ–°çš„å¯¹è¯ã€‚\n",
    "#     *   å¦‚æœç”¨æˆ·é€‰æ‹©ä¸å›æº¯ï¼Œåˆ™ç»§ç»­åœ¨å½“å‰å¯¹è¯çš„æœ€æ–°çŠ¶æ€ä¸Šè¿›è¡Œäº¤äº’ã€‚\n",
    "\n",
    "# 2.  **`uuid.uuid4()`ï¼š**\n",
    "#     ä¸ºäº†ç¡®ä¿æ¯æ¬¡è¿è¡Œæ­¤ç¤ºä¾‹æ—¶éƒ½æœ‰ä¸€ä¸ªç‹¬ç«‹çš„å¯¹è¯å†å²ï¼Œæˆ‘ä½¿ç”¨äº† `uuid.uuid4()` æ¥ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„ `thread_id`ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œ`thread_id` é€šå¸¸ä¸ç”¨æˆ·ä¼šè¯æˆ–èŠå¤©å®¤ç›¸å…³è”ã€‚\n",
    "\n",
    "# 3.  **`graph.stream(None, to_replay.config, stream_mode=\"values\")`ï¼š**\n",
    "#     è¿™æ˜¯å®ç°æ—¶é—´æ—…è¡Œçš„å…³é”®ã€‚å½“æ‚¨å°† `stream()` çš„ç¬¬ä¸€ä¸ªå‚æ•°ï¼ˆè¾“å…¥æ¶ˆæ¯ï¼‰è®¾ç½®ä¸º `None` æ—¶ï¼ŒLangGraph ä¼šæ ¹æ®ä¼ å…¥çš„ `config`ï¼ˆå…¶ä¸­åŒ…å«äº† `checkpoint_id`ï¼‰ä»æ£€æŸ¥ç‚¹åŠ è½½å®Œæ•´çš„å†å²çŠ¶æ€ï¼Œå¹¶ä»è¯¥ç‚¹å¼€å§‹ç»§ç»­æ‰§è¡Œã€‚è¿™æ„å‘³ç€æ‚¨å¯ä»¥ä»å†å²çš„ä»»ä½•ä¸€ä¸ªç‚¹â€œå¤æ´»â€å¯¹è¯ï¼Œå¹¶ä»é‚£é‡Œå¼€å§‹æ–°çš„äº¤äº’åˆ†æ”¯ã€‚\n",
    "\n",
    "# ### å¦‚ä½•è¿è¡Œï¼š\n",
    "\n",
    "# 1.  ç¡®ä¿æ‚¨çš„ Jupyter Notebook ç¯å¢ƒä¸­å·²å®‰è£…æ‰€æœ‰å¿…è¦çš„åº“ (`langgraph`, `langchain-tavily`, `langchain[google-genai]`)ã€‚\n",
    "# 2.  ç¡®ä¿æ‚¨å·²æ­£ç¡®è®¾ç½® `GOOGLE_API_KEY` å’Œ `TAVILY_API_KEY` ç¯å¢ƒå˜é‡ï¼ˆæˆ–è€…é€šè¿‡ `getpass.getpass()` æ‰‹åŠ¨è¾“å…¥ï¼‰ã€‚\n",
    "# 3.  æŒ‰é¡ºåºè¿è¡Œ `ChatbotWithTimeTravel.ipynb` ä¸­æ‰€æœ‰ä¹‹å‰çš„ä»£ç å•å…ƒæ ¼ã€‚\n",
    "# 4.  å°†ä¸Šè¿°æä¾›çš„å®Œæ•´ä»£ç ç²˜è´´åˆ°ä¸€ä¸ªæ–°çš„ä»£ç å•å…ƒæ ¼ä¸­ï¼Œç„¶åè¿è¡Œå®ƒã€‚\n",
    "\n",
    "# æ‚¨å°†çœ‹åˆ°ä¸€ä¸ªäº¤äº’å¼ç•Œé¢ï¼Œå…è®¸æ‚¨ä½“éªŒ LangGraph çš„â€œæ—¶é—´æ—…è¡Œâ€åŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65f164a3-b302-41fb-9596-34adc7ccf1da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- å¼€å§‹æ–°å¯¹è¯çº¿ç¨‹: 86abd04f-e0c7-40a3-8376-9ae7af827eb1 ---\n",
      "User: Hi, I'm Bob. What is LangGraph?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I'm Bob. What is LangGraph?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (8e60b593-25e6-4b48-90ec-29232bc68a52)\n",
      " Call ID: 8e60b593-25e6-4b48-90ec-29232bc68a52\n",
      "  Args:\n",
      "    topic: general\n",
      "    query: What is LangGraph?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"What is LangGraph?\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"title\": \"LangGraph Tutorial: What Is LangGraph and How to Use It?\", \"content\": \"LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.\", \"score\": 0.9581988, \"raw_content\": null}, {\"url\": \"https://www.ibm.com/think/topics/langgraph\", \"title\": \"What is LangGraph? - IBM\", \"content\": \"LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. LangGraph illuminates the processes within an AI workflow, allowing full transparency of the agentâ€™s state. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including chatbots, state graphs and other agent-based systems. Nodes: In LangGraph, nodes represent individual components or agents within an AI workflow. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback.\", \"score\": 0.9554898, \"raw_content\": null}], \"response_time\": 1.51}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a framework within the LangChain ecosystem designed for building, deploying, and managing complex generative AI agent workflows. It uses graph-based architectures to model the relationships between different components of an AI agent workflow, allowing for transparency and enhanced decision-making. It simplifies the development of complex LLM applications by providing a structured way to manage state and coordinate agent interactions.\n",
      "\n",
      "User: Tell me more about its applications.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me more about its applications.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (dcf4e761-2452-4f86-81af-32033eec5b42)\n",
      " Call ID: dcf4e761-2452-4f86-81af-32033eec5b42\n",
      "  Args:\n",
      "    topic: general\n",
      "    query: LangGraph applications\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph applications\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.langchain.com/langgraph\", \"title\": \"LangGraph - LangChain\", \"content\": \"Design agent-driven user experiences with LangGraph Platform's APIs. Quickly deploy and scale your application with infrastructure built for agents. LangGraph sets the foundation for how we can build and scale AI workloads â€” from conversational agents, complex task automation, to custom LLM-backed experiences that 'just work'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution to iterate quickly, debug immediately, and scale effortlessly.â€ LangGraph sets the foundation for how we can build and scale AI workloads â€” from conversational agents, complex task automation, to custom LLM-backed experiences that 'just work'. LangGraph Platform is a service for deploying and scaling LangGraph applications, with an opinionated API for building agent UXs, plus an integrated developer studio.\", \"score\": 0.8014549, \"raw_content\": null}, {\"url\": \"https://langchain-ai.github.io/langgraph/concepts/application_structure/\", \"title\": \"Application structure - GitHub Pages\", \"content\": \"Published Time: Mon, 07 Jul 2025 00:42:09 GMT Skip to content *   Time travel *   Plans & pricing *   Scalability & resilience Application StructureÂ¶ This guide shows a typical structure of an application and shows how the required information to deploy an application using the LangGraph Platform is specified. Below are examples of directory structures for Python and JavaScript applications: The `langgraph.json` file is a JSON file that specifies the dependencies, graphs, environment variables, and other settings required to deploy a LangGraph application. Each graph is identified by a name (which should be unique) and a path for either: (1) the compiled graph or (2) a function that makes a graph is defined. Back to top Previous Plans & pricingNext Scalability & resilience\", \"score\": 0.7311551, \"raw_content\": null}], \"response_time\": 1.33}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph can be used for:\n",
      "\n",
      "*   **Conversational agents:** Building chatbots that can handle various user requests.\n",
      "*   **Complex task automation:** Automating intricate tasks by coordinating multiple agents.\n",
      "*   **Custom LLM-backed experiences:** Creating tailored experiences powered by large language models.\n",
      "\n",
      "User: Can it be used for emotional support chatbots?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can it be used for emotional support chatbots?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (113569a2-ab20-4721-ae87-9af836b3f82a)\n",
      " Call ID: 113569a2-ab20-4721-ae87-9af836b3f82a\n",
      "  Args:\n",
      "    topic: general\n",
      "    query: LangGraph emotional support chatbot\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph emotional support chatbot\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.youtube.com/watch?v=b3XsvoFWp4c\", \"title\": \"Build a Customer Support Bot | LangGraph - YouTube\", \"content\": \"Build a Customer Support Bot | LangGraph LangChain 1530 likes 71244 views 7 May 2024 Build a Customer Support Chatbot | LangGraph In this tutorial, we create a travel assistant chatbot using LangGraph, demonstrating reusable techniques applicable to building any customer support chatbot or AI system that uses tools, supports many user journeys, or requires a high degree of control. Zero-Shot Tool Executor: In the first part, we develop a simple agent with an LLM and tools, showing the limitations of this flat design for complex experiences. User Confirmation: In the second part, we add user confirmation before the agent takes any sensitive actions, giving the user more control but at the cost of a less autonomous experience. Conditional Interrupts: In the third part, we split tools into \\\"safe\\\" and \\\"sensitive\\\" categories, only requiring user confirmation on sensitive actions. Specialized Workflows: In the fourth part, we separate user journeys into specific \\\"skills\\\" or \\\"workflows\\\". By the end of this tutorial, you'll understand key principles for designing customer support chatbots, balancing expressiveness and control to create delightful user experiences.\", \"score\": 0.66203266, \"raw_content\": null}, {\"url\": \"https://python.langchain.com/docs/tutorials/chatbot/\", \"title\": \"Build a Chatbot | ğŸ¦œï¸   LangChain\", \"content\": \"`from langgraph.checkpoint.memory import MemorySaverfrom langgraph.graph import START, MessagesState, StateGraph# Define a new graphworkflow = StateGraph(state_schema=MessagesState)# Define the function that calls the modeldef call_model(state: MessagesState):    response = model.invoke(state[\\\"messages\\\"])    return {\\\"messages\\\": response}# Define the (single) node in the graphworkflow.add_edge(START, \\\"model\\\")workflow.add_node(\\\"model\\\", call_model)# Add memorymemory = MemorySaver()app = workflow.compile(checkpointer=memory)` `from typing import Sequencefrom langchain_core.messages import BaseMessagefrom langgraph.graph.message import add_messagesfrom typing_extensions import Annotated, TypedDictclass State(TypedDict):    messages: Annotated[Sequence[BaseMessage], add_messages]    language: strworkflow = StateGraph(state_schema=State)def call_model(state: State):    prompt = prompt_template.invoke(state)    response = model.invoke(prompt)    return {\\\"messages\\\": [response]}workflow.add_edge(START, \\\"model\\\")workflow.add_node(\\\"model\\\", call_model)memory = MemorySaver()app = workflow.compile(checkpointer=memory)` `config = {\\\"configurable\\\": {\\\"thread_id\\\": \\\"abc789\\\"}}query = \\\"Hi I'm Todd, please tell me a joke.\\\"language = \\\"English\\\"input_messages = [HumanMessage(query)]for chunk, metadata in app.stream(    {\\\"messages\\\": input_messages, \\\"language\\\": language},    config,    stream_mode=\\\"messages\\\",):    if isinstance(chunk, AIMessage):  # Filter to just model responses        print(chunk.content, end=\\\"|\\\")`\", \"score\": 0.502564, \"raw_content\": null}], \"response_time\": 1.33}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "While the search results don't explicitly confirm LangGraph's use in *emotional* support chatbots, the technology is well-suited for customer support bots. With careful design and the right prompts, it seems feasible to adapt LangGraph for emotional support. Considerations would include:\n",
      "\n",
      "*   **Training Data:** Fine-tuning the LLMs with data that includes empathetic responses and an understanding of emotional cues.\n",
      "*   **Ethical Considerations:** Implementing safeguards to prevent the chatbot from giving harmful advice or posing as a human therapist.\n",
      "*   **Context Management:** Using LangGraph's state management to track the user's emotional state and tailor responses accordingly.\n",
      "*   **Specialized workflows:** Creating workflows that direct users to professional help when necessary.\n",
      "\n",
      "--- å¯¹è¯å†å²è®°å½• ---\n",
      "[0] Checkpoint ID: 1f060ed8-9ba1-61af-bfff-a97a2e9a63c3\n",
      "    æ¶ˆæ¯æ•°é‡: 0\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: No messages at this state...\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ('__start__',)\n",
      "------------------------------\n",
      "[1] Checkpoint ID: 1f060ed8-9ba6-600e-8000-faeea06c7fb8\n",
      "    æ¶ˆæ¯æ•°é‡: 1\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: Hi, I'm Bob. What is LangGraph?...\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ('chatbot',)\n",
      "------------------------------\n",
      "[2] Checkpoint ID: 1f060ed8-ab2e-6fb3-8001-13d58599cd00\n",
      "    æ¶ˆæ¯æ•°é‡: 2\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: ...\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ('tools',)\n",
      "------------------------------\n",
      "[3] Checkpoint ID: 1f060ed8-cbce-68c2-8002-c217f8d46509\n",
      "    æ¶ˆæ¯æ•°é‡: 3\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: {\"query\": \"What is LangGraph?\", \"follow_up_questions\": null, \"answer\": null, \"im...\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ('chatbot',)\n",
      "------------------------------\n",
      "[4] Checkpoint ID: 1f060ed8-d5a9-66f5-8003-80b571c9e522\n",
      "    æ¶ˆæ¯æ•°é‡: 4\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: LangGraph is a framework within the LangChain ecosystem designed for building, d...\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ()\n",
      "------------------------------\n",
      "[5] Checkpoint ID: 1f060ed8-d5ac-6629-8004-8ea28566ee79\n",
      "    æ¶ˆæ¯æ•°é‡: 4\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: LangGraph is a framework within the LangChain ecosystem designed for building, d...\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ('__start__',)\n",
      "------------------------------\n",
      "[6] Checkpoint ID: 1f060ed8-d5b0-6241-8005-4a52af41c97c\n",
      "    æ¶ˆæ¯æ•°é‡: 5\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: Tell me more about its applications....\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ('chatbot',)\n",
      "------------------------------\n",
      "[7] Checkpoint ID: 1f060ed8-dedd-6f2e-8006-4b0d245fc9d0\n",
      "    æ¶ˆæ¯æ•°é‡: 6\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: ...\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ('tools',)\n",
      "------------------------------\n",
      "[8] Checkpoint ID: 1f060ed8-fa96-6e3d-8007-07dacb2a96fe\n",
      "    æ¶ˆæ¯æ•°é‡: 7\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: {\"query\": \"LangGraph applications\", \"follow_up_questions\": null, \"answer\": null,...\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ('chatbot',)\n",
      "------------------------------\n",
      "[9] Checkpoint ID: 1f060ed9-05f2-6a7e-8008-ecdc83d2f8b0\n",
      "    æ¶ˆæ¯æ•°é‡: 8\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: LangGraph can be used for:\n",
      "\n",
      "*   **Conversational agents:** Building chatbots tha...\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ()\n",
      "------------------------------\n",
      "[10] Checkpoint ID: 1f060ed9-05f7-6c2e-8009-9b6a3020cc6a\n",
      "    æ¶ˆæ¯æ•°é‡: 8\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: LangGraph can be used for:\n",
      "\n",
      "*   **Conversational agents:** Building chatbots tha...\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ('__start__',)\n",
      "------------------------------\n",
      "[11] Checkpoint ID: 1f060ed9-05fa-62f0-800a-e555297246db\n",
      "    æ¶ˆæ¯æ•°é‡: 9\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: Can it be used for emotional support chatbots?...\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ('chatbot',)\n",
      "------------------------------\n",
      "[12] Checkpoint ID: 1f060ed9-0eb8-61fc-800b-b86b68a008e0\n",
      "    æ¶ˆæ¯æ•°é‡: 10\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: ...\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ('tools',)\n",
      "------------------------------\n",
      "[13] Checkpoint ID: 1f060ed9-2f5b-6b40-800c-9567a80107a0\n",
      "    æ¶ˆæ¯æ•°é‡: 11\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: {\"query\": \"LangGraph emotional support chatbot\", \"follow_up_questions\": null, \"a...\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ('chatbot',)\n",
      "------------------------------\n",
      "[14] Checkpoint ID: 1f060ed9-41b3-69b2-800d-7247b892b80f\n",
      "    æ¶ˆæ¯æ•°é‡: 12\n",
      "    æœ€åä¸€æ¡æ¶ˆæ¯: While the search results don't explicitly confirm LangGraph's use in *emotional*...\n",
      "    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: ()\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "è¯·è¾“å…¥æ‚¨æƒ³å›æº¯åˆ°çš„å†å²ç‚¹åºå· (ä¾‹å¦‚: 0, 1, 2...)ï¼Œè¾“å…¥ 'n' ç»§ç»­å½“å‰å¯¹è¯ï¼Œæˆ–è¾“å…¥ 'q' é€€å‡º:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‚¨é€‰æ‹©äº†å›æº¯åˆ°å†å²ç‚¹ [1]ã€‚\n",
      "\n",
      "--- ä»æ£€æŸ¥ç‚¹ 1f060ed8-9ba6-600e-8000-faeea06c7fb8 æ¢å¤å¯¹è¯ ---\n",
      "\n",
      "å½“å‰å¯¹è¯å†…å®¹ (æ¢å¤å):\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I'm Bob. What is LangGraph?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ä»è¯¥å†å²ç‚¹å¼€å§‹ï¼Œè¯·è¾“å…¥æ‚¨çš„æ–°é—®é¢˜ (è¾“å…¥ 'q' é€€å‡º):  ä½ è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "ä½ è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æ˜¯çš„ï¼Œä½ çš„åå­—æ˜¯é²å‹ƒã€‚æœ—æ ¼æ‹‰å¤«æ˜¯ä»€ä¹ˆï¼Ÿ\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ä»è¯¥å†å²ç‚¹å¼€å§‹ï¼Œè¯·è¾“å…¥æ‚¨çš„æ–°é—®é¢˜ (è¾“å…¥ 'q' é€€å‡º):  æˆ‘ä»¬ä¹‹å‰çš„å¯¹è¯æœ‰å“ªäº›å†…å®¹ï¼Ÿ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "æˆ‘ä»¬ä¹‹å‰çš„å¯¹è¯æœ‰å“ªäº›å†…å®¹ï¼Ÿ\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "æˆ‘æ²¡æœ‰è®°ä½ä¹‹å‰çš„å¯¹è¯ã€‚\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ä»è¯¥å†å²ç‚¹å¼€å§‹ï¼Œè¯·è¾“å…¥æ‚¨çš„æ–°é—®é¢˜ (è¾“å…¥ 'q' é€€å‡º):  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç»“æŸå½“å‰åˆ†æ”¯å¯¹è¯ã€‚\n"
     ]
    }
   ],
   "source": [
    "import uuid # ç”¨äºç”Ÿæˆå”¯ä¸€çš„ thread_id\n",
    "\n",
    "def run_conversation_and_show_history(initial_user_input: str, thread_id: str):\n",
    "    \"\"\"\n",
    "    è¿è¡Œä¸€æ®µå¯¹è¯ï¼Œç„¶åæ˜¾ç¤ºå†å²è®°å½•ï¼Œå¹¶å…è®¸ç”¨æˆ·é€‰æ‹©å›æº¯ç‚¹ã€‚\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- å¼€å§‹æ–°å¯¹è¯çº¿ç¨‹: {thread_id} ---\")\n",
    "    current_config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "    # ç¬¬ä¸€æ¬¡äº¤äº’\n",
    "    print(f\"User: {initial_user_input}\")\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": initial_user_input}]},\n",
    "        current_config,\n",
    "        stream_mode=\"values\",\n",
    "    )\n",
    "    for event in events:\n",
    "        if \"messages\" in event and event[\"messages\"]:\n",
    "            event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    # ç¬¬äºŒæ¬¡äº¤äº’\n",
    "    second_input = \"Tell me more about its applications.\"\n",
    "    print(f\"\\nUser: {second_input}\")\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": second_input}]},\n",
    "        current_config,\n",
    "        stream_mode=\"values\",\n",
    "    )\n",
    "    for event in events:\n",
    "        if \"messages\" in event and event[\"messages\"]:\n",
    "            event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    # ç¬¬ä¸‰æ¬¡äº¤äº’\n",
    "    third_input = \"Can it be used for emotional support chatbots?\"\n",
    "    print(f\"\\nUser: {third_input}\")\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": third_input}]},\n",
    "        current_config,\n",
    "        stream_mode=\"values\",\n",
    "    )\n",
    "    for event in events:\n",
    "        if \"messages\" in event and event[\"messages\"]:\n",
    "            event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    print(\"\\n--- å¯¹è¯å†å²è®°å½• ---\")\n",
    "    history_snapshots = []\n",
    "    # get_state_history è¿”å›çš„æ˜¯å€’åºï¼Œæˆ‘ä»¬æŠŠå®ƒæ­£åºå­˜å‚¨æ–¹ä¾¿ç”¨æˆ·é€‰æ‹©\n",
    "    for i, state in enumerate(reversed(list(graph.get_state_history(current_config)))):\n",
    "        history_snapshots.append(state)\n",
    "        # è·å–æœ€åä¸€æ¡æ¶ˆæ¯çš„å†…å®¹ï¼Œå¦‚æœæ¶ˆæ¯åˆ—è¡¨ä¸ºç©ºåˆ™æ˜¾ç¤ºæç¤º\n",
    "        last_message_content = \"No messages at this state\"\n",
    "        if state.values and \"messages\" in state.values and state.values[\"messages\"]:\n",
    "            last_message_content = state.values[\"messages\"][-1].content\n",
    "        \n",
    "        print(f\"[{i}] Checkpoint ID: {state.config['configurable']['checkpoint_id']}\")\n",
    "        print(f\"    æ¶ˆæ¯æ•°é‡: {len(state.values.get('messages', []))}\")\n",
    "        print(f\"    æœ€åä¸€æ¡æ¶ˆæ¯: {last_message_content[:80]}...\") # åªæ˜¾ç¤ºå‰80ä¸ªå­—ç¬¦\n",
    "        print(f\"    ä¸‹ä¸€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹: {state.next}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(\"\\nè¯·è¾“å…¥æ‚¨æƒ³å›æº¯åˆ°çš„å†å²ç‚¹åºå· (ä¾‹å¦‚: 0, 1, 2...)ï¼Œè¾“å…¥ 'n' ç»§ç»­å½“å‰å¯¹è¯ï¼Œæˆ–è¾“å…¥ 'q' é€€å‡º: \").strip()\n",
    "            if choice.lower() == 'q':\n",
    "                print(\"é€€å‡ºæ—¶é—´æ—…è¡Œæ¨¡å¼ã€‚\")\n",
    "                return\n",
    "            elif choice.lower() == 'n':\n",
    "                print(\"ç»§ç»­å½“å‰å¯¹è¯ã€‚\")\n",
    "                selected_snapshot = None # è¡¨ç¤ºä¸å›æº¯ï¼Œç»§ç»­å½“å‰çŠ¶æ€\n",
    "                break\n",
    "            \n",
    "            selected_index = int(choice)\n",
    "            if 0 <= selected_index < len(history_snapshots):\n",
    "                selected_snapshot = history_snapshots[selected_index]\n",
    "                print(f\"æ‚¨é€‰æ‹©äº†å›æº¯åˆ°å†å²ç‚¹ [{selected_index}]ã€‚\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"æ— æ•ˆçš„åºå·ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚\")\n",
    "        except ValueError:\n",
    "            print(\"è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥æ•°å­—æˆ– 'n'/'q'ã€‚\")\n",
    "\n",
    "    if selected_snapshot:\n",
    "        # ä½¿ç”¨é€‰å®šçš„å†å²æ£€æŸ¥ç‚¹çš„ config æ¥æ¢å¤å¯¹è¯\n",
    "        print(f\"\\n--- ä»æ£€æŸ¥ç‚¹ {selected_snapshot.config['configurable']['checkpoint_id']} æ¢å¤å¯¹è¯ ---\")\n",
    "        \n",
    "        # æ‰“å°æ¢å¤åçš„å½“å‰å¯¹è¯å†…å®¹\n",
    "        print(\"\\nå½“å‰å¯¹è¯å†…å®¹ (æ¢å¤å):\")\n",
    "        if selected_snapshot.values and \"messages\" in selected_snapshot.values:\n",
    "            for msg in selected_snapshot.values[\"messages\"]:\n",
    "                msg.pretty_print()\n",
    "        else:\n",
    "            print(\"æ— å†å²æ¶ˆæ¯å¯æ˜¾ç¤ºã€‚\")\n",
    "        \n",
    "        # å‡†å¤‡ä¸€ä¸ªæ–°çš„è¾“å…¥ï¼Œä»è¿™ä¸ªå†å²ç‚¹å¼€å§‹æ–°çš„åˆ†æ”¯\n",
    "        while True:\n",
    "            new_user_input = input(\"\\nä»è¯¥å†å²ç‚¹å¼€å§‹ï¼Œè¯·è¾“å…¥æ‚¨çš„æ–°é—®é¢˜ (è¾“å…¥ 'q' é€€å‡º): \").strip()\n",
    "            if new_user_input.lower() == 'q':\n",
    "                print(\"ç»“æŸå½“å‰åˆ†æ”¯å¯¹è¯ã€‚\")\n",
    "                break\n",
    "            \n",
    "            # ä½¿ç”¨é€‰å®šçš„ snapshot çš„ config æ¥ stream æ–°çš„è¾“å…¥\n",
    "            new_events = graph.stream(\n",
    "                {\"messages\": [{\"role\": \"user\", \"content\": new_user_input}]},\n",
    "                selected_snapshot.config, # ä½¿ç”¨å†å²æ£€æŸ¥ç‚¹çš„ config\n",
    "                stream_mode=\"values\",\n",
    "            )\n",
    "            for event in new_events:\n",
    "                if \"messages\" in event and event[\"messages\"]:\n",
    "                    event[\"messages\"][-1].pretty_print()\n",
    "    else:\n",
    "        # å¦‚æœç”¨æˆ·é€‰æ‹©ä¸å›æº¯ï¼Œåˆ™ç»§ç»­å½“å‰å¯¹è¯\n",
    "        print(\"\\n--- ç»§ç»­å½“å‰å¯¹è¯ ---\")\n",
    "        while True:\n",
    "            new_user_input = input(\"\\nè¯·è¾“å…¥æ‚¨çš„æ–°é—®é¢˜ (è¾“å…¥ 'q' é€€å‡º): \").strip()\n",
    "            if new_user_input.lower() == 'q':\n",
    "                print(\"ç»“æŸå¯¹è¯ã€‚\")\n",
    "                break\n",
    "            \n",
    "            new_events = graph.stream(\n",
    "                {\"messages\": [{\"role\": \"user\", \"content\": new_user_input}]},\n",
    "                current_config, # ä½¿ç”¨å½“å‰å¯¹è¯çš„ config\n",
    "                stream_mode=\"values\",\n",
    "            )\n",
    "            for event in new_events:\n",
    "                if \"messages\" in event and event[\"messages\"]:\n",
    "                    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# è¿è¡Œç¤ºä¾‹\n",
    "# ä½¿ç”¨ä¸€ä¸ªæ–°çš„çº¿ç¨‹IDæ¥é¿å…ä¸ä¹‹å‰æ•™ç¨‹çš„thread_idå†²çª\n",
    "new_thread_id = str(uuid.uuid4())\n",
    "run_conversation_and_show_history(\"Hi, I'm Bob. What is LangGraph?\", new_thread_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957dafa4-3fc3-4cf9-8f64-f3b73d38b5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9785a06-4eed-4360-b7bd-d6784f8cfbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97295f1-6c7c-496c-b99d-1d128ed887e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44f54c8-04b5-4026-8669-e6cd9ea3cfad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263dc64d-015d-4281-96ed-4418ca3c18ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1bd4b-11fe-41a1-a202-509c5ff82050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c698225-3582-4b95-878c-006959a3deb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3392658-7308-497b-bbab-148ef959695d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb3c501-4e30-4806-9032-d7fd12297ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f9b5e-8266-4f98-803d-3f7a84c2af33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d8469-9dc1-445e-b52e-53646cbdea4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d059d6-a996-49fe-9854-7c6a66764ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67035c7-757b-4945-8226-1b0d81abbf1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c95d9-03b9-441b-b85c-85e786ac8ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adce8e6-1395-4f21-af47-7c67ac2a4d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196de161-bf8c-4651-a4a6-e565fd3be287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf2958-f7a4-41ed-9295-7c3b398bd986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb9aff-81bb-4b70-9476-1ae6ae2106d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc39be-7242-478a-a433-3dde3a53b4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e0fcb-7410-420a-8efe-8d97dab69916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1427e4-3236-4aba-add8-b30241f5eb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba34ae-5d70-4ff2-8e9c-4667d9373066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81013bb-08f1-4172-a12f-3e0fabcf1bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238836ba-c49a-4faf-94b7-097df86e11e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5c044-de15-4aa6-9366-ff79b6da656f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e1a64-56f3-4f43-a1db-2490781a35dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857cc8ea-6c5d-47d0-9b84-4ed1ffedb6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
