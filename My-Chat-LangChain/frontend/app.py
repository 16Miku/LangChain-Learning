# frontend/app.py

import streamlit as st
import requests
import json
import os

# --- 1. API é…ç½® (ä¿æŒä¸å˜) ---
BACKEND_URL_ENDPOINT = "http://127.0.0.1:8000/chat_url"
BACKEND_FILE_ENDPOINT = "http://127.0.0.1:8000/chat_file"

# --- 2. é¡µé¢é…ç½® & æ ·å¼åŠ è½½ (ä¿æŒä¸å˜) ---
st.set_page_config(
    page_title="Chat LangChain | Enterprise Edition",
    page_icon="ğŸ”—",
    layout="wide",
    initial_sidebar_state="expanded"
)
def load_css(file_path):
    with open(file_path) as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
load_css("style.css")

# --- 3. API è°ƒç”¨å‡½æ•° (ä¿æŒä¸å˜) ---
def get_backend_response_from_url(url: str, query: str, chat_history: list):
    # ... (å‡½æ•°å†…å®¹ä¸å˜)
    try:
        payload = {"url": url, "query": query, "chat_history": chat_history}
        proxies = {"http": None, "https": None}
        response = requests.post(BACKEND_URL_ENDPOINT, json=payload, timeout=180, proxies=proxies)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        return {"answer": f"è¯·æ±‚åç«¯æœåŠ¡æ—¶å‡ºé”™ (URL): {e}", "source_documents": []}

def get_backend_response_from_file(query: str, chat_history: list, uploaded_file):
    # ... (å‡½æ•°å†…å®¹ä¸å˜)
    try:
        files = {'file': (uploaded_file.name, uploaded_file.getvalue(), uploaded_file.type)}
        data = {'query': query, 'chat_history_str': json.dumps(chat_history)}
        proxies = {"http": None, "https": None}
        response = requests.post(BACKEND_FILE_ENDPOINT, files=files, data=data, timeout=300, proxies=proxies)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        return {"answer": f"è¯·æ±‚åç«¯æœåŠ¡æ—¶å‡ºé”™ (File): {e}", "source_documents": []}

# --- 4. ä¾§è¾¹æ å†…å®¹ (ä¿æŒä¸å˜) ---
with st.sidebar:
    # ... (å†…å®¹ä¸å˜)
    st.markdown("## ğŸ”— Chat LangChain v4.0", unsafe_allow_html=True)
    st.markdown("---")
    st.markdown("**v4.0 æ–°å¢åŠŸèƒ½:**\n- **æ–‡æ¡£çŸ¥è¯†åº“:** æ–°å¢äº†é€šè¿‡ä¸Šä¼  PDF æ–‡ä»¶è¿›è¡Œé—®ç­”çš„åŠŸèƒ½ã€‚\n\n**å·¥ä½œæ¨¡å¼:**\n1.  **ç½‘é¡µçŸ¥è¯†åº“:** åœ¨ Tab ä¸­è¾“å…¥ URL è¿›è¡Œåœ¨çº¿å†…å®¹é—®ç­”ã€‚\n2.  **æ–‡æ¡£çŸ¥è¯†åº“:** åœ¨ Tab ä¸­ä¸Šä¼  PDF æ–‡ä»¶è¿›è¡Œæœ¬åœ°æ–‡æ¡£é—®ç­”ã€‚\n")
    st.markdown("---")
    st.markdown("**æ ¸å¿ƒæŠ€æœ¯:**\n- å‰ç«¯: Streamlit\n- åç«¯: FastAPI\n- RAG: LangChain, ChromaDB, SentenceTransformers, Flashrank\n")

# --- 5. ä¸»å†…å®¹åŒºåŸŸ ---
st.title("My Chat LangChain ğŸ¤– (Enterprise Edition)")

tab_url, tab_file = st.tabs(["ğŸ”— ç½‘é¡µçŸ¥è¯†åº“", "ğŸ“„ æ–‡æ¡£çŸ¥è¯†åº“"])

# --- Tab 1: ç½‘é¡µçŸ¥è¯†åº“ (é€»è¾‘å¾®è°ƒ) ---
with tab_url:
    st.header("ä¸åœ¨çº¿ç½‘é¡µå†…å®¹å¯¹è¯")

    if "url_messages" not in st.session_state:
        st.session_state.url_messages = []
    if "current_url" not in st.session_state:
        st.session_state.current_url = "https://python.langchain.com/docs/modules/agents/"

    col1, col2 = st.columns([3, 1])
    with col1:
        new_url = st.text_input("çŸ¥è¯†åº“ URL:", st.session_state.current_url, key="url_input")
    with col2:
        st.selectbox("æ¨¡å‹:", ["Gemini 2.5 Flash (Backend)"], disabled=True, key="url_model_select")

    if st.session_state.current_url != new_url:
        st.session_state.current_url = new_url
        st.session_state.url_messages = []
        st.info(f"ç½‘é¡µçŸ¥è¯†åº“å·²åˆ‡æ¢åˆ°: {new_url}ã€‚")
        st.rerun()

    # æ¸²æŸ“å†å²æ¶ˆæ¯ (é€»è¾‘ä¸å˜)
    for message in st.session_state.url_messages:
        # ... (æ¸²æŸ“é€»è¾‘ä¸å˜)
        avatar = "ğŸ§‘â€ğŸ’»" if message["role"] == "user" else "ğŸ¤–"
        with st.chat_message(message["role"], avatar=avatar):
            st.markdown(message["content"])
            if message["role"] == "assistant" and "sources" in message and message["sources"]:
                with st.expander("ğŸ“– æŸ¥çœ‹ç­”æ¡ˆæ¥æº"):
                    for i, source in enumerate(message["sources"]):
                        source_url = source.get("metadata", {}).get("source", "æœªçŸ¥æ¥æº")
                        st.markdown(f"**æ¥æº {i+1}:** [{source_url}]({source_url})")
                        st.markdown(f"> {source['page_content']}")
                        if i < len(message["sources"]) - 1: st.markdown("---")

    # --- æ ¸å¿ƒä¿®æ”¹ï¼šå°†è¾“å…¥æ¡†ç§»åˆ° Tab é€»è¾‘çš„æœ«å°¾ ---
    if prompt := st.chat_input("å°±å½“å‰ç½‘é¡µæé—®..."):
        st.session_state.url_messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
            st.markdown(prompt)
        
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            with st.spinner("æ­£åœ¨åŸºäºç½‘é¡µå†…å®¹æ€è€ƒ..."):
                response_data = get_backend_response_from_url(
                    url=st.session_state.current_url,
                    query=prompt,
                    chat_history=st.session_state.url_messages[:-1]
                )
                answer = response_data.get("answer", "æŠ±æ­‰ï¼Œå‡ºé”™äº†ã€‚")
                sources = response_data.get("source_documents", [])
                st.markdown(answer)
                if sources:
                    with st.expander("ğŸ“– æŸ¥çœ‹ç­”æ¡ˆæ¥æº"):
                        for i, source in enumerate(sources):
                            source_url = source.get("metadata", {}).get("source", "æœªçŸ¥æ¥æº")
                            st.markdown(f"**æ¥æº {i+1}:** [{source_url}]({source_url})")
                            st.markdown(f"> {source['page_content']}")
                            if i < len(sources) - 1: st.markdown("---")
                
                st.session_state.url_messages.append({"role": "assistant", "content": answer, "sources": sources})
                # æ·»åŠ  rerun ç¡®ä¿æ¥æºå±•å¼€å™¨çŠ¶æ€æ­£ç¡®æ›´æ–°
                st.rerun()

# --- Tab 2: æ–‡æ¡£çŸ¥è¯†åº“ (æ ¸å¿ƒé‡æ„) ---
with tab_file:
    st.header("ä¸æ‚¨ä¸Šä¼ çš„ PDF æ–‡æ¡£å¯¹è¯")

    if "file_messages" not in st.session_state:
        st.session_state.file_messages = []
    if "current_file_id" not in st.session_state:
        st.session_state.current_file_id = None

    uploaded_file = st.file_uploader(
        "è¯·åœ¨æ­¤å¤„ä¸Šä¼ æ‚¨çš„ PDF æ–‡ä»¶", 
        type=['pdf'],
        help="ä¸Šä¼ åï¼Œæ‚¨å¯ä»¥å°±è¯¥æ–‡æ¡£çš„å†…å®¹è¿›è¡Œæé—®ã€‚"
    )

    # --- æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨ uploaded_file.file_id æ›¿æ¢ .id ---
    if uploaded_file and (st.session_state.current_file_id != uploaded_file.file_id):
        st.session_state.current_file_id = uploaded_file.file_id
        st.session_state.file_messages = []
        st.info(f"æ–‡æ¡£çŸ¥è¯†åº“å·²åˆ‡æ¢åˆ°: {uploaded_file.name}ã€‚")

    # æ¸²æŸ“å†å²æ¶ˆæ¯ (é€»è¾‘ä¸å˜)
    for message in st.session_state.file_messages:
        # ... (æ¸²æŸ“é€»è¾‘ä¸å˜)
        avatar = "ğŸ§‘â€ğŸ’»" if message["role"] == "user" else "ğŸ¤–"
        with st.chat_message(message["role"], avatar=avatar):
            st.markdown(message["content"])
            if message["role"] == "assistant" and "sources" in message and message["sources"]:
                with st.expander("ğŸ“– æŸ¥çœ‹ç­”æ¡ˆæ¥æº"):
                    for i, source in enumerate(message["sources"]):
                        page_num = source.get("metadata", {}).get("page", -1)
                        st.markdown(f"**æ¥æº {i+1}:** ç¬¬ {page_num + 1} é¡µ")
                        st.markdown(f"> {source['page_content']}")
                        if i < len(message["sources"]) - 1: st.markdown("---")

    # --- æ ¸å¿ƒä¿®æ”¹ï¼šå°†è¾“å…¥æ¡†ç§»åˆ° Tab é€»è¾‘çš„æœ«å°¾ï¼Œå¹¶ç”¨ disabled å‚æ•°æ§åˆ¶ ---
    # å¦‚æœæ²¡æœ‰ä¸Šä¼ æ–‡ä»¶ï¼Œè¾“å…¥æ¡†ä¼šæ˜¾ç¤ºä½†ä¸å¯ç”¨
    if prompt := st.chat_input(
        f"å°± {uploaded_file.name} æé—®..." if uploaded_file else "è¯·å…ˆä¸Šä¼ ä¸€ä¸ª PDF æ–‡ä»¶", 
        disabled=not uploaded_file
    ):
        st.session_state.file_messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
            st.markdown(prompt)

        with st.chat_message("assistant", avatar="ğŸ¤–"):
            with st.spinner("æ­£åœ¨åŸºäºæ–‡æ¡£å†…å®¹æ€è€ƒ..."):
                response_data = get_backend_response_from_file(
                    query=prompt,
                    chat_history=st.session_state.file_messages[:-1],
                    uploaded_file=uploaded_file
                )
                answer = response_data.get("answer", "æŠ±æ­‰ï¼Œå‡ºé”™äº†ã€‚")
                sources = response_data.get("source_documents", [])
                st.markdown(answer)
                if sources:
                    with st.expander("ğŸ“– æŸ¥çœ‹ç­”æ¡ˆæ¥æº"):
                        for i, source in enumerate(sources):
                            page_num = source.get("metadata", {}).get("page", -1)
                            st.markdown(f"**æ¥æº {i+1}:** ç¬¬ {page_num + 1} é¡µ")
                            st.markdown(f"> {source['page_content']}")
                            if i < len(sources) - 1: st.markdown("---")
                
                st.session_state.file_messages.append({"role": "assistant", "content": answer, "sources": sources})
                # æ·»åŠ  rerun ç¡®ä¿æ¥æºå±•å¼€å™¨çŠ¶æ€æ­£ç¡®æ›´æ–°
                st.rerun()