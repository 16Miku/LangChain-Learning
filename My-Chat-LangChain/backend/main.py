from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
import numpy as np
import os
import json
import tempfile
import hashlib

from langchain_qa_backend import (
    create_vector_store_from_url,
    create_vector_store_from_file,
    load_vector_store, 
    get_retrieval_chain, 
    get_persist_directory_for_url,
    get_persist_directory_for_file
)
from langchain_core.messages import HumanMessage, AIMessage

# Import new agent service
from agent_service import chat_with_agent

app = FastAPI(
    title="Enterprise RAG & Agent Backend API",
    description="An API for the RAG and Agent application powered by LangChain and Google Gemini.",
    version="5.0.0",
)

rag_chain_cache = {}

# --- Data Models ---

class ChatHistoryItem(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    url: str
    query: str
    chat_history: List[ChatHistoryItem]

class SourceDocument(BaseModel):
    page_content: str = Field(..., description="Source document content snippet")
    metadata: Dict[str, Any] = Field({}, description="Source document metadata")

class ChatResponse(BaseModel):
    answer: str = Field(..., description="Answer generated by the system")
    source_documents: List[SourceDocument] = Field([], description="Source documents used for RAG")

class AgentChatRequest(BaseModel):
    message: str
    thread_id: str = "default_thread"
    api_keys: Optional[Dict[str, str]] = None

class AgentChatResponse(BaseModel):
    response: str

# --- Helper Functions ---
def clean_metadata(metadata: dict) -> dict:
    cleaned = {}
    for key, value in metadata.items():
        if isinstance(value, np.float32):
            cleaned[key] = float(value)
        elif isinstance(value, dict):
            cleaned[key] = clean_metadata(value)
        else:
            cleaned[key] = value
    return cleaned

# --- API Endpoints ---

@app.get("/", tags=["Health Check"])
def read_root():
    return {"status": "ok", "message": "Welcome to the RAG & Agent Backend API v5.0!"}

# --- Agent Chat Endpoint ---
@app.post("/chat_agent", response_model=AgentChatResponse, tags=["Agent Chat"])
async def chat_agent_endpoint(request: AgentChatRequest):
    """
    Endpoint for chatting with the autonomous agent.
    """
    try:
        response_content = await chat_with_agent(
            message=request.message, 
            thread_id=request.thread_id,
            api_keys=request.api_keys
        )
        return AgentChatResponse(response=response_content)
    except Exception as e:
        print(f"Error in Agent Chat: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# --- Existing RAG Endpoints (Kept for backward compatibility or direct RAG usage) ---

@app.post("/chat_url", response_model=ChatResponse, tags=["RAG Chat"])
async def chat_url_endpoint(request: ChatRequest):
    url = request.url
    query = request.query
    
    if url in rag_chain_cache:
        retrieval_chain = rag_chain_cache[url]
    else:
        persist_directory = get_persist_directory_for_url(url)
        if os.path.exists(persist_directory):
            vector_store = load_vector_store(persist_directory)
        else:
            vector_store = await create_vector_store_from_url(url, persist_directory)
        
        if not vector_store:
            raise HTTPException(status_code=500, detail="Failed to process URL.")
        
        base_retriever = vector_store.as_retriever(search_kwargs={"k": 20})
        retrieval_chain = get_retrieval_chain(base_retriever)
        if not retrieval_chain:
            raise HTTPException(status_code=500, detail="Failed to create RAG chain.")
        rag_chain_cache[url] = retrieval_chain

    return await invoke_rag_chain(retrieval_chain, query, request.chat_history)

@app.post("/chat_file", response_model=ChatResponse, tags=["RAG Chat"])
async def chat_file_endpoint(
    query: str = Form(...),
    chat_history_str: str = Form("[]"),
    file: UploadFile = File(...)
):
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_filepath = os.path.join(temp_dir, file.filename)
        file_content = await file.read()
        with open(temp_filepath, "wb") as f:
            f.write(file_content)
        
        persist_directory = get_persist_directory_for_file(file.filename, file_content)
        
        if persist_directory in rag_chain_cache:
            retrieval_chain = rag_chain_cache[persist_directory]
        else:
            if os.path.exists(persist_directory):
                vector_store = load_vector_store(persist_directory)
            else:
                vector_store = await create_vector_store_from_file(temp_filepath, persist_directory)

            if not vector_store:
                raise HTTPException(status_code=500, detail="Failed to process File.")
            
            base_retriever = vector_store.as_retriever(search_kwargs={"k": 20})
            retrieval_chain = get_retrieval_chain(base_retriever)
            if not retrieval_chain:
                raise HTTPException(status_code=500, detail="Failed to create RAG chain.")
            rag_chain_cache[persist_directory] = retrieval_chain

    chat_history = json.loads(chat_history_str)
    return await invoke_rag_chain(retrieval_chain, query, chat_history)

async def invoke_rag_chain(chain, query: str, history: List[Any]):
    formatted_chat_history = []
    for item in history:
        if isinstance(item, dict):
            role = item.get("role")
            content = item.get("content")
        else:
            role = item.role
            content = item.content

        if role == "user":
            formatted_chat_history.append(HumanMessage(content=content))
        elif role == "assistant":
            formatted_chat_history.append(AIMessage(content=content))
    
    try:
        response = chain.invoke({
            "input": query,
            "chat_history": formatted_chat_history
        })
        
        source_documents = response.get("context", [])
        formatted_sources = [
            SourceDocument(page_content=doc.page_content, metadata=clean_metadata(doc.metadata))
            for doc in source_documents
        ]
        return ChatResponse(answer=response["answer"], source_documents=formatted_sources)
    except Exception as e:
        print(f"Error invoking RAG chain: {e}")
