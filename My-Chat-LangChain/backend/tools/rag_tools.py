import os
import asyncio
from langchain_core.tools import tool
from langchain_qa_backend import (
    create_vector_store_from_url,
    load_vector_store,
    get_retrieval_chain,
    get_persist_directory_for_url
)
from langchain_core.messages import HumanMessage, AIMessage
from typing import List, Dict, Any
import numpy as np

# RAG Chain Cache (Shared with main app if needed, or separate)
# Note: Ideally this should be a shared cache, but for tool simplicity we might maintain a local one 
# or import the one from main if structure allows. For now, let's keep a local cache for the tool.
tool_rag_chain_cache = {}

def clean_metadata(metadata: dict) -> dict:
    """Recursively convert numpy types to python types for JSON serialization"""
    cleaned = {}
    for key, value in metadata.items():
        if isinstance(value, np.float32):
            cleaned[key] = float(value)
        elif isinstance(value, dict):
            cleaned[key] = clean_metadata(value)
        else:
            cleaned[key] = value
    return cleaned

@tool
async def ingest_knowledge(url: str):
    """
    å°†æŒ‡å®šçš„ç½‘é¡µURLå†…å®¹æ‘„å–å¹¶å¤„ç†ä¸ºçŸ¥è¯†åº“ã€‚
    å½“ç”¨æˆ·è¦æ±‚å­¦ä¹ æŸä¸ªæ–°ç½‘é¡µæˆ–åŸºäºæŸä¸ªç½‘é¡µè¿›è¡Œé—®ç­”æ—¶ï¼Œé¦–å…ˆè°ƒç”¨æ­¤å·¥å…·ã€‚
    """
    print(f"\nğŸ“š [Knowledge] æ­£åœ¨æ‘„å–çŸ¥è¯†åº“: {url} ...")
    
    # Check if chain already exists in cache
    if url in tool_rag_chain_cache:
        print(f"  -> çŸ¥è¯†åº“å·²åœ¨ç¼“å­˜ä¸­: {url}")
        return f"çŸ¥è¯†åº“å·²å‡†å¤‡å°±ç»ª (Cached): {url}"

    # Check persistence
    persist_directory = get_persist_directory_for_url(url)
    if os.path.exists(persist_directory):
        print(f"  -> ä»ç£ç›˜åŠ è½½çŸ¥è¯†åº“: {persist_directory}")
        vector_store = load_vector_store(persist_directory)
    else:
        print(f"  -> åˆ›å»ºæ–°çŸ¥è¯†åº“: {url}")
        vector_store = await create_vector_store_from_url(url, persist_directory)
    
    if not vector_store:
        return f"âŒ é”™è¯¯: æ— æ³•å¤„ç† URL {url}"

    # Create Chain
    base_retriever = vector_store.as_retriever(search_kwargs={"k": 20})
    retrieval_chain = get_retrieval_chain(base_retriever)
    
    if not retrieval_chain:
        return f"âŒ é”™è¯¯: æ— æ³•ä¸º {url} åˆ›å»º RAG é“¾"
        
    tool_rag_chain_cache[url] = retrieval_chain
    print(f"âœ… [Knowledge] çŸ¥è¯†åº“æ‘„å–å®Œæˆ: {url}")
    return f"æˆåŠŸå­¦ä¹ äº†ç½‘é¡µå†…å®¹: {url}"

@tool
async def query_knowledge(query: str, url: str):
    """
    åŸºäºå·²æ‘„å–çš„ç½‘é¡µçŸ¥è¯†åº“å›ç­”é—®é¢˜ã€‚
    å¿…é¡»å…ˆè°ƒç”¨ `ingest_knowledge` ç¡®ä¿è¯¥ URL å·²è¢«å¤„ç†ã€‚
    """
    print(f"\nğŸ¤” [RAG] æ­£åœ¨æŸ¥è¯¢çŸ¥è¯†åº“ ({url}): {query} ...")
    
    if url not in tool_rag_chain_cache:
        # Try to auto-ingest if not found (optional, but robust)
        print(f"  -> è­¦å‘Š: URL {url} æœªåœ¨ç¼“å­˜ä¸­ï¼Œå°è¯•è‡ªåŠ¨æ‘„å–...")
        await ingest_knowledge(url)
        if url not in tool_rag_chain_cache:
            return f"âŒ é”™è¯¯: çŸ¥è¯†åº“æœªæ‰¾åˆ°ä¸”æ— æ³•è‡ªåŠ¨åŠ è½½: {url}"

    chain = tool_rag_chain_cache[url]
    
    try:
        # Minimal history for single-turn tool usage, or pass full history if available in context
        response = await chain.ainvoke({
            "input": query,
            "chat_history": [] # Tool call usually handles single specific query
        })
        
        answer = response["answer"]
        source_documents = response.get("context", [])
        
        # Format sources for the Agent
        sources_text = ""
        for i, doc in enumerate(source_documents[:3]): # Limit to top 3 sources
            cleaned_meta = clean_metadata(doc.metadata)
            source_url = cleaned_meta.get("source", "Unknown")
            sources_text += f"\n- Source {i+1} ({source_url}): {doc.page_content[:100]}..."

        final_output = f"{answer}\n\nå‚è€ƒæ¥æº:{sources_text}"
        print(f"âœ… [RAG] æŸ¥è¯¢å®Œæˆã€‚")
        return final_output

    except Exception as e:
        print(f"âŒ [RAG] æŸ¥è¯¢å‡ºé”™: {e}")
        return f"æŸ¥è¯¢çŸ¥è¯†åº“æ—¶å‘ç”Ÿé”™è¯¯: {e}"
