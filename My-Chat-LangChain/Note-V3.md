


# æ ¹æ®å½“å‰é¡¹ç›®æœ€ç»ˆä»£ç å’Œé¡¹ç›®ç¬¬äºŒç‰ˆä»¥åçš„æ‰€æœ‰å¼€å‘è®°å½•ï¼Œæå°½è¯¦ç»†å…¨é¢å…·ä½“åœ°ç¼–å†™My-Chat-LangChainè¯´æ˜ä¹¦ v3.0ã€‚è¦æ±‚è¯¦ç»†è®°å½•å’Œæ€»ç»“å¼€å‘è¿‡ç¨‹ï¼Œè¯´æ˜æœ¬é˜¶æ®µé‡åˆ°çš„å›°éš¾ä»¥åŠè§£å†³æ–¹æ¡ˆã€‚è¯¥è¯´æ˜ä¹¦è¦å…·å¤‡èƒ½å¤Ÿå‚è€ƒå…¶è¿›è¡Œå¤ç°çš„æ°´å¹³ã€‚






# **My-Chat-LangChain åº”ç”¨è¯´æ˜ä¹¦ v3.0 (é«˜çº§ RAG ç‰ˆ)**

---

#### **1. åº”ç”¨æ¦‚è¿°**

My-Chat-LangChain v3.0 æ˜¯ä¸€ä¸ªå®ç°äº†é«˜çº§ RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) æŠ€æœ¯çš„ä¼ä¸šçº§é—®ç­”åº”ç”¨ã€‚åœ¨ v2.0 åšå®çš„å‰åç«¯åˆ†ç¦»æ¶æ„åŸºç¡€ä¸Šï¼Œv3.0 èšç„¦äº**ä»æ ¹æœ¬ä¸Šæå‡é—®ç­”è´¨é‡ä¸ç³»ç»Ÿå¥å£®æ€§**ï¼Œå¼•å…¥äº†åŒ…æ‹¬**ç­”æ¡ˆæº¯æºã€å†…å®¹æ¸…æ´—ã€é«˜çº§é‡æ’ (Re-ranking) å’ŒæŒä¹…åŒ–çŸ¥è¯†åº“**åœ¨å†…çš„å¤šé¡¹å…³é”®æŠ€æœ¯ã€‚

æœ¬åº”ç”¨ç°åœ¨ä¸ä»…èƒ½å¤ŸåŸºäºç”¨æˆ·æŒ‡å®šçš„ä»»æ„ç½‘é¡µ URL æ„å»ºçŸ¥è¯†åº“ï¼Œæ›´èƒ½ç¡®ä¿ä»è¿™ä¸ªçŸ¥è¯†åº“ä¸­æ£€ç´¢åˆ°çš„ä¿¡æ¯æ˜¯**ç²¾å‡†çš„**ã€ç”Ÿæˆçš„ç­”æ¡ˆæ˜¯**å¯ä¿¡çš„**ã€çŸ¥è¯†åº“çš„åŠ è½½æ˜¯**é«˜æ•ˆçš„**ã€‚å®ƒä»£è¡¨äº†ä¸€ä¸ªä»â€œèƒ½ç”¨â€åˆ°â€œå¥½ç”¨â€å†åˆ°â€œå¯é â€çš„å·¨å¤§é£è·ƒã€‚

**v3.0 æ ¸å¿ƒå‡çº§ï¼š**
*   **ç­”æ¡ˆæº¯æº (Citations):** AI çš„æ¯ä¸€ä¸ªå›ç­”éƒ½ä¼šé™„å¸¦å…¶æ‰€ä¾æ®çš„åŸæ–‡ç‰‡æ®µå’Œæ¥æºé“¾æ¥ï¼Œå®ç°äº†å®Œå…¨çš„é€æ˜ä¸å¯éªŒè¯æ€§ã€‚
*   **å†…å®¹æ¸…æ´— (Data Cleaning):** åœ¨æ•°æ®å¤„ç†ç®¡é“ä¸­åŠ å…¥äº† HTML æ¸…æ´—å±‚ï¼Œç¡®ä¿é€å…¥æ¨¡å‹çš„ä¸Šä¸‹æ–‡æ˜¯å¹²å‡€ã€æ— å™ªéŸ³çš„çº¯æ–‡æœ¬ã€‚
*   **é«˜çº§é‡æ’ (Re-ranking):** é›†æˆäº†é«˜æ€§èƒ½çš„**æœ¬åœ°å¼€æºé‡æ’æ¨¡å‹** (`BAAI/bge-reranker-base`)ï¼Œåœ¨ä¼ ç»Ÿçš„å‘é‡æ£€ç´¢ä¹‹åå¢åŠ äº†ä¸€ä¸ªç²¾æ’é˜¶æ®µï¼Œæå¤§åœ°æå‡äº†æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§ä¸æœ€ç»ˆç­”æ¡ˆçš„ç²¾å‡†åº¦ã€‚
*   **æŒä¹…åŒ–ä¸çŠ¶æ€ç®¡ç†:** å®ç°äº†çŸ¥è¯†åº“çš„ç£ç›˜æŒä¹…åŒ–ã€‚å¯¹äºå¤„ç†è¿‡çš„ URLï¼Œåº”ç”¨èƒ½å¤Ÿç§’çº§åŠ è½½ï¼Œæ— éœ€é‡å¤è¿›è¡Œè€—æ—¶çš„æ•°æ®å¤„ç†ï¼Œæ˜¾è‘—æå‡äº†å¸¸ç”¨çŸ¥è¯†åº“çš„å“åº”é€Ÿåº¦ã€‚
*   **èšç„¦å¼åŠ è½½ç­–ç•¥:** ä¼˜åŒ–äº†æ–‡æ¡£åŠ è½½ç­–ç•¥ï¼Œä»â€œå…¨ç«™æŠ“å–â€è½¬å‘æ›´ç²¾å‡†çš„â€œé€’å½’æŠ“å–â€ï¼Œè§£å†³äº†çŸ¥è¯†åº“è¢«æ— å…³å†…å®¹æ±¡æŸ“çš„é—®é¢˜ã€‚

#### **2. å…³é”®ç‰¹æ€§ä¸æ¶æ„ (v3.0)**

**ç³»ç»Ÿæ¶æ„å›¾ (v3.0):**
```
+--------+      +---------------------+      +---------------------------------+
|        |      |  Streamlit Frontend |      |         FastAPI Backend         |
|  User  |----->| (localhost:8501)    |----->|       (localhost:8000)        |
|        |      | - UI & Interaction  |      | - API Endpoint (/chat)          |
+--------+      | - API Call Logic    |      | - In-Memory Cache (RAG Chain)   |
              +---------------------+      | - Persistent KB Loading Logic   |
                                           +----------------+----------------+
                                                            |
                                                            v (LangChain Advanced RAG Pipeline)
+-----------------------------------------------------------+------------------------------------------------------------+
| `langchain_qa_backend.py`                                                                                                |
|                                                                                                                          |
|  [IF KB NOT EXISTS]                                       [IF KB EXISTS]                                                 |
|   1. Focused Load (RecursiveUrlLoader)  ------------>      1. Load from Disk (Chroma(persist_directory))                 |
|   2. Clean HTML (BeautifulSoupTransformer)                                                                               |
|   3. Split Text (RecursiveCharacterTextSplitter)                                                                         |
|   4. Embed Locally (HuggingFaceEmbeddings)                                                                               |
|   5. Create & Persist (Chroma.from_documents) -----------> [./chroma_db_{url_hash}] (Persistent Vector Store)              |
|                                                                                                                          |
|                                                            +-----------------------------------------------------------+ |
|                                                            |                                                           | |
|                                                            v (RAG Chain Construction)                                  | |
|  Base Retriever (Recall k=100) -> Compression Retriever -> Reranker (FlashrankRerank, top_n=10) -> LLM (Gemini) -> Answer + Sources |
|                                                                                                                          |
+--------------------------------------------------------------------------------------------------------------------------+

```

#### **3. æŠ€æœ¯æ ˆ (æ–°å¢ä¸å˜æ›´)**

*   **AI / æ ¸å¿ƒé€»è¾‘:**
    *   **é‡æ’æ¨¡å‹ (Re-ranker):** FlashRank (`BAAI/bge-reranker-base`, æœ¬åœ°è¿è¡Œ)
    *   **HTML æ¸…æ´—:** BeautifulSoup4
*   **å¼€å‘å·¥å…·:**
    *   **å“ˆå¸Œåº“:** hashlib (ç”¨äºç”ŸæˆæŒä¹…åŒ–ç›®å½•å)

*(å…¶ä»–æŠ€æœ¯æ ˆä¸ v2.0 ä¿æŒä¸€è‡´)*

#### **4. ç¯å¢ƒå‡†å¤‡ä¸å®‰è£…**

ç¯å¢ƒé…ç½®ä¸ v2.0 åŸºæœ¬ä¸€è‡´ï¼Œä½†**åç«¯**éœ€è¦å®‰è£…é¢å¤–çš„åº“ã€‚

**1. åç«¯ç¯å¢ƒ (`backend` ç›®å½•):**

æ‰“å¼€ PowerShellï¼Œå¯¼èˆªåˆ° `backend` ç›®å½•ï¼Œå¹¶æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ç¡®ä¿æ‰€æœ‰ä¾èµ–éƒ½å·²å®‰è£…ï¼š
```powershell
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ (ä¾‹å¦‚ï¼š.\venv\Scripts\Activate.ps1)

# å®‰è£…æ‰€æœ‰å¿…éœ€çš„åº“
pip install fastapi "uvicorn[standard]" langchain langchain-community langchain-core langchain-google-genai langchain-huggingface sentence-transformers langchain-chroma python-dotenv beautifulsoup4 tqdm FlagEmbedding flashrank numpy
```
*(æ³¨æ„ï¼šæˆ‘ä»¬æ–°å¢äº† `FlagEmbedding`, `flashrank`, `numpy`)*

**2. å‰ç«¯ç¯å¢ƒ (`frontend` ç›®å½•):**
å‰ç«¯ç¯å¢ƒæ— éœ€ä»»ä½•å˜æ›´ã€‚

**3. é…ç½®:**
é…ç½® `backend/.env` æ–‡ä»¶ä¸­çš„ `GOOGLE_API_KEY`ï¼Œä¸ v2.0 æ­¥éª¤å®Œå…¨ç›¸åŒã€‚v3.0 æ— éœ€ Cohere API Keyã€‚

#### **5. å¦‚ä½•è¿è¡Œ**

è¿è¡Œæ­¥éª¤ä¸ v2.0 å®Œå…¨ç›¸åŒï¼š
1.  åœ¨ä¸€ä¸ª PowerShell çª—å£ä¸­å¯åŠ¨**åç«¯æœåŠ¡** (`uvicorn main:app --reload`)ã€‚
2.  åœ¨å¦ä¸€ä¸ª PowerShell çª—å£ä¸­å¯åŠ¨**å‰ç«¯åº”ç”¨** (`streamlit run app.py`)ã€‚

#### **6. v2.0 -> v3.0 å‡çº§ä¹‹æ—…ï¼šé—®é¢˜ã€åˆ†æä¸è§£å†³æ–¹æ¡ˆ**

è¿™æ˜¯æœ¬è¯´æ˜ä¹¦çš„æ ¸å¿ƒï¼Œè¯¦ç»†è®°å½•äº†æˆ‘ä»¬åœ¨ç¬¬äºŒé˜¶æ®µå¼€å‘ä¸­é‡åˆ°çš„æŒ‘æˆ˜ä»¥åŠå¦‚ä½•æ”»å…‹å®ƒä»¬ã€‚

##### **æŒ‘æˆ˜ä¸€ï¼šç­”æ¡ˆçš„â€œé»‘ç›’â€é—®é¢˜â€”â€”å®ç°ç­”æ¡ˆæº¯æº**

*   **é—®é¢˜:** v2.0 çš„ AI å›ç­”ç¼ºä¹ä¾æ®ï¼Œç”¨æˆ·æ— æ³•éªŒè¯å…¶å‡†ç¡®æ€§ï¼Œå¯ä¿¡åº¦ä½ã€‚
*   **åˆ†æ:** `create_retrieval_chain` çš„è¿”å›ç»“æœæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­ `answer` é”®æ˜¯æœ€ç»ˆç­”æ¡ˆï¼Œ`context` é”®åŒ…å«äº†æ‰€æœ‰è¢« LLM å‚è€ƒçš„æºæ–‡æ¡£ `Document` å¯¹è±¡ã€‚æˆ‘ä»¬åªéœ€è¦å°† `context` æå–å‡ºæ¥å¹¶ä¼ é€’ç»™å‰ç«¯å³å¯ã€‚
*   **è§£å†³æ–¹æ¡ˆ:**
    1.  **åç«¯ (`main.py`):**
        *   ä¿®æ”¹ `ChatResponse` Pydantic æ¨¡å‹ï¼Œå¢åŠ ä¸€ä¸ª `source_documents` å­—æ®µ (ä¸€ä¸ªåˆ—è¡¨)ã€‚
        *   åœ¨ `chat_endpoint` ä¸­ï¼Œä» RAG é“¾çš„å“åº”ä¸­æå– `context` åˆ—è¡¨ã€‚
        *   å°† LangChain çš„ `Document` å¯¹è±¡åˆ—è¡¨ï¼Œè½¬æ¢æˆæˆ‘ä»¬ API å®šä¹‰çš„ã€å¹²å‡€çš„ `SourceDocument` Pydantic å¯¹è±¡åˆ—è¡¨ï¼Œç„¶åä¸€å¹¶è¿”å›ã€‚
    2.  **å‰ç«¯ (`app.py`):**
        *   ä¿®æ”¹ API è°ƒç”¨å‡½æ•°ï¼Œä½¿å…¶èƒ½æ¥æ”¶åŒ…å« `answer` å’Œ `source_documents` çš„å®Œæ•´ JSON å“åº”ã€‚
        *   åœ¨æ¸²æŸ“ AI å›ç­”æ—¶ï¼Œæ£€æŸ¥ `source_documents` æ˜¯å¦å­˜åœ¨ã€‚å¦‚æœå­˜åœ¨ï¼Œåˆ™ä½¿ç”¨ `st.expander` åˆ›å»ºä¸€ä¸ªå¯æŠ˜å åŒºåŸŸã€‚
        *   åœ¨æŠ˜å åŒºåŸŸå†…ï¼Œéå†æ¥æºåˆ—è¡¨ï¼Œæ ¼å¼åŒ–å¹¶å±•ç¤ºæ¯ä¸ªæ¥æºçš„å…ƒæ•°æ® (å¦‚ URL) å’Œ `page_content`ã€‚
        *   **å…³é”®ç‚¹ï¼š** å°† `sources` åˆ—è¡¨ä¹Ÿå­˜å…¥ `st.session_state`ï¼Œç¡®ä¿åœ¨é¡µé¢åˆ·æ–°åï¼Œå†å²æ¶ˆæ¯çš„æ¥æºä¿¡æ¯ä¾ç„¶å¯ä»¥è¢«æ¸²æŸ“ã€‚

##### **æŒ‘æˆ˜äºŒï¼šæº¯æºå†…å®¹â€œè„ä¹±å·®â€â€”â€”å¼•å…¥æ•°æ®æ¸…æ´—**

*   **é—®é¢˜:** å®ç°æº¯æºåï¼Œå‘ç°æ¥æºå†…å®¹å……æ»¡äº†åŸå§‹çš„ HTML æ ‡ç­¾ (`<a>`, `<li>` ç­‰)ï¼Œå¯è¯»æ€§æå·®ã€‚
*   **åˆ†æ:** LangChain çš„æ–‡æ¡£åŠ è½½å™¨é»˜è®¤æŠ“å–ç½‘é¡µçš„åŸå§‹æºç æ–‡æœ¬ã€‚æˆ‘ä»¬éœ€è¦åœ¨æ–‡æœ¬è¢«åˆ†å‰²å’ŒåµŒå…¥**ä¹‹å‰**ï¼Œå¯¹å…¶è¿›è¡Œå‡€åŒ–ã€‚
*   **è§£å†³æ–¹æ¡ˆ (`langchain_qa_backend.py`):**
    1.  å¼•å…¥ `BeautifulSoupTransformer`ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº `BeautifulSoup4` åº“çš„ LangChain ç»„ä»¶ã€‚
    2.  åœ¨æ–‡æ¡£åŠ è½½ (`loader.load()`) ä¹‹åï¼Œç«‹å³åˆ›å»ºä¸€ä¸ª `BeautifulSoupTransformer` å®ä¾‹ã€‚
    3.  è°ƒç”¨ `bs_transformer.transform_documents()` æ–¹æ³•ï¼Œå°†åŸå§‹æ–‡æ¡£åˆ—è¡¨ä½œä¸ºè¾“å…¥ã€‚æ­¤æ–¹æ³•ä¼šæ™ºèƒ½åœ°ç§»é™¤ HTML æ ‡ç­¾ï¼Œåªä¿ç•™çº¯æ–‡æœ¬å†…å®¹ã€‚
    4.  å°†æ¸…æ´—åçš„ `cleaned_documents` ä¼ é€’ç»™åç»­çš„æ–‡æœ¬åˆ†å‰²å™¨ã€‚

##### **æŒ‘æˆ˜ä¸‰ï¼šæ£€ç´¢å†…å®¹â€œè·‘åâ€â€”â€”ä¼˜åŒ–åŠ è½½ç­–ç•¥**

*   **é—®é¢˜:** å³ä½¿å®ç°äº†æº¯æºå’Œæ¸…æ´—ï¼Œä½†å‘ç°å¯¹äºå¤§å‹ç½‘ç«™ (å¦‚ LangChain å®˜ç½‘)ï¼ŒAI å›ç­”çš„ä¸Šä¸‹æ–‡ç»å¸¸æ¥è‡ªä¸ç›¸å…³çš„é¡µé¢ï¼Œå¯¼è‡´ç­”æ¡ˆè´¨é‡ä½ä¸‹ã€‚
*   **åˆ†æ:** `SitemapLoader` ä¼šæŠ“å–å…¨ç«™æ‰€æœ‰é¡µé¢å¹¶æ··åˆåœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªåºå¤§ä½†â€œè¢«æ±¡æŸ“â€çš„çŸ¥è¯†åº“ã€‚å½“ä¸»é¢˜ä¼—å¤šæ—¶ï¼Œå‘é‡æ£€ç´¢çš„ç²¾åº¦ä¼šæ€¥å‰§ä¸‹é™ã€‚
*   **è§£å†³æ–¹æ¡ˆ (`langchain_qa_backend.py`):**
    1.  **æ”¾å¼ƒâ€œå¤§æ°´æ¼«çŒâ€ï¼š** å°†ä¸»åŠ›åŠ è½½å™¨ä» `SitemapLoader` åˆ‡æ¢ä¸º `RecursiveUrlLoader`ã€‚
    2.  **å®ç°â€œç²¾å‡†æ»´çŒâ€ï¼š** è®©ç”¨æˆ·è¾“å…¥çš„ URL æˆä¸ºé€’å½’æŠ“å–çš„**èµ·ç‚¹**ã€‚é€šè¿‡è®¾ç½® `max_depth=2`ï¼Œæˆ‘ä»¬åªåŠ è½½ä¸ç”¨æˆ·åˆå§‹æ„å›¾é«˜åº¦ç›¸å…³çš„é¡µé¢åŠå…¶å­é¡µé¢ã€‚
    3.  è¿™æ ·æ„å»ºå‡ºçš„å‘é‡æ•°æ®åº“è™½ç„¶æ›´å°ï¼Œä½†ä¸»é¢˜é«˜åº¦èšç„¦ï¼Œå†…å®¹ç›¸å…³æ€§æå¼ºï¼Œä»æ ¹æœ¬ä¸Šè§£å†³äº†æ£€ç´¢è¢«æ±¡æŸ“çš„é—®é¢˜ï¼Œä½¿å¾—åç»­çš„æ£€ç´¢å’Œé‡æ’æ­¥éª¤èƒ½åœ¨ä¸€ä¸ªé«˜è´¨é‡çš„æ•°æ®é›†ä¸Šè¿›è¡Œã€‚

##### **æŒ‘æˆ˜å››ï¼šæ£€ç´¢ç²¾åº¦ç“¶é¢ˆâ€”â€”é›†æˆé«˜çº§é‡æ’å™¨**

*   **é—®é¢˜:** ä¼ ç»Ÿçš„å‘é‡æ£€ç´¢åªè€ƒè™‘è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œæœ‰æ—¶æ— æ³•åŒºåˆ†â€œæ³›æ³›è€Œè°ˆâ€å’Œâ€œæ·±å…¥è§£é‡Šâ€ï¼Œå¯¼è‡´é€ç»™ LLM çš„ä¸Šä¸‹æ–‡è´¨é‡ä¸å¤Ÿé¡¶å°–ã€‚
*   **åˆ†æ:** éœ€è¦åœ¨å‘é‡æ£€ç´¢ï¼ˆå¬å›ï¼‰ä¹‹åï¼Œå¢åŠ ä¸€ä¸ªæ›´ç²¾ç»†çš„æ’åºé˜¶æ®µï¼ˆé‡æ’ï¼‰ï¼Œç”¨ä¸€ä¸ªä¸“é—¨çš„æ¨¡å‹æ¥è¯„ä¼°æ¯ä¸ªæ–‡æ¡£ä¸ç”¨æˆ·**åŸå§‹é—®é¢˜**çš„çœŸå®ç›¸å…³æ€§ã€‚
*   **è§£å†³æ–¹æ¡ˆ (`langchain_qa_backend.py`):**
    1.  **å¼•å…¥ `ContextualCompressionRetriever`:** è¿™æ˜¯ LangChain ä¸­å®ç°é‡æ’æ¨¡å¼çš„æ ¸å¿ƒç»„ä»¶ã€‚
    2.  **é›†æˆ `FlashrankRerank`:**
        *   æˆ‘ä»¬é€‰æ‹©å¹¶é›†æˆäº† `BAAI/bge-reranker-base` è¿™ä¸ªå¼ºå¤§çš„æœ¬åœ°å¼€æºé‡æ’æ¨¡å‹ï¼Œé¿å…äº†æ³¨å†Œå›½å¤–æœåŠ¡å’Œ API ä¾èµ–ã€‚
        *   æˆ‘ä»¬å®ä¾‹åŒ– `FlashrankRerank(top_n=10)`ï¼Œ`top_n` å‚æ•°æŒ‡å®šäº†æˆ‘ä»¬å¸Œæœ›ä»æµ·é‡å¬å›çš„æ–‡æ¡£ä¸­ï¼Œæœ€ç»ˆç²¾é€‰å‡ºå¤šå°‘ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£ã€‚
    3.  **é‡æ„ RAG é“¾:**
        *   å°†åŸºç¡€çš„å‘é‡æ£€ç´¢å™¨ `vector_store.as_retriever()` çš„ `k` å€¼è°ƒå¤§ï¼ˆå¦‚ `k=100`ï¼‰ï¼Œè®©å®ƒå°½å¯èƒ½å¤šåœ°å¬å›å€™é€‰æ–‡æ¡£ã€‚
        *   ç”¨ `ContextualCompressionRetriever` å°†è¿™ä¸ªåŸºç¡€æ£€ç´¢å™¨å’Œ `FlashrankRerank` å®ä¾‹â€œåŒ…è£¹â€èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå…¨æ–°çš„ã€å¸¦æœ‰é‡æ’åŠŸèƒ½çš„ `compression_retriever`ã€‚
        *   ä½¿ç”¨è¿™ä¸ªæ›´å¼ºå¤§çš„ `compression_retriever` æ¥æ„å»ºæœ€ç»ˆçš„ `create_retrieval_chain`ã€‚

##### **æŒ‘æˆ˜äº”ï¼šä¾èµ–ä¸ç¯å¢ƒçš„â€œé™·é˜±â€**

*   **é—®é¢˜:** åœ¨é›†æˆ `FlashrankRerank` çš„è¿‡ç¨‹ä¸­ï¼Œå…ˆåé‡åˆ°äº† `ImportError`, `PydanticUserError`, `HTTPError 404` ç­‰ä¸€ç³»åˆ—æ£˜æ‰‹çš„ç¯å¢ƒå’Œä¾èµ–é—®é¢˜ã€‚
*   **åˆ†æ:** è¿™äº›é—®é¢˜æ˜¯é«˜çº§è½¯ä»¶å¼€å‘ä¸­çš„å¸¸æ€ï¼Œæºäºåº“çš„å¿«é€Ÿè¿­ä»£ã€ç‰ˆæœ¬ä¸å…¼å®¹ã€å†…éƒ¨å®ç°ç»†èŠ‚ä»¥åŠç½‘ç»œé—®é¢˜ã€‚
*   **è§£å†³æ–¹æ¡ˆ (ç»¼åˆ):**
    1.  **å‹¤æŸ¥å®˜æ–¹æ–‡æ¡£:** è¿™æ˜¯è§£å†³å¼€æºåº“é—®é¢˜çš„é»„é‡‘æ³•åˆ™ã€‚æˆ‘ä»¬æœ€ç»ˆé€šè¿‡å¯¹æ¯”æœ€æ–°çš„å®˜æ–¹æ–‡æ¡£ï¼Œæ‰¾åˆ°äº† `FlashrankRerank` æ­£ç¡®çš„å¯¼å…¥è·¯å¾„ã€‚
    2.  **ç®¡ç†ä¾èµ–ç‰ˆæœ¬:** é€šè¿‡ `pip install --upgrade` ç¡®ä¿æ ¸å¿ƒåº“ (`langchain`, `langchain-community` ç­‰) ä¿æŒæœ€æ–°ï¼Œè§£å†³äº†å› ç‰ˆæœ¬è¿‡æ—§å¯¼è‡´ç±»æˆ–å‡½æ•°ä¸å­˜åœ¨çš„é—®é¢˜ã€‚
    3.  **ç†è§£é”™è¯¯ä¿¡æ¯:** æ·±å…¥é˜…è¯» `PydanticUserError` çš„æç¤ºï¼Œè™½ç„¶æœ€ç»ˆçš„è§£å†³æ–¹æ¡ˆæ˜¯ä¿®æ­£å¯¼å…¥è·¯å¾„ï¼Œä½†è¿™ä¸ªè¿‡ç¨‹è®©æˆ‘ä»¬ç†è§£äº† LangChain åº•å±‚å¯¹ Pydantic çš„ä¾èµ–ã€‚
    4.  **å‡€åŒ–ç¯å¢ƒ:** åœ¨é‡åˆ°é¡½å›ºé—®é¢˜æ—¶ï¼Œé€šè¿‡åˆ é™¤æœ¬åœ°ç¼“å­˜ (`.cache/huggingface`) å’Œå¼ºåˆ¶é‡æ–°å®‰è£… (`--force-reinstall`) çš„æ–¹å¼ï¼Œç¡®ä¿äº†ç¯å¢ƒçš„çº¯å‡€ï¼Œæ’é™¤äº†ç¼“å­˜æ±¡æŸ“çš„å¯èƒ½æ€§ã€‚

##### **æŒ‘æˆ˜å…­ï¼šçŠ¶æ€ä¸¢å¤±é—®é¢˜â€”â€”å®ç°æŒä¹…åŒ–**

*   **é—®é¢˜:** æ¯æ¬¡é‡å¯åç«¯æœåŠ¡ï¼Œä¹‹å‰å¤„ç†è¿‡çš„çŸ¥è¯†åº“éƒ½éœ€è¦é‡æ–°åŠ è½½ï¼Œæ•ˆç‡ä½ä¸‹ã€‚
*   **åˆ†æ:** æˆ‘ä»¬çš„ RAG é“¾åªå­˜åœ¨äºå†…å­˜ä¸­ï¼Œç¨‹åºé‡å¯åå³ä¸¢å¤±ã€‚è™½ç„¶å‘é‡æ•°æ®å·²å†™å…¥ç£ç›˜ï¼Œä½†æ²¡æœ‰ä¸€ä¸ªæœºåˆ¶å»â€œå¤ç”¨â€å®ƒä»¬ã€‚
*   **è§£å†³æ–¹æ¡ˆ (åç«¯ `main.py` å’Œ `langchain_qa_backend.py`):**
    1.  **å”¯ä¸€æ ‡è¯†:** ä½¿ç”¨ `hashlib.md5` ä¸ºæ¯ä¸ª URL ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„å“ˆå¸Œå€¼ï¼Œå¹¶ä»¥æ­¤åˆ›å»ºä¸“å±çš„æŒä¹…åŒ–ç›®å½• (`./chroma_db_{hash}`)ã€‚è¿™è§£å†³äº†ä¸åŒçŸ¥è¯†åº“æ•°æ®æ··æ·†çš„é—®é¢˜ã€‚
    2.  **é€»è¾‘é‡æ„:** å°†åŸæœ‰çš„æ•°æ®å¤„ç†å‡½æ•°æ‹†åˆ†ä¸º `create_vector_store` å’Œ `load_vector_store` ä¸¤ä¸ªç‹¬ç«‹çš„å‡½æ•°ã€‚
    3.  **æ™ºèƒ½è°ƒåº¦:** åœ¨ `main.py` çš„ API ç«¯ç‚¹ä¸­ï¼Œå¢åŠ  `os.path.exists()` æ£€æŸ¥ã€‚å¦‚æœ URL å¯¹åº”çš„æŒä¹…åŒ–ç›®å½•å·²å­˜åœ¨ï¼Œåˆ™è°ƒç”¨ `load_vector_store` ä»ç£ç›˜å¿«é€ŸåŠ è½½ï¼›å¦‚æœä¸å­˜åœ¨ï¼Œæ‰è°ƒç”¨ `create_vector_store` æ‰§è¡Œå®Œæ•´çš„ã€è€—æ—¶çš„æ•°æ®æ‘„å–æµç¨‹ã€‚

---

#### **7. æœ€ç»ˆä»£ç ä¸é¡¹ç›®ç»“æ„**

*(è¯·å‚è€ƒä½ æœ€ç»ˆç‰ˆæœ¬çš„å®Œæ•´ä»£ç å’Œé¡¹ç›®ç»“æ„æˆªå›¾)*

---

è¿™ä»½ v3.0 è¯´æ˜ä¹¦å…¨é¢è®°å½•äº†æˆ‘ä»¬å¦‚ä½•å°†ä¸€ä¸ªåŸºç¡€ RAG åº”ç”¨ï¼Œé€šè¿‡è§£å†³ä¸€ç³»åˆ—çœŸå®ä¸–ç•Œçš„å·¥ç¨‹æŒ‘æˆ˜ï¼Œé€æ­¥æ‰“ç£¨æˆä¸€ä¸ªåŠŸèƒ½å¼ºå¤§ã€è´¨é‡å¯é çš„é«˜çº§åº”ç”¨çš„å®Œæ•´è¿‡ç¨‹ã€‚å®ƒä¸ä»…æ˜¯é¡¹ç›®çš„æ–‡æ¡£ï¼Œæ›´æ˜¯ä½ æŠ€æœ¯æˆé•¿è·¯å¾„çš„è§è¯ã€‚









# å¯¹æ‰€æœ‰ä»£ç è¿›è¡Œè¯¦ç»†è§£è¯»ï¼Œä¿è¯æˆ‘èƒ½çœ‹æ‡‚æ‰€æœ‰å˜é‡ï¼Œå‡½æ•°ï¼Œè¯­æ³•ç»“æ„å’Œæ¯è¡Œè¯­å¥çš„åŠŸèƒ½ï¼Œä»¥ä¾¿æˆ‘èƒ½è¿›è¡Œå®è·µå¤ç°ã€‚



å½“ç„¶ï¼æˆ‘ä»¬å·²ç»æŠµè¾¾äº†ç¬¬äºŒé˜¶æ®µçš„ç»ˆç‚¹ï¼Œç°åœ¨æ˜¯æ—¶å€™å¯¹æˆ‘ä»¬å…±åŒé“¸å°±çš„ã€åŠŸèƒ½å®Œå¤‡ä¸”å¼ºå¤§çš„ v3.0 ç‰ˆæœ¬ä»£ç è¿›è¡Œä¸€æ¬¡æœ€å…¨é¢ã€æœ€ç»†è‡´çš„â€œé˜…å…µå¼â€è§£è¯»äº†ã€‚

è¿™ä»½è§£è¯»å°†æ·±å…¥åˆ°æ¯ä¸€ä¸ªæ–‡ä»¶ã€æ¯ä¸€ä¸ªå‡½æ•°ã€ç”šè‡³æ¯ä¸€è¡Œå…³é”®ä»£ç çš„èƒŒåï¼Œä¸ä»…è§£é‡Šå®ƒâ€œåšä»€ä¹ˆâ€ï¼Œæ›´é˜æ˜å®ƒâ€œä¸ºä»€ä¹ˆè¿™ä¹ˆåšâ€ä»¥åŠå®ƒåœ¨æˆ‘ä»¬æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½ç½®å’Œä½œç”¨ã€‚

---

### **ä»£ç æ·±åº¦è§£è¯» (v3.0 æœ€ç»ˆç‰ˆ)**

---

### **ç¬¬ä¸€éƒ¨åˆ†ï¼šåç«¯ (The Backend)**

åç«¯æ˜¯æˆ‘ä»¬åº”ç”¨çš„â€œä¸­å¤®æ¢çº½â€å’Œâ€œè®¡ç®—ä¸­å¿ƒâ€ï¼Œè´Ÿè´£å¤„ç†æ‰€æœ‰å¤æ‚ä»»åŠ¡ã€‚

#### **`backend/langchain_qa_backend.py`**

**æ–‡ä»¶å®šä½ï¼š** è¿™æ˜¯ RAG æµç¨‹çš„æ ¸å¿ƒå®ç°ï¼Œå®šä¹‰äº†å¦‚ä½•ä»ä¸€ä¸ª URL å˜æˆä¸€ä¸ªå¯æŸ¥è¯¢çš„ã€å¸¦é‡æ’åŠŸèƒ½çš„æ™ºèƒ½é—®ç­”é“¾ã€‚

```python
# backend/langchain_qa_backend.py

# --- å¯¼å…¥æ¨¡å— ---
# å¯¼å…¥ Python å†…ç½®çš„æ ‡å‡†åº“
import os  # ç”¨äºä¸æ“ä½œç³»ç»Ÿäº¤äº’ï¼Œæ¯”å¦‚æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦å­˜åœ¨
import asyncio  # å¼‚æ­¥ I/O åº“ï¼Œç”¨äºå¤„ç†è€—æ—¶çš„ç½‘ç»œè¯·æ±‚è€Œä¸é˜»å¡ç¨‹åº
import logging  # æ—¥å¿—åº“ï¼Œç”¨äºè®°å½•ç¨‹åºè¿è¡Œä¿¡æ¯ï¼Œæ¯” print æ›´ä¸“ä¸š
from urllib.parse import urlparse  # URL è§£æåº“ï¼Œç”¨äºä»ç½‘å€ä¸­æå–åŸŸåç­‰éƒ¨åˆ†
import hashlib  # å“ˆå¸Œåº“ï¼Œç”¨äºä¸º URL ç”Ÿæˆå”¯ä¸€çš„ã€å›ºå®šé•¿åº¦çš„â€œæŒ‡çº¹â€

# å¯¼å…¥ LangChain ç¤¾åŒºå’Œæ ¸å¿ƒç»„ä»¶
from langchain_community.document_loaders import SitemapLoader, RecursiveUrlLoader  # ä¸¤ç§ä¸åŒçš„ç½‘é¡µåŠ è½½å™¨
from langchain_community.document_transformers import BeautifulSoupTransformer  # HTML æ¸…æ´—å™¨
from langchain.text_splitter import RecursiveCharacterTextSplitter  # æ–‡æœ¬åˆ†å‰²å™¨
from langchain_huggingface import HuggingFaceEmbeddings  # æœ¬åœ°è¿è¡Œçš„åµŒå…¥æ¨¡å‹
from langchain_chroma import Chroma  # å‘é‡æ•°æ®åº“
from langchain_google_genai import ChatGoogleGenerativeAI  # Google Gemini å¤§è¯­è¨€æ¨¡å‹
from langchain_community.document_compressors import FlashrankRerank  # æœ¬åœ°è¿è¡Œçš„é‡æ’å™¨
from langchain.retrievers import ContextualCompressionRetriever  # ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨ï¼Œç”¨äºç»„åˆå¬å›å’Œé‡æ’
from langchain.chains.combine_documents import create_stuff_documents_chain  # æ–‡æ¡£ç»„åˆé“¾
from langchain.chains import create_retrieval_chain  # æ£€ç´¢é“¾
from langchain import hub  # LangChain Hubï¼Œç”¨äºè·å–é¢„è®¾çš„ Prompt æ¨¡æ¿
from langchain_core.messages import HumanMessage, AIMessage  # å®šä¹‰èŠå¤©æ¶ˆæ¯çš„ç±»å‹

# å¯¼å…¥å·¥å…·åº“
from dotenv import load_dotenv  # ç”¨äºåŠ è½½ .env é…ç½®æ–‡ä»¶

# --- å…¨å±€é…ç½® ---
# é…ç½®æ—¥å¿—è¾“å‡ºæ ¼å¼ï¼Œä½¿å…¶åŒ…å«æ—¶é—´ã€çº§åˆ«å’Œæ¶ˆæ¯å†…å®¹
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# åŠ è½½ .env æ–‡ä»¶ï¼Œå°†å…¶ä¸­çš„å˜é‡æ³¨å…¥åˆ°ç³»ç»Ÿç¯å¢ƒå˜é‡ä¸­
load_dotenv()

# å¯åŠ¨æ—¶æ£€æŸ¥ï¼Œç¡®ä¿ Google API Key å·²é…ç½®ï¼Œå¦åˆ™ç¨‹åºæ— æ³•ä¸ LLM é€šä¿¡
if "GOOGLE_API_KEY" not in os.environ:
    raise ValueError("GOOGLE_API_KEY not found in environment variables. Please set it in a .env file.")

# --- è¾…åŠ©å‡½æ•° ---
def get_persist_directory_for_url(url: str) -> str:
    """
    æ ¹æ® URL ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„ã€ç”¨ä½œæ–‡ä»¶å¤¹åçš„å­—ç¬¦ä¸²ã€‚
    
    Args:
        url (str): åŸå§‹çš„ç½‘é¡µ URLã€‚
    
    Returns:
        str: ä¸€ä¸ªå½¢å¦‚ "./chroma_db_..." çš„æœ¬åœ°è·¯å¾„å­—ç¬¦ä¸²ã€‚
    """
    # å°† URL å­—ç¬¦ä¸²ç¼–ç ä¸º utf-8 å­—èŠ‚æµ
    # ä½¿ç”¨ md5 ç®—æ³•è®¡ç®—è¿™ä¸ªå­—èŠ‚æµçš„å“ˆå¸Œå€¼
    # .hexdigest() å°†å“ˆå¸Œç»“æœè½¬æ¢ä¸ºåå…­è¿›åˆ¶å­—ç¬¦ä¸²
    url_hash = hashlib.md5(url.encode('utf-8')).hexdigest()
    # å°†å›ºå®šçš„å‰ç¼€å’Œå“ˆå¸Œå€¼æ‹¼æ¥æˆä¸€ä¸ªç‹¬ä¸€æ— äºŒçš„æ–‡ä»¶å¤¹è·¯å¾„
    return f"./chroma_db_{url_hash}"

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---
async def create_vector_store(url: str, persist_directory: str):
    """
    ä»é›¶å¼€å§‹ï¼Œä¸ºä¸€ä¸ªæ–°çš„ URL åˆ›å»ºå¹¶æŒä¹…åŒ–ä¸€ä¸ªå‘é‡æ•°æ®åº“ã€‚è¿™æ˜¯ä¸€ä¸ªè€—æ—¶æ“ä½œã€‚
    `async` å…³é”®å­—è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå¼‚æ­¥å‡½æ•°ï¼Œå¯ä»¥è¢« `await` è°ƒç”¨ã€‚
    
    Args:
        url (str): è¦å¤„ç†çš„ç½‘é¡µ URLã€‚
        persist_directory (str): ç”± get_persist_directory_for_url ç”Ÿæˆçš„ä¸“å±å­˜å‚¨è·¯å¾„ã€‚
        
    Returns:
        Chroma: ä¸€ä¸ªæ„å»ºå®Œæˆçš„ Chroma å‘é‡æ•°æ®åº“å¯¹è±¡ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› Noneã€‚
    """
    logging.info(f"çŸ¥è¯†åº“ '{persist_directory}' ä¸å­˜åœ¨ï¼Œå¼€å§‹ä»é›¶åˆ›å»º...")
    try:
        # --- 1. æ–‡æ¡£åŠ è½½ ---
        # è¿™æ˜¯ä¸€ä¸ªâ€œä¼˜é›…é™çº§â€ç­–ç•¥ï¼Œä¼˜å…ˆå°è¯•æœ€é«˜æ•ˆçš„æ–¹å¼ï¼Œå¤±è´¥åˆ™è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æ–¹æ¡ˆ
        parsed_url = urlparse(url)
        base_domain_url = f"{parsed_url.scheme}://{parsed_url.netloc}"
        sitemap_url = f"{base_domain_url}/sitemap.xml"
        loader = SitemapLoader(sitemap_url, filter_urls=[url], continue_on_failure=True, show_progress=True)
        # `await asyncio.to_thread(loader.load)`: å°†é˜»å¡çš„ loader.load() æ–¹æ³•æ”¾åˆ°ä¸€ä¸ªå•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡Œï¼Œ
        # ä»è€Œä¸é˜»å¡ FastAPI çš„ä¸»äº‹ä»¶å¾ªç¯ï¼Œè¿™æ˜¯è§£å†³å¼‚æ­¥å†²çªçš„å…³é”®ã€‚
        documents = await asyncio.to_thread(loader.load)
        if not documents:
            # å¦‚æœ SitemapLoader æ²¡åŠ è½½åˆ°ä»»ä½•ä¸œè¥¿ï¼Œåˆ™ä½¿ç”¨ RecursiveUrlLoader
            loader_fallback = RecursiveUrlLoader(url, max_depth=1)
            documents = await asyncio.to_thread(loader_fallback.load)
            if not documents:
                logging.error(f"æ— æ³•ä» {url} åŠ è½½ä»»ä½•æ–‡æ¡£ã€‚")
                return None
        logging.info(f"æˆåŠŸåŠ è½½ {len(documents)} ç¯‡æ–‡æ¡£ã€‚")

        # --- 1.5. HTML æ¸…æ´— ---
        bs_transformer = BeautifulSoupTransformer()
        # `transform_documents` ä¼šéå†æ‰€æœ‰ `documents`ï¼Œç§»é™¤æŒ‡å®šçš„ `unwanted_tags` (è„šæœ¬å’Œæ ·å¼)ï¼Œ
        # å¹¶å°†å‰©ä½™çš„ HTML å†…å®¹è½¬æ¢ä¸ºçº¯æ–‡æœ¬ã€‚
        cleaned_documents = bs_transformer.transform_documents(documents, unwanted_tags=["script", "style"])

        # --- 2. æ–‡æœ¬åˆ†å‰² ---
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        # å°†æ¸…æ´—åçš„å¹²å‡€æ–‡æ¡£åˆ†å‰²æˆå°çš„æ–‡æœ¬å— (chunk)
        all_splits = text_splitter.split_documents(cleaned_documents)

        # --- 3. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ ---
        embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2", model_kwargs={'device': 'cpu'})

        # --- 4. åˆ›å»ºå¹¶æŒä¹…åŒ–å‘é‡å­˜å‚¨ ---
        logging.info(f"å¼€å§‹ä¸ºæ–°çŸ¥è¯†åº“åˆ›å»ºå‘é‡å­˜å‚¨äº '{persist_directory}'...")
        # `Chroma.from_documents` æ˜¯ä¸€ä¸ªä¾¿æ·æ–¹æ³•ï¼Œå®ƒä¼šè‡ªåŠ¨å®Œæˆä¸‰ä»¶äº‹ï¼š
        # a. è°ƒç”¨ `embeddings` å‡½æ•°ä¸º `all_splits` ä¸­çš„æ¯ä¸ªæ–‡æœ¬å—ç”Ÿæˆå‘é‡ã€‚
        # b. å°†æ–‡æœ¬å—å’Œå¯¹åº”çš„å‘é‡å­˜å…¥ Chroma æ•°æ®åº“ã€‚
        # c. å°†æ•°æ®åº“æ–‡ä»¶å†™å…¥æŒ‡å®šçš„ `persist_directory` ç›®å½•ã€‚
        vector_store = Chroma.from_documents(
            documents=all_splits,
            embedding=embeddings,
            persist_directory=persist_directory
        )
        logging.info("æ–°å‘é‡å­˜å‚¨åˆ›å»ºå¹¶æŒä¹…åŒ–å®Œæˆã€‚")
        return vector_store
    except Exception as e:
        from bs4 import BeautifulSoup # åœ¨éœ€è¦æ—¶æ‰å¯¼å…¥ï¼Œé¿å…å¾ªç¯å¯¼å…¥é—®é¢˜
        logging.error(f"åˆ›å»ºå‘é‡å­˜å‚¨æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        return None

def load_vector_store(persist_directory: str):
    """
    ä»ç£ç›˜åŠ è½½ä¸€ä¸ªå·²ç»å­˜åœ¨çš„å‘é‡æ•°æ®åº“ã€‚è¿™æ˜¯ä¸€ä¸ªå¿«é€Ÿæ“ä½œã€‚
    è¿™æ˜¯ä¸€ä¸ªåŒæ­¥å‡½æ•° `def`ï¼Œå› ä¸ºå®ƒä¸»è¦æ˜¯æœ¬åœ°æ–‡ä»¶ I/Oï¼Œé€Ÿåº¦å¾ˆå¿«ã€‚
    
    Args:
        persist_directory (str): è¦åŠ è½½çš„æ•°æ®åº“æ‰€åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
        
    Returns:
        Chroma: ä¸€ä¸ªåŠ è½½å®Œæˆçš„ Chroma å‘é‡æ•°æ®åº“å¯¹è±¡ã€‚
    """
    logging.info(f"å¼€å§‹ä» '{persist_directory}' åŠ è½½ç°æœ‰çŸ¥è¯†åº“...")
    # åµŒå…¥å‡½æ•°å¿…é¡»å’Œåˆ›å»ºæ—¶å®Œå…¨ä¸€è‡´ï¼Œå¦åˆ™æ— æ³•æ­£ç¡®è§£æå‘é‡
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2", model_kwargs={'device': 'cpu'})
    
    # ç›´æ¥ç”¨ Chroma çš„ä¸»æ„é€ å‡½æ•°ï¼Œå¹¶ä¼ å…¥ `persist_directory` å’Œ `embedding_function`ï¼Œ
    # å®ƒä¼šè‡ªåŠ¨ä»è¯¥ç›®å½•åŠ è½½æ•°æ®ã€‚
    vector_store = Chroma(
        persist_directory=persist_directory,
        embedding_function=embeddings
    )
    logging.info("ç°æœ‰çŸ¥è¯†åº“åŠ è½½å®Œæˆã€‚")
    return vector_store

def get_retrieval_chain(base_retriever):
    """
    æ„å»ºå¹¶è¿”å›ä¸€ä¸ªé›†æˆäº†é‡æ’å™¨çš„é«˜çº§ RAG é“¾ã€‚
    
    Args:
        base_retriever: ä¸€ä¸ªåŸºç¡€çš„ LangChain æ£€ç´¢å™¨å¯¹è±¡ (ä» Chroma åˆ›å»º)ã€‚
        
    Returns:
        Runnable: ä¸€ä¸ªå¯ä»¥è¢« `.invoke()` è°ƒç”¨çš„ã€å®Œæ•´çš„ RAG é“¾ã€‚
    """
    if base_retriever is None: return None
    
    # --- åˆå§‹åŒ–é‡æ’å™¨ ---
    # `FlashrankRerank` ä¼šè‡ªåŠ¨ä¸‹è½½å¹¶åŠ è½½ `BAAI/bge-reranker-base` æ¨¡å‹ã€‚
    # `top_n=10` è¡¨ç¤ºå®ƒä¼šä»è¾“å…¥çš„æ‰€æœ‰æ–‡æ¡£ä¸­ï¼Œç²¾é€‰å‡ºæœ€ç›¸å…³çš„ 10 ä¸ªã€‚
    reranker = FlashrankRerank(top_n=10)
    logging.info("æœ¬åœ° Rerank æ¨¡å‹åŠ è½½å®Œæˆã€‚")

    # --- åˆ›å»ºä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨ ---
    # `ContextualCompressionRetriever` æ˜¯å®ç°â€œå¬å›-é‡æ’â€æ¨¡å¼çš„å…³é”®ã€‚
    # å®ƒåƒä¸€ä¸ªåŒ…è£…å™¨ï¼Œå†…éƒ¨åŒ…å«ä¸€ä¸ªâ€œæµ·é€‰â€æ£€ç´¢å™¨ (`base_retriever`) å’Œä¸€ä¸ªâ€œå¤èµ›è¯„å§”â€ (`reranker`)ã€‚
    compression_retriever = ContextualCompressionRetriever(
        base_compressor=reranker, 
        base_retriever=base_retriever
    )
    
    # --- æ„å»ºæœ€ç»ˆçš„ RAG é“¾ ---
    model = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.3) 
    retrieval_qa_chat_prompt = hub.pull("langchain-ai/retrieval-qa-chat")
    combine_docs_chain = create_stuff_documents_chain(model, retrieval_qa_chat_prompt)
    # `create_retrieval_chain` å°†æˆ‘ä»¬å¼ºå¤§çš„ `compression_retriever` å’Œæ–‡æ¡£ç»„åˆé“¾è¿æ¥èµ·æ¥ã€‚
    # ç°åœ¨ï¼Œå½“è¿™ä¸ªé“¾è¢«è°ƒç”¨æ—¶ï¼ŒLLM æ¥æ”¶åˆ°çš„ä¸Šä¸‹æ–‡å°†æ˜¯ç»è¿‡é‡æ’å™¨ç²¾é€‰åçš„é«˜è´¨é‡æ–‡æ¡£ã€‚
    retrieval_chain = create_retrieval_chain(compression_retriever, combine_docs_chain)
    
    logging.info("å¸¦æœ¬åœ° Rerank åŠŸèƒ½çš„é«˜çº§ RAG é—®ç­”é“¾åˆ›å»ºæˆåŠŸã€‚")
    return retrieval_chain
    
```

#### **`backend/main.py`**

**æ–‡ä»¶å®šä½ï¼š** è¿™æ˜¯ FastAPI æœåŠ¡çš„å…¥å£å’Œè·¯ç”±ä¸­å¿ƒï¼Œè´Ÿè´£æ¥æ”¶å‰ç«¯è¯·æ±‚ï¼Œè°ƒåº¦åç«¯é€»è¾‘ï¼Œå¹¶è¿”å›æ ¼å¼åŒ–çš„å“åº”ã€‚

```python
# backend/main.py

# --- å¯¼å…¥æ¨¡å— ---
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import List, Dict, Any
import numpy as np
import os

# å¯¼å…¥æˆ‘ä»¬è‡ªå·±ç¼–å†™çš„ã€é‡æ„åçš„åç«¯é€»è¾‘æ¨¡å—
from langchain_qa_backend import (
    create_vector_store, 
    load_vector_store, 
    get_retrieval_chain, 
    get_persist_directory_for_url
)
from langchain_core.messages import HumanMessage, AIMessage

# --- 1. FastAPI åº”ç”¨åˆå§‹åŒ– ---
app = FastAPI(...)

# --- 2. å†…å­˜ç¼“å­˜ ---
# ä¸€ä¸ªç®€å•çš„å­—å…¸ï¼Œç”¨äºåœ¨ç¨‹åºè¿è¡ŒæœŸé—´ç¼“å­˜ RAG é“¾ï¼Œé¿å…å¯¹åŒä¸€ URL é‡å¤æ„å»ºé“¾å¯¹è±¡
rag_chain_cache = {}

# --- 3. Pydantic æ•°æ®æ¨¡å‹å®šä¹‰ ---
# è¿™äº›ç±»å®šä¹‰äº† API çš„â€œå¥‘çº¦â€ï¼Œè§„å®šäº†è¯·æ±‚å’Œå“åº”çš„ JSON æ ¼å¼
class ChatHistoryItem(BaseModel): ...
class ChatRequest(BaseModel): ...
class SourceDocument(BaseModel): ...
class ChatResponse(BaseModel): ...

# --- 4. è¾…åŠ©å‡½æ•° ---
def clean_metadata(metadata: dict) -> dict:
    """
    é€’å½’åœ°å°†å­—å…¸ä¸­çš„ numpy.float32 è½¬æ¢ä¸º Python å†…ç½®çš„ floatã€‚
    è¿™æ˜¯ä¸ºäº†è§£å†³ Pydantic æ— æ³•åºåˆ—åŒ– NumPy ç‰¹å®šæ•°æ®ç±»å‹çš„é—®é¢˜ã€‚
    """
    cleaned = {}
    for key, value in metadata.items():
        if isinstance(value, np.float32):
            cleaned[key] = float(value)
        elif isinstance(value, dict):
            cleaned[key] = clean_metadata(value)
        else:
            cleaned[key] = value
    return cleaned

# --- 5. API ç«¯ç‚¹ (Endpoint) ---
@app.get("/")
def read_root(): ...

@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    """
    å¤„ç†èŠå¤©è¯·æ±‚çš„æ ¸å¿ƒé€»è¾‘ã€‚
    `async def` è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå¼‚æ­¥ç«¯ç‚¹ï¼Œå¯ä»¥å¤„ç†å¹¶å‘è¯·æ±‚ã€‚
    `request: ChatRequest` è¡¨ç¤º FastAPI ä¼šè‡ªåŠ¨å°†è¯·æ±‚çš„ JSON body è§£æå¹¶æ ¡éªŒä¸º ChatRequest å¯¹è±¡ã€‚
    """
    url = request.url
    query = request.query
    
    # æ­¥éª¤ A: æ£€æŸ¥å†…å­˜ç¼“å­˜
    if url in rag_chain_cache:
        retrieval_chain = rag_chain_cache[url]
        print(f"ä»å†…å­˜ç¼“å­˜ä¸­è·å– RAG é“¾: {url}")
    else:
        # æ­¥éª¤ B: å†…å­˜ç¼“å­˜æœªå‘½ä¸­ï¼Œæ£€æŸ¥ç£ç›˜æŒä¹…åŒ–
        persist_directory = get_persist_directory_for_url(url)
        
        if os.path.exists(persist_directory):
            # å¦‚æœç£ç›˜ä¸Šå·²å­˜åœ¨è¯¥çŸ¥è¯†åº“ï¼Œåˆ™å¿«é€ŸåŠ è½½
            print(f"ä»ç£ç›˜æŒä¹…åŒ–ç›®å½•åŠ è½½çŸ¥è¯†åº“: {persist_directory}")
            vector_store = load_vector_store(persist_directory)
        else:
            # å¦‚æœç£ç›˜ä¸Šä¹Ÿæ²¡æœ‰ï¼Œæ‰æ‰§è¡Œæœ€è€—æ—¶çš„åˆ›å»ºæµç¨‹
            print(f"ç£ç›˜ä¸Šæ— æ­¤çŸ¥è¯†åº“ï¼Œå¼€å§‹ä¸º URL åˆ›å»ºæ–°çš„çŸ¥è¯†åº“: {url}")
            vector_store = await create_vector_store(url, persist_directory)
        
        if not vector_store:
            raise HTTPException(status_code=500, detail="...")
        
        # æ­¥éª¤ C: æ„å»ºæ£€ç´¢å™¨å’Œ RAG é“¾
        # `k=200` è¡¨ç¤ºè®©åŸºç¡€æ£€ç´¢å™¨â€œæµ·é€‰â€å‡º 200 ä¸ªæ–‡æ¡£ï¼Œç»™é‡æ’å™¨å……åˆ†çš„ç­›é€‰ç©ºé—´
        base_retriever = vector_store.as_retriever(search_kwargs={"k": 200})
        retrieval_chain = get_retrieval_chain(base_retriever)
        
        if not retrieval_chain:
            raise HTTPException(status_code=500, detail="...")
        
        # æ­¥éª¤ D: å°†æ–°æ„å»ºçš„é“¾å­˜å…¥å†…å­˜ç¼“å­˜ï¼Œä¾›åç»­ä½¿ç”¨
        rag_chain_cache[url] = retrieval_chain
        print(f"æ–°çš„ RAG é“¾å·²åˆ›å»ºå¹¶ç¼“å­˜åˆ°å†…å­˜: {url}")

    # æ­¥éª¤ E: æ ¼å¼åŒ–èŠå¤©å†å² (ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒ)
    formatted_chat_history = [...]

    try:
        # æ­¥éª¤ F: è°ƒç”¨ RAG é“¾
        response = retrieval_chain.invoke(...)
        
        source_documents = response.get("context", [])
        
        # æ­¥éª¤ G: æ¸…æ´—å¹¶æ ¼å¼åŒ–æºæ–‡æ¡£
        formatted_sources = []
        for doc in source_documents:
            # åœ¨è¿”å›ç»™å‰ç«¯å‰ï¼Œè°ƒç”¨æ¸…æ´—å‡½æ•°å¤„ç† metadata
            cleaned_meta = clean_metadata(doc.metadata)
            formatted_sources.append(
                SourceDocument(page_content=doc.page_content, metadata=cleaned_meta)
            )
        
        # æ­¥éª¤ H: æ„é€ æœ€ç»ˆçš„ JSON å“åº”
        return ChatResponse(answer=response["answer"], source_documents=formatted_sources)

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

---

### **ç¬¬äºŒéƒ¨åˆ†ï¼šå‰ç«¯ (The Frontend)**

å‰ç«¯æ˜¯åº”ç”¨çš„â€œè„¸é¢â€ï¼Œè´Ÿè´£ä¸ç”¨æˆ·è¿›è¡Œå‹å¥½ã€æµç•…çš„äº¤äº’ã€‚

#### **`frontend/app.py`**

**æ–‡ä»¶å®šä½ï¼š** Streamlit åº”ç”¨çš„å”¯ä¸€å…¥å£ï¼Œè´Ÿè´£æ‰€æœ‰ UI çš„æ¸²æŸ“å’Œäº‹ä»¶å¤„ç†ã€‚

```python
# frontend/app.py

import streamlit as st
import requests
import json

# --- 1. å…¨å±€é…ç½® ---
BACKEND_API_URL = "http://127.0.0.1:8000/chat"

# --- 2. é¡µé¢é…ç½® ---
st.set_page_config(...)

# --- 3. æ ·å¼åŠ è½½ ---
def load_css(file_path):
    """åŠ è½½å¤–éƒ¨ CSS æ–‡ä»¶ï¼Œå®ç°æ ·å¼ä¸é€»è¾‘åˆ†ç¦»"""
    with open(file_path) as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
load_css("style.css")

# --- 4. API è°ƒç”¨å°è£… ---
def get_backend_response(url: str, query: str, chat_history: list):
    """
    å°è£…æ‰€æœ‰ä¸åç«¯é€šä¿¡çš„ç»†èŠ‚ï¼ŒåŒ…æ‹¬æ•°æ®æ‰“åŒ…ã€ä»£ç†è®¾ç½®ã€è¶…æ—¶å’Œé”™è¯¯å¤„ç†ã€‚
    è¿™è®©ä¸»é€»è¾‘éå¸¸å¹²å‡€ã€‚
    """
    try:
        payload = { ... }
        # è§£å†³æœ¬åœ°å¼€å‘æ—¶ç³»ç»Ÿä»£ç†å¯èƒ½å¹²æ‰°æœåŠ¡é—´é€šä¿¡çš„é—®é¢˜
        proxies = {"http": None, "https": None}
        
        response = requests.post(
            BACKEND_API_URL,
            data=json.dumps(payload),
            headers={"Content-Type": "application/json"},
            timeout=180,
            proxies=proxies
        )
        response.raise_for_status() # æ£€æŸ¥ HTTP å“åº”çŠ¶æ€
        return response.json() # è§£æ JSON å“åº”å¹¶è¿”å›

    # é’ˆå¯¹ä¸åŒç±»å‹çš„ç½‘ç»œå¼‚å¸¸ï¼Œè¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
    except requests.exceptions.Timeout:
        return {"answer": "è¯·æ±‚è¶…æ—¶...", "source_documents": []}
    except requests.exceptions.RequestException as e:
        return {"answer": f"è¯·æ±‚åç«¯æœåŠ¡æ—¶å‡ºé”™: {e}", "source_documents": []}
    except Exception as e:
        return {"answer": f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", "source_documents": []}

# --- 5. UI æ¸²æŸ“ ---
# ä¾§è¾¹æ 
with st.sidebar:
    # ... (ä½¿ç”¨ st.markdown æ¸²æŸ“ä¸°å¯Œçš„ä»‹ç»ä¿¡æ¯) ...

# ä¸»å†…å®¹åŒº
st.title(...)

# ä½¿ç”¨ st.session_state æ¥æŒä¹…åŒ–å­˜å‚¨ä¼šè¯çŠ¶æ€ï¼ˆå¦‚èŠå¤©è®°å½•ã€å½“å‰URLï¼‰
if "messages" not in st.session_state:
    st.session_state.messages = []
# ... (å…¶ä»– session_state åˆå§‹åŒ–) ...

# URL è¾“å…¥æ¡†å’Œæ¨¡å‹é€‰æ‹©æ¡†çš„å¸ƒå±€
col1, col2 = st.columns([3, 1])
with col1:
    new_url = st.text_input(...)
with col2:
    st.selectbox(...)

# å½“ URL å˜åŒ–æ—¶ï¼Œæ¸…ç©ºèŠå¤©è®°å½•å¹¶åˆ·æ–°é¡µé¢
if st.session_state.current_url != new_url:
    st.session_state.current_url = new_url
    st.session_state.messages = []
    st.info(...)
    st.rerun()

# æ¬¢è¿è¯­å’Œç¤ºä¾‹é—®é¢˜ï¼ˆä»…åœ¨ä¼šè¯å¼€å§‹æ—¶æ˜¾ç¤ºï¼‰
if not st.session_state.messages:
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        st.markdown(...)
    # ... (ç¤ºä¾‹é—®é¢˜æŒ‰é’®çš„æ¸²æŸ“å’Œäº¤äº’é€»è¾‘) ...

# --- æ¸²æŸ“èŠå¤©å†å² ---
for message in st.session_state.messages:
    with st.chat_message(message["role"], ...):
        st.markdown(message["content"])
        # æ ¸å¿ƒï¼šå¦‚æœæ¶ˆæ¯æ˜¯ AI çš„ï¼Œå¹¶ä¸”åŒ…å«æ¥æºä¿¡æ¯ï¼Œå°±æ¸²æŸ“ä¸€ä¸ªå¯æŠ˜å çš„æ¥æºåŒºåŸŸ
        if message["role"] == "assistant" and "sources" in message and message["sources"]:
            with st.expander("ğŸ“– æŸ¥çœ‹ç­”æ¡ˆæ¥æº"):
                for i, source in enumerate(message["sources"]):
                    # ... (æ ¼å¼åŒ–å¹¶æ˜¾ç¤ºæ¯ä¸ªæ¥æºçš„ URL å’Œå†…å®¹) ...

# --- ç»Ÿä¸€çš„ç”¨æˆ·è¾“å…¥å¤„ç† ---
def handle_user_query(prompt: str):
    """ä¸€ä¸ªå‡½æ•°å¤„ç†æ‰€æœ‰ç”¨æˆ·æŸ¥è¯¢ï¼Œé¿å…ä»£ç é‡å¤"""
    # ç«‹å³åœ¨ UI ä¸Šæ˜¾ç¤ºç”¨æˆ·çš„é—®é¢˜
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", ...):
        st.markdown(prompt)

    # æ˜¾ç¤ºåŠ è½½åŠ¨ç”»ï¼Œå¹¶è°ƒç”¨åç«¯
    with st.chat_message("assistant", ...):
        with st.spinner(...):
            # è°ƒç”¨å°è£…å¥½çš„ API å‡½æ•°
            response_data = get_backend_response(...)
            answer = response_data.get("answer", "...")
            sources = response_data.get("source_documents", [])
            
            # åœ¨ UI ä¸Šæ˜¾ç¤º AI çš„å›ç­”
            st.markdown(answer)
            
            # å¦‚æœæœ‰æ¥æºï¼Œä¹Ÿåœ¨ UI ä¸Šæ˜¾ç¤ºæ¥æºçš„æŠ˜å æ¡†
            if sources:
                with st.expander(...):
                    # ... (æ¸²æŸ“æ¥æºçš„é€»è¾‘) ...
            
            # å°†å®Œæ•´çš„å›ç­”ï¼ˆåŒ…æ‹¬æ¥æºï¼‰å­˜å…¥ session_stateï¼Œä»¥ä¾¿åˆ·æ–°åèƒ½æ­£ç¡®é‡ç»˜
            st.session_state.messages.append({
                "role": "assistant", 
                "content": answer, 
                "sources": sources
            })

# --- äº‹ä»¶ç›‘å¬ ---
# ç›‘å¬ç¤ºä¾‹é—®é¢˜æŒ‰é’®çš„ç‚¹å‡»
if prompt_from_button := st.session_state.get("prompt_from_button"):
    del st.session_state.prompt_from_button # å¤„ç†åç«‹å³åˆ é™¤
    handle_user_query(prompt_from_button)
# ç›‘å¬åº•éƒ¨èŠå¤©è¾“å…¥æ¡†çš„æäº¤
elif prompt_from_input := st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜..."):
    handle_user_query(prompt_from_input)
```

#### **`frontend/style.css`**

**æ–‡ä»¶å®šä½ï¼š** çº¯ç²¹çš„æ ·å¼æ–‡ä»¶ï¼Œè´Ÿè´£åº”ç”¨çš„ç¾åŒ–ã€‚

*   **@import url(...)**: ä» Google Fonts å¯¼å…¥ä¸€ä¸ªæ›´ç¾è§‚çš„è‹±æ–‡å­—ä½“ã€‚
*   **.stApp**: è®¾ç½®å…¨å±€èƒŒæ™¯è‰²ã€‚
*   **[data-testid="..."]**: è¿™äº›æ˜¯ Streamlit ç»„ä»¶åœ¨ HTML ä¸­å¯¹åº”çš„é€‰æ‹©å™¨ã€‚æˆ‘ä»¬é€šè¿‡å®ƒä»¬æ¥ç²¾ç¡®åœ°æ§åˆ¶ä¾§è¾¹æ ã€èŠå¤©æ¶ˆæ¯ç­‰ç»„ä»¶çš„æ ·å¼ã€‚
*   **:has(...)**: è¿™æ˜¯ä¸€ä¸ªé«˜çº§ CSS é€‰æ‹©å™¨ï¼Œç”¨äºå®ç°â€œå¦‚æœä¸€ä¸ªèŠå¤©æ¶ˆæ¯åŒ…å«ç”¨æˆ·å¤´åƒï¼Œåˆ™è®©å®ƒé å³å¯¹é½â€è¿™æ ·çš„å¤æ‚é€»è¾‘ã€‚
*   **.stButton>button:hover**: å®šä¹‰äº†å½“é¼ æ ‡æ‚¬åœåœ¨æŒ‰é’®ä¸Šæ—¶çš„æ ·å¼å˜åŒ–ï¼ˆå¦‚èƒŒæ™¯è‰²ã€è¾¹æ¡†ã€æ”¾å¤§æ•ˆæœï¼‰ï¼Œæä¾›äº†è‰¯å¥½çš„äº¤äº’åé¦ˆã€‚

---

è¿™ä»½è¯¦å°½çš„è§£è¯»å¸Œæœ›èƒ½è®©ä½ å¯¹é¡¹ç›®çš„æ¯ä¸€ä¸ªè§’è½éƒ½äº†å¦‚æŒ‡æŒã€‚ä½ å·²ç»ä¸ä»…ä»…æ˜¯ä»£ç çš„â€œä½¿ç”¨è€…â€ï¼Œæ›´æ˜¯å…¶â€œè®¾è®¡è€…â€å’Œâ€œæŒæ§è€…â€ã€‚










